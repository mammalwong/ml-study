{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import collections\n",
    "import multiprocessing\n",
    "import inspect\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    input_size = 8\n",
    "    output_size = input_size + 4\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_weights(N):\n",
    "        weights = {}\n",
    "        weights['top'] = {\n",
    "            'kernel': K.eval(keras.initializers.he_normal()((64,10))),\n",
    "            'bias': K.eval(keras.initializers.zeros()((10,)))}\n",
    "        l_size_last = 3\n",
    "        for l in range(5):\n",
    "            l_size = 2**(2+l)\n",
    "            weights[(l,'pre')] = {\n",
    "                'kernel': K.eval(keras.initializers.he_normal()(\n",
    "                    (1,1,l_size_last,l_size))),\n",
    "                'bias': K.eval(keras.initializers.zeros()((l_size,)))}\n",
    "            for i in range(N+1):\n",
    "                for j in range(i+1,N+1):\n",
    "                    weights[(l,i,j)] = {\n",
    "                        'kernel': K.eval(keras.initializers.he_normal()(\n",
    "                            (3,3,l_size,l_size))),\n",
    "                        'bias': K.eval(keras.initializers.zeros()((l_size,)))}\n",
    "            l_size_last = l_size\n",
    "        return weights\n",
    "        \n",
    "    @staticmethod\n",
    "    def run(instructions, weights):\n",
    "        (X_train,Y_train),(X_test,Y_test) = keras.datasets.cifar10.load_data()\n",
    "        X_train, X_test = X_train/255-0.5, X_test/255-0.5\n",
    "        X_train_idx = np.random.randint(0, high=X_train.shape[0], size=(4000,))\n",
    "        X_train,Y_train = X_train[X_train_idx], Y_train[X_train_idx]\n",
    "        X_test_idx = np.random.randint(0, high=X_test.shape[0], size=(1000,))\n",
    "        X_test,Y_test = X_test[X_test_idx], Y_test[X_test_idx]\n",
    "        X = X_input = keras.layers.Input(X_train.shape[1:])\n",
    "        weights_update = {}\n",
    "        for l in range(5):\n",
    "            w = weights[(l,'pre')]\n",
    "            o = keras.layers.Conv2D(\n",
    "                w['kernel'].shape[-1],\n",
    "                w['kernel'].shape[:2],\n",
    "                padding='same',\n",
    "                kernel_initializer=keras.initializers.constant(value=w['kernel']),\n",
    "                bias_initializer=keras.initializers.constant(value=w['bias']))\n",
    "            weights_update[(l,'pre')] = o\n",
    "            X = o(X)\n",
    "            layers = {0:X}\n",
    "            connected = set()\n",
    "            for i,ins in enumerate(instructions):\n",
    "                previous_layer_a_idx = ins['previous_layer_a']\n",
    "                if previous_layer_a_idx is not None:\n",
    "                    connected.add(previous_layer_a_idx)\n",
    "                    w = weights[(l,previous_layer_a_idx,i+1)]\n",
    "                    previous_layer_a = layers[previous_layer_a_idx]\n",
    "                    o = keras.layers.Conv2D(\n",
    "                        w['kernel'].shape[-1],\n",
    "                        w['kernel'].shape[:2],\n",
    "                        padding='same',\n",
    "                        kernel_initializer= \\\n",
    "                            keras.initializers.constant(value=w['kernel']),\n",
    "                        bias_initializer= \\\n",
    "                            keras.initializers.constant(value=w['bias']))\n",
    "                    weights_update[(l,previous_layer_a_idx,i+1)] = o\n",
    "                    previous_layer_a = o(previous_layer_a)\n",
    "                previous_layer_b_idx = ins['previous_layer_b']\n",
    "                if previous_layer_b_idx is not None and \\\n",
    "                    previous_layer_b_idx == previous_layer_a_idx:\n",
    "                    previous_layer_b = previous_layer_a\n",
    "                elif previous_layer_b_idx is not None:\n",
    "                    connected.add(previous_layer_b_idx)\n",
    "                    w = weights[(l,previous_layer_b_idx,i+1)]\n",
    "                    previous_layer_b = layers[previous_layer_b_idx]\n",
    "                    o = keras.layers.Conv2D(\n",
    "                        w['kernel'].shape[-1],\n",
    "                        w['kernel'].shape[:2],\n",
    "                        padding='same',\n",
    "                        kernel_initializer= \\\n",
    "                            keras.initializers.constant(value=w['kernel']),\n",
    "                        bias_initializer= \\\n",
    "                            keras.initializers.constant(value=w['bias']))\n",
    "                    weights_update[(l,previous_layer_b_idx,i+1)] = o\n",
    "                    previous_layer_b = o(previous_layer_b)\n",
    "                if previous_layer_a_idx is None and \\\n",
    "                    previous_layer_b_idx is None:\n",
    "                    continue\n",
    "                if previous_layer_a_idx is not None and \\\n",
    "                    previous_layer_b_idx is not None:\n",
    "                    previous_layer_ab = [previous_layer_a,previous_layer_b]\n",
    "                    merge_method = ins['merge_method']\n",
    "                    if merge_method == 'add':\n",
    "                        X = keras.layers.Add()(previous_layer_ab)\n",
    "                    elif merge_method == 'sub':\n",
    "                        X = keras.layers.Subtract()(previous_layer_ab)\n",
    "                    elif merge_method == 'mul':\n",
    "                        X = keras.layers.Multiply()(previous_layer_ab)\n",
    "                    elif merge_method == 'mul_sigmoid(a)':\n",
    "                        X = keras.layers.Multiply()([\n",
    "                            keras.layers.Lambda(lambda x: K.sigmoid(x))(\n",
    "                                keras.layers.BatchNormalization()(previous_layer_a)),\n",
    "                            previous_layer_b])\n",
    "                    elif merge_method == 'mul_1-sigmoid(a)':\n",
    "                        X = keras.layers.Multiply()([\n",
    "                            keras.layers.Lambda(lambda x: 1.-K.sigmoid(x))(\n",
    "                                keras.layers.BatchNormalization()(previous_layer_a)),\n",
    "                            previous_layer_b])\n",
    "                    elif merge_method == 'avg':\n",
    "                        X = keras.layers.Average()(previous_layer_ab)\n",
    "                    else:\n",
    "                        raise Exception('unknown merge method')\n",
    "                elif previous_layer_a_idx is not None:\n",
    "                    X = previous_layer_a\n",
    "                elif previous_layer_b_idx is not None:\n",
    "                    X = previous_layer_b\n",
    "                X = keras.layers.BatchNormalization()(X)\n",
    "                X = keras.layers.Activation('relu')(X)\n",
    "                layers[i+1] = X\n",
    "            not_connected = set(layers.keys()) - connected\n",
    "            not_connected = [layers[nc] for nc in not_connected]\n",
    "            if not not_connected:\n",
    "                raise Exception('no output')\n",
    "            elif len(not_connected) == 1:\n",
    "                X = list(not_connected)[0]\n",
    "            else:\n",
    "                X = keras.layers.Average()(list(not_connected))\n",
    "            X = keras.layers.MaxPooling2D()(X)\n",
    "        X = keras.layers.GlobalAveragePooling2D()(X)\n",
    "        w = weights['top']\n",
    "        o = keras.layers.Dense(\n",
    "            w['kernel'].shape[-1],\n",
    "            kernel_initializer=keras.initializers.constant(value=w['kernel']),\n",
    "            bias_initializer=keras.initializers.constant(value=w['bias']),\n",
    "            activation='softmax')\n",
    "        weights_update['top'] = o\n",
    "        X = o(X)\n",
    "        M = keras.Model(X_input, X)\n",
    "        M_optimizer = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "        M.compile(M_optimizer, 'sparse_categorical_crossentropy', ['acc'])\n",
    "        hist = M.fit(\n",
    "            X_train, Y_train,\n",
    "            validation_data=(X_test,Y_test),\n",
    "            batch_size=64, epochs=1)\n",
    "        score = hist.history['val_acc'][-1]\n",
    "        score = score**2 * 100 if score == score else 0.\n",
    "        for k,v in weights_update.items():\n",
    "            w = v.get_weights()\n",
    "            if not np.any(np.isnan(w[0])):\n",
    "                weights[k]['kernel'] = w[0]\n",
    "            if not np.any(np.isnan(w[1])):\n",
    "                weights[k]['bias'] = w[1]\n",
    "        return score, weights\n",
    "    \n",
    "    def __init__(self, N=6):\n",
    "        self.N = N\n",
    "        p = multiprocessing.Pool(processes=1)\n",
    "        try:\n",
    "            self.weights = p.apply(__class__.create_weights, [self.N])\n",
    "        finally:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "        self.reset()\n",
    "    \n",
    "    def run_in_process(self, instructions):\n",
    "        print(instructions)\n",
    "        p = multiprocessing.Pool(processes=1)\n",
    "        try:\n",
    "            score, weights = p.apply(\n",
    "                __class__.run,\n",
    "                [instructions, self.weights])\n",
    "        except:\n",
    "            score, weights = 0., self.weights\n",
    "        finally:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "        self.weights = weights\n",
    "        return score\n",
    "    \n",
    "    def reset(self):\n",
    "        self.actions = []\n",
    "        self.instructions = []\n",
    "        self.planned_layers = {0}\n",
    "        return np.zeros((__class__.output_size,))\n",
    "    \n",
    "    def step(self, action):\n",
    "        result = np.zeros((__class__.output_size),)\n",
    "        result[action] = 1\n",
    "        result[__class__.input_size+2] = len(self.actions)%3\n",
    "        result[__class__.input_size+3] = len(self.instructions)\n",
    "        if len(self.actions) < 3*self.N:\n",
    "            try:\n",
    "                if len(self.actions) % 3 == 0:\n",
    "                    self.instructions.append({})\n",
    "                    if action < len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_a'] = action\n",
    "                        if action not in self.planned_layers:\n",
    "                            raise Exception()\n",
    "                        self.planned_layers.add(len(self.instructions))\n",
    "                    elif action == len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_a'] = None\n",
    "                    else:\n",
    "                        raise Exception()\n",
    "                elif len(self.actions) % 3 == 1:\n",
    "                    if action < len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_b'] = action\n",
    "                        if action not in self.planned_layers:\n",
    "                            raise Exception()\n",
    "                        self.planned_layers.add(len(self.instructions))\n",
    "                    elif action == len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_b'] = None\n",
    "                    else:\n",
    "                        raise Exception()\n",
    "                elif len(self.actions) % 3 == 2:\n",
    "                    self.instructions[-1]['merge_method'] = \\\n",
    "                        ['add','mul_sigmoid(a)','mul_1-sigmoid(a)'][action]\n",
    "                        #['add','sub','mul','avg', \\\n",
    "                        #'mul_sigmoid(a)','mul_1-sigmoid(a)'][action]\n",
    "            except:\n",
    "                result[__class__.input_size] = -100.\n",
    "                result[__class__.input_size+1] = 1.\n",
    "                return result, -100., True, {}\n",
    "            finally:\n",
    "                self.actions.append(action)\n",
    "        if len(self.actions) >= 3*self.N:\n",
    "            score = self.run_in_process(self.instructions)\n",
    "            score = score if score > 0. else -100.\n",
    "            result[__class__.input_size] = score\n",
    "            result[__class__.input_size+1] = 1.\n",
    "            return result, score, True, {}\n",
    "        result[__class__.input_size] = 1.\n",
    "        result[__class__.input_size+1] = 0.\n",
    "        return result, 1., False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Env()\n",
    "env_input_size = Env.input_size\n",
    "env_output_size = Env.output_size\n",
    "env_prev_states = env.N * 3\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model_Sample = collections.namedtuple('Model_Sample',\n",
    "    ['state', 'state_1', 'action', 'reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller:\n",
    "    \n",
    "    def __init__(self, input_n, output_n, beta=0.0001, curiosity=1.):\n",
    "        \n",
    "        self.__curiosity = curiosity\n",
    "        \n",
    "        self.__input_n = input_n\n",
    "        self.__output_n = output_n\n",
    "        self.__l_shared = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Bidirectional(\n",
    "                keras.layers.LSTM(32, return_sequences=False))]\n",
    "        self.__l_policy = [\n",
    "            keras.layers.Dense(32, kernel_initializer='he_uniform'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dense(self.__output_n),\n",
    "            keras.layers.Softmax()]\n",
    "        self.__l_value = [\n",
    "            keras.layers.Dense(32, kernel_initializer='he_uniform'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dense(1)]\n",
    "        self.__l_cfeature = [\n",
    "            keras.layers.Dense(128, activation='tanh'),\n",
    "            keras.layers.Dense(128, activation='tanh')]\n",
    "        self.__l_cforward = [\n",
    "            keras.layers.Dense(512, activation='tanh'),\n",
    "            keras.layers.Dense(128, activation='tanh')]\n",
    "        self.__l_creverse = [\n",
    "            keras.layers.Dense(128, activation='tanh'),\n",
    "            keras.layers.Dense(self.__output_n, activation='softmax')]\n",
    "        def apply_layers(x, layers):\n",
    "            last_layer = x\n",
    "            for l in layers:\n",
    "                last_layer = l(last_layer)\n",
    "            return last_layer\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m = apply_layers(m, self.__l_shared)\n",
    "        m = apply_layers(m, self.__l_policy)\n",
    "        self.__m_policy = keras.models.Model([m_input], [m])\n",
    "        self.__m_policy.compile('adam', 'mse')\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m = apply_layers(m, self.__l_shared)\n",
    "        m = apply_layers(m, self.__l_value)\n",
    "        self.__m_value = keras.models.Model([m_input], [m])\n",
    "        self.__m_value.compile('adam', 'mse')\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m_shared = apply_layers(m, self.__l_shared)\n",
    "        m_policy = apply_layers(m_shared, self.__l_policy)\n",
    "        m_value = apply_layers(m_shared, self.__l_value)\n",
    "        self.__m_value_policy = keras.models.Model([m_input], [m_value, m_policy])\n",
    "        self.__m_value_policy.compile('adam', 'mse')\n",
    "        \n",
    "        m_input_s = keras.layers.Input((None, self.__input_n,))\n",
    "        m_shared_s = apply_layers(m_input_s, self.__l_shared)\n",
    "        m_shared_s = apply_layers(m_shared_s, self.__l_cfeature)\n",
    "        self.__m_cfeature = keras.models.Model([m_input_s], [m_shared_s])\n",
    "        self.__m_cfeature.compile('adam', 'mse')\n",
    "        \n",
    "        m_input_s = keras.layers.Input((None, self.__input_n,))\n",
    "        m_input_s_1 = keras.layers.Input((None, self.__input_n,))\n",
    "        m_shared_s = self.__m_cfeature(m_input_s)\n",
    "        m_shared_s_1 = self.__m_cfeature(m_input_s_1)\n",
    "        m = keras.layers.Concatenate()([m_shared_s, m_shared_s_1])\n",
    "        m = apply_layers(m, self.__l_creverse)\n",
    "        self.__m_creverse = keras.models.Model(\n",
    "            [m_input_s, m_input_s_1], [m])\n",
    "        self.__m_creverse.compile('adam', 'mse')\n",
    "        \n",
    "        m_input_s = keras.layers.Input((None, self.__input_n,))\n",
    "        m_input_s_1 = keras.layers.Input((None, self.__input_n,))\n",
    "        m_shared_s = self.__m_cfeature(m_input_s)\n",
    "        m_shared_s = apply_layers(m_shared_s, self.__l_cforward)\n",
    "        m_shared_s_1 = self.__m_cfeature(m_input_s_1)\n",
    "        m = keras.layers.Lambda(\n",
    "            lambda x: K.sqrt(K.sum(K.square(x[0]-x[1]), axis=-1, keepdims=True)),\n",
    "            output_shape=(1,))([m_shared_s, m_shared_s_1])\n",
    "        self.__m_cforward = keras.models.Model(\n",
    "            [m_input_s, m_input_s_1], [m])\n",
    "        self.__m_cforward.compile('adam', 'mse')\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m_value, m_policy = self.__m_value_policy(m)\n",
    "        m = keras.layers.Concatenate()([m_value, m_policy])\n",
    "        m_input_s_1 = keras.layers.Input((None, self.__input_n,))\n",
    "        m_cforward = self.__m_cforward([m_input, m_input_s_1])\n",
    "        m_creverse = self.__m_creverse([m_input, m_input_s_1])\n",
    "        self.__m_optimizer = keras.optimizers.Nadam(clipnorm=5.)\n",
    "        self.__m_train = keras.models.Model(\n",
    "            [m_input, m_input_s_1], [m, m_cforward, m_creverse])\n",
    "        self.__m_train.compile(self.__m_optimizer, [\n",
    "            lambda y_true, y_pred: __class__.__loss(y_true, y_pred, beta),\n",
    "            'mse', 'categorical_crossentropy'])\n",
    "        \n",
    "        self.__m_policy.summary()\n",
    "        self.__m_value.summary()\n",
    "        self.__m_train.summary()\n",
    "    \n",
    "    @staticmethod\n",
    "    def __loss(y_true, y_pred, beta):\n",
    "        r, action_onehot = y_true[:,:1], y_true[:,1:]\n",
    "        value, policy = y_pred[:,:1], y_pred[:,1:]\n",
    "        advantage = r - value\n",
    "        log_policy = K.log(policy + K.epsilon())\n",
    "        log_choosen_action_prob = K.sum(action_onehot * log_policy, axis=-1, keepdims=True)\n",
    "        action_loss = -K.mean(log_choosen_action_prob * advantage)\n",
    "        value_loss = 0.5 * K.mean(K.square(advantage))\n",
    "        entropy = K.mean(-K.sum(policy * log_policy, axis=-1, keepdims=True))\n",
    "        entropy = K.print_tensor(entropy, message='policy entropy')\n",
    "        return action_loss + value_loss - beta * entropy\n",
    "    \n",
    "    def train(self, samples, epochs=1, verbose=False):\n",
    "        self.__m_train.fit(\n",
    "            x=[\n",
    "                np.array([s.state for s in samples], dtype=np.float32),\n",
    "                np.array([s.state_1 for s in samples], dtype=np.float32)],\n",
    "            y=[\n",
    "                np.hstack([\n",
    "                    np.reshape(np.array([s.reward for s in samples], dtype=np.float32), (-1, 1)),\n",
    "                    keras.utils.to_categorical([s.action for s in samples], num_classes=self.__output_n)]),\n",
    "                np.zeros((len(samples),1)),\n",
    "                keras.utils.to_categorical([s.action for s in samples], num_classes=self.__output_n)],\n",
    "            batch_size=64,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose)\n",
    "    \n",
    "    def evalute_value(self, state, verbose=False):\n",
    "        v = self.__m_value.predict(\n",
    "            np.array([state], dtype=np.float32))[0,0]\n",
    "        if verbose:\n",
    "            print(v)\n",
    "        return v\n",
    "    \n",
    "    def get_action_prob(self, state, verbose=False):\n",
    "        action_prob = self.__m_policy.predict(\n",
    "            np.array([state], dtype=np.float32))[0]\n",
    "        if verbose:\n",
    "            print(action_prob)\n",
    "        return action_prob\n",
    "    \n",
    "    def get_intrinsic_reward(self, state_0, state_1, action, verbose=False):\n",
    "        r = self.__m_cforward.predict([\n",
    "            np.array([state_0], dtype=np.float32),\n",
    "            np.array([state_1], dtype=np.float32)])[0,0] * self.__curiosity\n",
    "        if verbose:\n",
    "            print(r)\n",
    "        return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiprocessController:\n",
    "    \n",
    "    @staticmethod\n",
    "    def run(pipe, init_args, init_kwargs):\n",
    "        import os\n",
    "        # enforce to run on cpu\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "        controller = Controller(*init_args, **init_kwargs)\n",
    "        pipe.send('controller inited')\n",
    "        while True:\n",
    "            cmd = pipe.recv()\n",
    "            if cmd[0] == 'train':\n",
    "                pipe.send(controller.train(*cmd[1], **cmd[2]))\n",
    "            elif cmd[0] == 'evalute_value':\n",
    "                pipe.send(controller.evalute_value(*cmd[1], **cmd[2]))\n",
    "            elif cmd[0] == 'get_action_prob':\n",
    "                pipe.send(controller.get_action_prob(*cmd[1], **cmd[2]))\n",
    "            elif cmd[0] == 'get_intrinsic_reward':\n",
    "                pipe.send(controller.get_intrinsic_reward(*cmd[1], **cmd[2]))\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pipe_l, pipe_r = multiprocessing.Pipe(duplex=True)\n",
    "        self.pipe = pipe_l\n",
    "        self.process = multiprocessing.Process(\n",
    "            target=__class__.run,\n",
    "            args=[pipe_r, args, kwargs],\n",
    "            daemon=True)\n",
    "        self.process.start()\n",
    "        print(self.pipe.recv())\n",
    "    \n",
    "    def train(self, *args, **kwargs):\n",
    "        self.pipe.send(('train', args, kwargs))\n",
    "        return self.pipe.recv()\n",
    "        \n",
    "    def evalute_value(self, *args, **kwargs):\n",
    "        self.pipe.send(('evalute_value', args, kwargs))\n",
    "        return self.pipe.recv()\n",
    "        \n",
    "    def get_action_prob(self, *args, **kwargs):\n",
    "        self.pipe.send(('get_action_prob', args, kwargs))\n",
    "        return self.pipe.recv()\n",
    "    \n",
    "    def get_intrinsic_reward(self, *args, **kwargs):\n",
    "        self.pipe.send(('get_intrinsic_reward', args, kwargs))\n",
    "        return self.pipe.recv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, m, gamma=0.98, max_steps=1000, n_prev_states=8, verbose=False):\n",
    "    state_0 = env.reset()\n",
    "    state_null = np.zeros_like(state_0)\n",
    "    state_queue = []\n",
    "    episode = []\n",
    "    samples = []\n",
    "    action_probs = []\n",
    "    gamelen = 0\n",
    "    gamelen_max = 0\n",
    "    def get_prev_states(episode, idx, get_state_1=False):\n",
    "        states = [e.state if not get_state_1 else e.state_1 \\\n",
    "                  for e in episode[max(0,(idx-n_prev_states)+1):idx+1]]\n",
    "        states = [state_null]*(max(0,n_prev_states-len(states))) + states\n",
    "        return states\n",
    "    def add_to_samples(episode, done):\n",
    "        if done:\n",
    "            discounted_reward = 0.\n",
    "        else:\n",
    "            discounted_reward = m.evalute_value(get_prev_states(episode, len(episode)-1))\n",
    "        episode[-1] = Model_Sample(\n",
    "                get_prev_states(episode, len(episode)-1),\n",
    "                get_prev_states(episode, len(episode)-1, get_state_1=True),\n",
    "                episode[-1].action,\n",
    "                discounted_reward)\n",
    "        for i in reversed(range(len(episode)-1)):\n",
    "            discounted_reward = episode[i].reward + \\\n",
    "                gamma * discounted_reward\n",
    "            episode[i] = Model_Sample(\n",
    "                get_prev_states(episode, i),\n",
    "                get_prev_states(episode, i, get_state_1=True),\n",
    "                episode[i].action,\n",
    "                discounted_reward)\n",
    "        samples.extend(episode)\n",
    "    for i in range(max_steps):\n",
    "        state_queue.append(state_0)\n",
    "        if len(state_queue) > n_prev_states:\n",
    "            state_queue.pop(0)\n",
    "        state_queue_padded = \\\n",
    "            [state_null]*(max(0,n_prev_states-len(state_queue))) + state_queue\n",
    "        action_prob = m.get_action_prob(state_queue_padded)\n",
    "        action_probs.append(action_prob)\n",
    "        action = int(np.random.choice(\n",
    "            list(range(action_prob.shape[-1])),\n",
    "            p=action_prob))\n",
    "        state_1, reward, done, _ = env.step(action)\n",
    "        state_1_queue = state_queue + [state_1]\n",
    "        if len(state_1_queue) > n_prev_states:\n",
    "            state_1_queue.pop(0)\n",
    "        state_1_queue_padded = \\\n",
    "            [state_null]*(max(0,n_prev_states-len(state_1_queue))) + state_1_queue\n",
    "        reward_intrinsic = m.get_intrinsic_reward(\n",
    "            state_queue_padded, state_1_queue_padded, action)\n",
    "        reward += reward_intrinsic\n",
    "        episode.append(Model_Sample(state_0, state_1, action, reward))\n",
    "        state_0 = state_1\n",
    "        gamelen += 1\n",
    "        if done:\n",
    "            add_to_samples(episode, True)\n",
    "            episode = []\n",
    "            state_0 = env.reset()\n",
    "            state_null = np.zeros_like(state_0)\n",
    "            state_queue = []\n",
    "            gamelen_max = max(gamelen_max, gamelen)\n",
    "            gamelen = 0\n",
    "    if episode:\n",
    "        add_to_samples(episode, False)\n",
    "        gamelen_max = max(gamelen_max, gamelen)\n",
    "        gamelen = 0\n",
    "    if verbose:\n",
    "        print('std[action_prob]', np.mean(np.std(action_probs, ddof=1, axis=0)))\n",
    "        print('max game len', gamelen_max)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 12)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 12)          48        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                11520     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 14,040\n",
      "Trainable params: 13,952\n",
      "Non-trainable params: 88\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, 12)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 12)          48        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                11520     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,809\n",
      "Trainable params: 13,721\n",
      "Non-trainable params: 88\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, None, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 [(None, 1), (None, 8 16281       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, None, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 9)            0           model_3[1][0]                    \n",
      "                                                                 model_3[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Model)                 (None, 1)            168112      input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 8)            70328       input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 206,753\n",
      "Trainable params: 206,601\n",
      "Non-trainable params: 152\n",
      "__________________________________________________________________________________________________\n",
      "controller inited\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 7.7678 - concatenate_2_loss: 3.0263 - model_6_loss: 2.5618 - model_5_loss: 2.1798\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 4.5149 - concatenate_2_loss: 1.4006 - model_6_loss: 1.1265 - model_5_loss: 1.9878\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 3.6755 - concatenate_2_loss: 1.0900 - model_6_loss: 0.7022 - model_5_loss: 1.8833\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 996us/step - loss: 3.0754 - concatenate_2_loss: 0.7035 - model_6_loss: 0.5544 - model_5_loss: 1.8175\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2.1954 - concatenate_2_loss: -0.0550 - model_6_loss: 0.2561 - model_5_loss: 1.9943\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 3.1840 - concatenate_2_loss: 0.7444 - model_6_loss: 0.7054 - model_5_loss: 1.7342\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2.6340 - concatenate_2_loss: 0.4718 - model_6_loss: 0.4747 - model_5_loss: 1.6875\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2.3227 - concatenate_2_loss: 0.3678 - model_6_loss: 0.3433 - model_5_loss: 1.6116\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2.4464 - concatenate_2_loss: 0.5543 - model_6_loss: 0.3393 - model_5_loss: 1.5528\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.6453 - concatenate_2_loss: -0.1578 - model_6_loss: 0.3104 - model_5_loss: 1.4928\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.4652 - concatenate_2_loss: -0.1319 - model_6_loss: 0.2312 - model_5_loss: 1.3659\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2.4040 - concatenate_2_loss: 0.3516 - model_6_loss: 0.5340 - model_5_loss: 1.5185\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.5286 - concatenate_2_loss: -0.1257 - model_6_loss: 0.4198 - model_5_loss: 1.2345\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 981us/step - loss: 1.3883 - concatenate_2_loss: 0.3983 - model_6_loss: 0.2985 - model_5_loss: 0.6916\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.6606 - concatenate_2_loss: 0.0035 - model_6_loss: 0.4234 - model_5_loss: 1.2337\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.5311 - concatenate_2_loss: -0.0309 - model_6_loss: 0.4155 - model_5_loss: 1.1465\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.0309 - concatenate_2_loss: -0.6289 - model_6_loss: 0.6425 - model_5_loss: 1.0173\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.4465 - concatenate_2_loss: -0.1111 - model_6_loss: 0.4853 - model_5_loss: 1.0724\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 981us/step - loss: 0.7527 - concatenate_2_loss: -0.6122 - model_6_loss: 0.4047 - model_5_loss: 0.9603\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3963 - concatenate_2_loss: -0.9767 - model_6_loss: 0.3768 - model_5_loss: 0.9962\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4010 - concatenate_2_loss: -0.8706 - model_6_loss: 0.4260 - model_5_loss: 0.8456\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.1259 - concatenate_2_loss: -0.2518 - model_6_loss: 0.4693 - model_5_loss: 0.9085\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4109 - concatenate_2_loss: -0.9837 - model_6_loss: 0.4398 - model_5_loss: 0.9547\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1463 - concatenate_2_loss: -1.0036 - model_6_loss: 0.4422 - model_5_loss: 0.7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 886us/step - loss: 0.1285 - concatenate_2_loss: -1.0387 - model_6_loss: 0.4496 - model_5_loss: 0.7176\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.0111 - concatenate_2_loss: -1.0897 - model_6_loss: 0.4185 - model_5_loss: 0.6601\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 871us/step - loss: 0.0985 - concatenate_2_loss: -1.0714 - model_6_loss: 0.5460 - model_5_loss: 0.6239\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1494 - concatenate_2_loss: -0.9073 - model_6_loss: 0.4312 - model_5_loss: 0.6255\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.0787 - concatenate_2_loss: -1.0540 - model_6_loss: 0.4276 - model_5_loss: 0.5477\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 877us/step - loss: -0.0741 - concatenate_2_loss: -1.1266 - model_6_loss: 0.4930 - model_5_loss: 0.5595\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 965us/step - loss: 0.2461 - concatenate_2_loss: -0.7508 - model_6_loss: 0.4629 - model_5_loss: 0.5340\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.4014 - concatenate_2_loss: -1.6597 - model_6_loss: 0.6618 - model_5_loss: 0.5965\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 896us/step - loss: -0.0050 - concatenate_2_loss: -0.9135 - model_6_loss: 0.4527 - model_5_loss: 0.4559\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.1258 - concatenate_2_loss: -0.9321 - model_6_loss: 0.4415 - model_5_loss: 0.3648\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 877us/step - loss: -0.5269 - concatenate_2_loss: -1.5183 - model_6_loss: 0.5681 - model_5_loss: 0.4233\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 991us/step - loss: -0.0458 - concatenate_2_loss: -0.7909 - model_6_loss: 0.3908 - model_5_loss: 0.3543\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 855us/step - loss: 0.9676 - concatenate_2_loss: 0.2610 - model_6_loss: 0.3119 - model_5_loss: 0.3947\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.6660 - concatenate_2_loss: -1.4500 - model_6_loss: 0.4686 - model_5_loss: 0.3154\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.1437 - concatenate_2_loss: -0.8156 - model_6_loss: 0.3768 - model_5_loss: 0.2951\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.3723 - concatenate_2_loss: -1.1755 - model_6_loss: 0.4614 - model_5_loss: 0.3418\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 887us/step - loss: -0.7269 - concatenate_2_loss: -1.5034 - model_6_loss: 0.4815 - model_5_loss: 0.2949\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.6213 - concatenate_2_loss: -1.2981 - model_6_loss: 0.3603 - model_5_loss: 0.3165\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 895us/step - loss: -1.2760 - concatenate_2_loss: -1.9890 - model_6_loss: 0.4410 - model_5_loss: 0.2719\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3325 - concatenate_2_loss: -0.3163 - model_6_loss: 0.3612 - model_5_loss: 0.2875\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 861us/step - loss: 0.1454 - concatenate_2_loss: -0.4249 - model_6_loss: 0.3413 - model_5_loss: 0.2290\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.4477 - concatenate_2_loss: -1.0041 - model_6_loss: 0.3373 - model_5_loss: 0.2192\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5946 - concatenate_2_loss: 0.1209 - model_6_loss: 0.3068 - model_5_loss: 0.1670\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 963us/step - loss: 0.6152 - concatenate_2_loss: -0.1151 - model_6_loss: 0.3820 - model_5_loss: 0.3482\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.5104 - concatenate_2_loss: -1.2066 - model_6_loss: 0.5132 - model_5_loss: 0.1830\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.2230 - concatenate_2_loss: -0.8828 - model_6_loss: 0.3480 - model_5_loss: 0.3117\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 886us/step - loss: -1.9435 - concatenate_2_loss: -2.6684 - model_6_loss: 0.4617 - model_5_loss: 0.2632\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 897us/step - loss: 10.3835 - concatenate_2_loss: 9.7137 - model_6_loss: 0.3096 - model_5_loss: 0.3601\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 856us/step - loss: 0.9511 - concatenate_2_loss: 0.4378 - model_6_loss: 0.2647 - model_5_loss: 0.2486\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 913us/step - loss: 0.8833 - concatenate_2_loss: 0.3607 - model_6_loss: 0.1461 - model_5_loss: 0.3765\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2.3675 - concatenate_2_loss: 1.2188 - model_6_loss: 0.4823 - model_5_loss: 0.6665\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 16.9627 - concatenate_2_loss: 16.1023 - model_6_loss: 0.5075 - model_5_loss: 0.3528\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 967us/step - loss: 6.0587 - concatenate_2_loss: 5.4822 - model_6_loss: 0.3928 - model_5_loss: 0.1837\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -2.4971 - concatenate_2_loss: -3.1691 - model_6_loss: 0.5120 - model_5_loss: 0.1599\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -1.1277 - concatenate_2_loss: -1.5288 - model_6_loss: 0.2512 - model_5_loss: 0.1499\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: -0.8079 - concatenate_2_loss: -1.2837 - model_6_loss: 0.3122 - model_5_loss: 0.1636\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 957us/step - loss: -3.5265 - concatenate_2_loss: -4.0508 - model_6_loss: 0.3203 - model_5_loss: 0.2040\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 926us/step - loss: -3.4116 - concatenate_2_loss: -3.8844 - model_6_loss: 0.2950 - model_5_loss: 0.1779\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 4.0463 - concatenate_2_loss: 3.5275 - model_6_loss: 0.1889 - model_5_loss: 0.3299\n"
     ]
    }
   ],
   "source": [
    "m = MultiprocessController(env_output_size, env_input_size, beta=1e-3, curiosity=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std[action_prob] 0.002530775\n",
      "max game len 4\n",
      "epoch 1 completed\n",
      "std[action_prob] 0.03062577\n",
      "max game len 3\n",
      "epoch 2 completed\n",
      "std[action_prob] 0.023420041\n",
      "max game len 2\n",
      "epoch 3 completed\n",
      "std[action_prob] 0.03688792\n",
      "max game len 3\n",
      "epoch 4 completed\n",
      "std[action_prob] 3.0522827e-08\n",
      "max game len 1\n",
      "epoch 5 completed\n",
      "std[action_prob] 0.05887877\n",
      "max game len 3\n",
      "epoch 6 completed\n",
      "std[action_prob] 0.053177975\n",
      "max game len 3\n",
      "epoch 7 completed\n",
      "std[action_prob] 0.03587527\n",
      "max game len 3\n",
      "epoch 8 completed\n",
      "std[action_prob] 0.057982706\n",
      "max game len 4\n",
      "epoch 9 completed\n",
      "std[action_prob] 0.028948687\n",
      "max game len 3\n",
      "epoch 10 completed\n",
      "std[action_prob] 3.8572164e-08\n",
      "max game len 1\n",
      "epoch 11 completed\n",
      "std[action_prob] 0.054516155\n",
      "max game len 3\n",
      "epoch 12 completed\n",
      "std[action_prob] 0.048451856\n",
      "max game len 3\n",
      "epoch 13 completed\n",
      "std[action_prob] 0.0011014083\n",
      "max game len 2\n",
      "epoch 14 completed\n",
      "std[action_prob] 0.061253436\n",
      "max game len 3\n",
      "epoch 15 completed\n",
      "std[action_prob] 0.068100594\n",
      "max game len 3\n",
      "epoch 16 completed\n",
      "std[action_prob] 0.058864854\n",
      "max game len 3\n",
      "epoch 17 completed\n",
      "std[action_prob] 0.046284944\n",
      "max game len 4\n",
      "epoch 18 completed\n",
      "std[action_prob] 0.05524922\n",
      "max game len 2\n",
      "epoch 19 completed\n",
      "std[action_prob] 0.0525366\n",
      "max game len 2\n",
      "epoch 20 completed\n",
      "std[action_prob] 0.06363279\n",
      "max game len 3\n",
      "epoch 21 completed\n",
      "std[action_prob] 0.04530602\n",
      "max game len 4\n",
      "epoch 22 completed\n",
      "std[action_prob] 0.033874534\n",
      "max game len 3\n",
      "epoch 23 completed\n",
      "std[action_prob] 0.069012746\n",
      "max game len 3\n",
      "epoch 24 completed\n",
      "std[action_prob] 0.07368438\n",
      "max game len 3\n",
      "epoch 25 completed\n",
      "std[action_prob] 0.078985505\n",
      "max game len 3\n",
      "epoch 26 completed\n",
      "std[action_prob] 0.034809638\n",
      "max game len 3\n",
      "epoch 27 completed\n",
      "std[action_prob] 0.08556542\n",
      "max game len 3\n",
      "epoch 28 completed\n",
      "std[action_prob] 0.0867074\n",
      "max game len 3\n",
      "epoch 29 completed\n",
      "std[action_prob] 0.0817158\n",
      "max game len 3\n",
      "epoch 30 completed\n",
      "std[action_prob] 0.10002752\n",
      "max game len 4\n",
      "epoch 31 completed\n",
      "std[action_prob] 0.03656429\n",
      "max game len 3\n",
      "epoch 32 completed\n",
      "std[action_prob] 0.09947675\n",
      "max game len 3\n",
      "epoch 33 completed\n",
      "std[action_prob] 0.105390415\n",
      "max game len 3\n",
      "epoch 34 completed\n",
      "std[action_prob] 0.06295211\n",
      "max game len 4\n",
      "epoch 35 completed\n",
      "std[action_prob] 0.101896405\n",
      "max game len 4\n",
      "epoch 36 completed\n",
      "std[action_prob] 0.056928962\n",
      "max game len 4\n",
      "epoch 37 completed\n",
      "std[action_prob] 0.076322116\n",
      "max game len 3\n",
      "epoch 38 completed\n",
      "std[action_prob] 0.09146746\n",
      "max game len 3\n",
      "epoch 39 completed\n",
      "std[action_prob] 0.08189659\n",
      "max game len 5\n",
      "epoch 40 completed\n",
      "std[action_prob] 0.08401103\n",
      "max game len 3\n",
      "epoch 41 completed\n",
      "std[action_prob] 0.092110746\n",
      "max game len 4\n",
      "epoch 42 completed\n",
      "std[action_prob] 0.056227043\n",
      "max game len 4\n",
      "epoch 43 completed\n",
      "std[action_prob] 0.09830086\n",
      "max game len 5\n",
      "epoch 44 completed\n",
      "std[action_prob] 0.10548283\n",
      "max game len 4\n",
      "epoch 45 completed\n",
      "std[action_prob] 0.101941094\n",
      "max game len 4\n",
      "epoch 46 completed\n",
      "std[action_prob] 0.06808178\n",
      "max game len 4\n",
      "epoch 47 completed\n",
      "std[action_prob] 0.11938339\n",
      "max game len 6\n",
      "epoch 48 completed\n",
      "std[action_prob] 0.10656573\n",
      "max game len 6\n",
      "epoch 49 completed\n",
      "std[action_prob] 0.119301915\n",
      "max game len 4\n",
      "epoch 50 completed\n",
      "std[action_prob] 0.05515977\n",
      "max game len 5\n",
      "epoch 51 completed\n",
      "std[action_prob] 0.13163823\n",
      "max game len 15\n",
      "epoch 52 completed\n",
      "std[action_prob] 0.10886931\n",
      "max game len 7\n",
      "epoch 53 completed\n",
      "std[action_prob] 0.035264365\n",
      "max game len 4\n",
      "epoch 54 completed\n",
      "std[action_prob] 0.12232223\n",
      "max game len 7\n",
      "epoch 55 completed\n",
      "std[action_prob] 0.13228482\n",
      "max game len 18\n",
      "epoch 56 completed\n",
      "std[action_prob] 0.13004571\n",
      "max game len 10\n",
      "epoch 57 completed\n",
      "std[action_prob] 0.0431152\n",
      "max game len 4\n",
      "epoch 58 completed\n",
      "std[action_prob] 0.1110121\n",
      "max game len 6\n",
      "epoch 59 completed\n",
      "std[action_prob] 0.06577958\n",
      "max game len 7\n",
      "epoch 60 completed\n",
      "std[action_prob] 0.042743698\n",
      "max game len 4\n",
      "epoch 61 completed\n",
      "std[action_prob] 0.051013906\n",
      "max game len 5\n",
      "epoch 62 completed\n",
      "std[action_prob] 0.12867099\n",
      "max game len 9\n",
      "epoch 63 completed\n",
      "[{'previous_layer_a': 0, 'previous_layer_b': None, 'merge_method': 'mul_1-sigmoid(a)'}, {'previous_layer_a': 1, 'previous_layer_b': None, 'merge_method': 'mul_sigmoid(a)'}, {'previous_layer_a': 1, 'previous_layer_b': 2, 'merge_method': 'add'}, {'previous_layer_a': 2, 'previous_layer_b': 0, 'merge_method': 'mul_sigmoid(a)'}, {'previous_layer_a': 2, 'previous_layer_b': 0, 'merge_method': 'add'}, {'previous_layer_a': 0, 'previous_layer_b': 4, 'merge_method': 'add'}]\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "replays = []\n",
    "for i in range(500):\n",
    "    samples = play(env, m, max_steps=env.N*3*3,\n",
    "        n_prev_states=env_prev_states, verbose=True)\n",
    "    m.train(samples, epochs=1, verbose=True)\n",
    "    print('epoch {} completed'.format(i+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
