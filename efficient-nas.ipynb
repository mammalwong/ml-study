{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import collections\n",
    "import multiprocessing\n",
    "import inspect\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    input_size = 8\n",
    "    output_size = input_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_weights(N):\n",
    "        weights = {}\n",
    "        weights['top'] = {\n",
    "            'kernel': K.eval(keras.initializers.he_normal()((64,10))),\n",
    "            'bias': K.eval(keras.initializers.zeros()((10,)))}\n",
    "        l_size_last = 3\n",
    "        for l in range(5):\n",
    "            l_size = 2**(2+l)\n",
    "            weights[(l,'pre')] = {\n",
    "                'kernel': K.eval(keras.initializers.he_normal()(\n",
    "                    (1,1,l_size_last,l_size))),\n",
    "                'bias': K.eval(keras.initializers.zeros()((l_size,)))}\n",
    "            for i in range(N+1):\n",
    "                for j in range(i+1,N+1):\n",
    "                    weights[(l,i,j)] = {\n",
    "                        'kernel': K.eval(keras.initializers.he_normal()(\n",
    "                            (3,3,l_size,l_size))),\n",
    "                        'bias': K.eval(keras.initializers.zeros()((l_size,)))}\n",
    "            l_size_last = l_size\n",
    "        return weights\n",
    "        \n",
    "    @staticmethod\n",
    "    def run(instructions, weights):\n",
    "        (X_train,Y_train),(X_test,Y_test) = keras.datasets.cifar10.load_data()\n",
    "        X_train, X_test = X_train/255-0.5, X_test/255-0.5\n",
    "        X_train_idx = np.random.randint(0, high=X_train.shape[0], size=(4000,))\n",
    "        X_train,Y_train = X_train[X_train_idx], Y_train[X_train_idx]\n",
    "        X_test_idx = np.random.randint(0, high=X_test.shape[0], size=(1000,))\n",
    "        X_test,Y_test = X_test[X_test_idx], Y_test[X_test_idx]\n",
    "        X = X_input = keras.layers.Input(X_train.shape[1:])\n",
    "        weights_update = {}\n",
    "        for l in range(5):\n",
    "            w = weights[(l,'pre')]\n",
    "            o = keras.layers.Conv2D(\n",
    "                w['kernel'].shape[-1],\n",
    "                w['kernel'].shape[:2],\n",
    "                padding='same',\n",
    "                kernel_initializer=keras.initializers.constant(value=w['kernel']),\n",
    "                bias_initializer=keras.initializers.constant(value=w['bias']))\n",
    "            weights_update[(l,'pre')] = o\n",
    "            X = o(X)\n",
    "            layers = {0:X}\n",
    "            connected = set()\n",
    "            for i,ins in enumerate(instructions):\n",
    "                previous_layer_a_idx = ins['previous_layer_a']\n",
    "                if previous_layer_a_idx is not None:\n",
    "                    connected.add(previous_layer_a_idx)\n",
    "                    w = weights[(l,previous_layer_a_idx,i+1)]\n",
    "                    previous_layer_a = layers[previous_layer_a_idx]\n",
    "                    o = keras.layers.Conv2D(\n",
    "                        w['kernel'].shape[-1],\n",
    "                        w['kernel'].shape[:2],\n",
    "                        padding='same',\n",
    "                        kernel_initializer= \\\n",
    "                            keras.initializers.constant(value=w['kernel']),\n",
    "                        bias_initializer= \\\n",
    "                            keras.initializers.constant(value=w['bias']))\n",
    "                    weights_update[(l,previous_layer_a_idx,i+1)] = o\n",
    "                    previous_layer_a = o(previous_layer_a)\n",
    "                previous_layer_b_idx = ins['previous_layer_b']\n",
    "                if previous_layer_b_idx is not None and \\\n",
    "                    previous_layer_b_idx == previous_layer_a_idx:\n",
    "                    previous_layer_b = previous_layer_a\n",
    "                elif previous_layer_b_idx is not None:\n",
    "                    connected.add(previous_layer_b_idx)\n",
    "                    w = weights[(l,previous_layer_b_idx,i+1)]\n",
    "                    previous_layer_b = layers[previous_layer_b_idx]\n",
    "                    o = keras.layers.Conv2D(\n",
    "                        w['kernel'].shape[-1],\n",
    "                        w['kernel'].shape[:2],\n",
    "                        padding='same',\n",
    "                        kernel_initializer= \\\n",
    "                            keras.initializers.constant(value=w['kernel']),\n",
    "                        bias_initializer= \\\n",
    "                            keras.initializers.constant(value=w['bias']))\n",
    "                    weights_update[(l,previous_layer_b_idx,i+1)] = o\n",
    "                    previous_layer_b = o(previous_layer_b)\n",
    "                if previous_layer_a_idx is None and \\\n",
    "                    previous_layer_b_idx is None:\n",
    "                    continue\n",
    "                if previous_layer_a_idx is not None and \\\n",
    "                    previous_layer_b_idx is not None:\n",
    "                    previous_layer_ab = [previous_layer_a,previous_layer_b]\n",
    "                    merge_method = ins['merge_method']\n",
    "                    if merge_method == 'add':\n",
    "                        X = keras.layers.Add()(previous_layer_ab)\n",
    "                    elif merge_method == 'sub':\n",
    "                        X = keras.layers.Subtract()(previous_layer_ab)\n",
    "                    elif merge_method == 'mul':\n",
    "                        X = keras.layers.Multiply()(previous_layer_ab)\n",
    "                    elif merge_method == 'mul_sigmoid(a)':\n",
    "                        X = keras.layers.Multiply()([\n",
    "                            keras.layers.Lambda(lambda x: K.sigmoid(x))(previous_layer_a),\n",
    "                            previous_layer_b])\n",
    "                    elif merge_method == 'mul_1-sigmoid(a)':\n",
    "                        X = keras.layers.Multiply()([\n",
    "                            keras.layers.Lambda(lambda x: 1.-K.sigmoid(x))(previous_layer_a),\n",
    "                            previous_layer_b])\n",
    "                    elif merge_method == 'avg':\n",
    "                        X = keras.layers.Average()(previous_layer_ab)\n",
    "                    else:\n",
    "                        raise Exception('unknown merge method')\n",
    "                elif previous_layer_a_idx is not None:\n",
    "                    X = previous_layer_a\n",
    "                elif previous_layer_b_idx is not None:\n",
    "                    X = previous_layer_b\n",
    "                X = keras.layers.BatchNormalization()(X)\n",
    "                X = keras.layers.Activation('relu')(X)\n",
    "                layers[i+1] = X\n",
    "            not_connected = set(layers.keys()) - connected\n",
    "            not_connected = [layers[nc] for nc in not_connected]\n",
    "            if not not_connected:\n",
    "                raise Exception('no output')\n",
    "            elif len(not_connected) == 1:\n",
    "                X = list(not_connected)[0]\n",
    "            else:\n",
    "                X = keras.layers.Average()(list(not_connected))\n",
    "            X = keras.layers.MaxPooling2D()(X)\n",
    "        X = keras.layers.GlobalAveragePooling2D()(X)\n",
    "        w = weights['top']\n",
    "        o = keras.layers.Dense(\n",
    "            w['kernel'].shape[-1],\n",
    "            kernel_initializer=keras.initializers.constant(value=w['kernel']),\n",
    "            bias_initializer=keras.initializers.constant(value=w['bias']),\n",
    "            activation='softmax')\n",
    "        weights_update['top'] = o\n",
    "        X = o(X)\n",
    "        M = keras.Model(X_input, X)\n",
    "        M_optimizer = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "        M.compile(M_optimizer, 'sparse_categorical_crossentropy', ['acc'])\n",
    "        hist = M.fit(\n",
    "            X_train, Y_train,\n",
    "            validation_data=(X_test,Y_test),\n",
    "            batch_size=64, epochs=1)\n",
    "        score = hist.history['val_acc'][-1]\n",
    "        score = score**2 * 100 if score == score else 0.\n",
    "        for k,v in weights_update.items():\n",
    "            w = v.get_weights()\n",
    "            if not np.any(np.isnan(w[0])):\n",
    "                weights[k]['kernel'] = w[0]\n",
    "            if not np.any(np.isnan(w[1])):\n",
    "                weights[k]['bias'] = w[1]\n",
    "        return score, weights\n",
    "    \n",
    "    def __init__(self, N=6):\n",
    "        self.N = N\n",
    "        p = multiprocessing.Pool(processes=1)\n",
    "        try:\n",
    "            self.weights = p.apply(__class__.create_weights, [self.N])\n",
    "        finally:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "        self.reset()\n",
    "    \n",
    "    def run_in_process(self, instructions):\n",
    "        print(instructions)\n",
    "        p = multiprocessing.Pool(processes=1)\n",
    "        try:\n",
    "            score, weights = p.apply(\n",
    "                __class__.run,\n",
    "                [instructions, self.weights])\n",
    "        except:\n",
    "            score, weights = 0., self.weights\n",
    "        finally:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "        self.weights = weights\n",
    "        return score\n",
    "    \n",
    "    def reset(self):\n",
    "        self.actions = []\n",
    "        self.instructions = []\n",
    "        self.planned_layers = {0}\n",
    "        return np.zeros((__class__.output_size,))\n",
    "    \n",
    "    def step(self, action):\n",
    "        result = np.zeros((__class__.output_size),)\n",
    "        result[action] = 1\n",
    "        if len(self.actions) < 3*self.N:\n",
    "            try:\n",
    "                if len(self.actions) % 3 == 0:\n",
    "                    self.instructions.append({})\n",
    "                    if action < len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_a'] = action\n",
    "                        if action not in self.planned_layers:\n",
    "                            raise Exception()\n",
    "                        self.planned_layers.add(len(self.instructions))\n",
    "                    elif action == len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_a'] = None\n",
    "                    else:\n",
    "                        raise Exception()\n",
    "                elif len(self.actions) % 3 == 1:\n",
    "                    if action < len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_b'] = action\n",
    "                        if action not in self.planned_layers:\n",
    "                            raise Exception()\n",
    "                        self.planned_layers.add(len(self.instructions))\n",
    "                    elif action == len(self.instructions):\n",
    "                        self.instructions[-1]['previous_layer_b'] = None\n",
    "                    else:\n",
    "                        raise Exception()\n",
    "                elif len(self.actions) % 3 == 2:\n",
    "                    self.instructions[-1]['merge_method'] = \\\n",
    "                        ['add','sub','mul','avg', \\\n",
    "                        'mul_sigmoid(a)','mul_1-sigmoid(a)'][action]\n",
    "            except:\n",
    "                if len(self.actions)+1 == 3*self.N:\n",
    "                    pass\n",
    "                else:\n",
    "                    return result, -100., True, {}\n",
    "            finally:\n",
    "                self.actions.append(action)\n",
    "        if len(self.actions) >= 3*self.N:\n",
    "            score = self.run_in_process(self.instructions)\n",
    "            return result, score if score > 0. else -100., True, {}\n",
    "        return result, 1., False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Env()\n",
    "env_input_size = Env.input_size\n",
    "env_output_size = Env.output_size\n",
    "env_prev_states = env.N * 3\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model_Sample = collections.namedtuple('Model_Sample',\n",
    "    ['state', 'action', 'reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller:\n",
    "    \n",
    "    def __init__(self, input_n, output_n, beta=0.0001):\n",
    "        \n",
    "        self.__input_n = input_n\n",
    "        self.__output_n = output_n\n",
    "        self.__l_shared = [\n",
    "            keras.layers.LSTM(8, return_sequences=True),\n",
    "            keras.layers.LSTM(8, return_sequences=False)]\n",
    "        self.__l_policy = [\n",
    "            keras.layers.Dense(8, kernel_initializer='he_uniform'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dense(self.__output_n),\n",
    "            keras.layers.Softmax()]\n",
    "        self.__l_value = [\n",
    "            keras.layers.Dense(8, kernel_initializer='he_uniform'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dense(1)]\n",
    "        def apply_layers(x, layers):\n",
    "            last_layer = x\n",
    "            for l in layers:\n",
    "                last_layer = l(last_layer)\n",
    "            return last_layer\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m = apply_layers(m, self.__l_shared)\n",
    "        m = apply_layers(m, self.__l_policy)\n",
    "        self.__m_policy = keras.models.Model([m_input], [m])\n",
    "        self.__m_policy.compile('adam', 'mse')\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m = apply_layers(m, self.__l_shared)\n",
    "        m = apply_layers(m, self.__l_value)\n",
    "        self.__m_value = keras.models.Model([m_input], [m])\n",
    "        self.__m_value.compile('adam', 'mse')\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m_shared = apply_layers(m, self.__l_shared)\n",
    "        m_policy = apply_layers(m_shared, self.__l_policy)\n",
    "        m_value = apply_layers(m_shared, self.__l_value)\n",
    "        self.__m_value_policy = keras.models.Model([m_input], [m_value, m_policy])\n",
    "        self.__m_value_policy.compile('adam', 'mse')\n",
    "        \n",
    "        m = m_input = keras.layers.Input((None, self.__input_n,))\n",
    "        m_value, m_policy = self.__m_value_policy(m)\n",
    "        m = keras.layers.Concatenate()([m_value, m_policy])\n",
    "        self.__m_optimizer = keras.optimizers.Nadam(clipnorm=5.)\n",
    "        self.__m_train = keras.models.Model([m_input], [m])\n",
    "        self.__m_train.compile(self.__m_optimizer,\n",
    "            lambda y_true, y_pred: __class__.__loss(y_true, y_pred, beta))\n",
    "        \n",
    "        self.__m_policy.summary()\n",
    "        self.__m_value.summary()\n",
    "        self.__m_train.summary()\n",
    "    \n",
    "    @staticmethod\n",
    "    def __loss(y_true, y_pred, beta):\n",
    "        r, action_onehot = y_true[:,:1], y_true[:,1:]\n",
    "        value, policy = y_pred[:,:1], y_pred[:,1:]\n",
    "        advantage = r - value\n",
    "        log_policy = K.log(policy + K.epsilon())\n",
    "        log_choosen_action_prob = K.sum(action_onehot * log_policy, axis=-1, keepdims=True)\n",
    "        action_loss = -K.mean(log_choosen_action_prob * advantage)\n",
    "        value_loss = 0.5 * K.mean(K.square(advantage))\n",
    "        entropy = K.mean(-K.sum(policy * log_policy, axis=-1, keepdims=True))\n",
    "        return action_loss + value_loss - beta * entropy\n",
    "    \n",
    "    def train(self, samples, epochs=1, verbose=False):\n",
    "        self.__m_train.fit(\n",
    "            x=np.array([s.state for s in samples], dtype=np.float32),\n",
    "            y=np.hstack([\n",
    "                np.reshape(np.array([s.reward for s in samples], dtype=np.float32), (-1, 1)),\n",
    "                keras.utils.to_categorical([s.action for s in samples], num_classes=self.__output_n)]),\n",
    "            batch_size=64,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose)\n",
    "    \n",
    "    def evalute_value(self, state, verbose=False):\n",
    "        v = self.__m_value.predict(\n",
    "            np.array([state], dtype=np.float32))[0,0]\n",
    "        if verbose:\n",
    "            print(v)\n",
    "        return v\n",
    "    \n",
    "    def get_action_prob(self, state, verbose=False):\n",
    "        action_prob = self.__m_policy.predict(\n",
    "            np.array([state], dtype=np.float32))[0]\n",
    "        if verbose:\n",
    "            print(action_prob)\n",
    "        return action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiprocessController:\n",
    "    \n",
    "    @staticmethod\n",
    "    def run(pipe, init_args, init_kwargs):\n",
    "        import os\n",
    "        # enforce to run on cpu\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "        controller = Controller(*init_args, **init_kwargs)\n",
    "        pipe.send('controller inited')\n",
    "        while True:\n",
    "            cmd = pipe.recv()\n",
    "            if cmd[0] == 'train':\n",
    "                pipe.send(controller.train(*cmd[1], **cmd[2]))\n",
    "            elif cmd[0] == 'evalute_value':\n",
    "                pipe.send(controller.evalute_value(*cmd[1], **cmd[2]))\n",
    "            elif cmd[0] == 'get_action_prob':\n",
    "                pipe.send(controller.get_action_prob(*cmd[1], **cmd[2]))\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pipe_l, pipe_r = multiprocessing.Pipe(duplex=True)\n",
    "        self.pipe = pipe_l\n",
    "        self.process = multiprocessing.Process(\n",
    "            target=__class__.run,\n",
    "            args=[pipe_r, args, kwargs],\n",
    "            daemon=True)\n",
    "        self.process.start()\n",
    "        print(self.pipe.recv())\n",
    "    \n",
    "    def train(self, *args, **kwargs):\n",
    "        self.pipe.send(('train', args, kwargs))\n",
    "        return self.pipe.recv()\n",
    "        \n",
    "    def evalute_value(self, *args, **kwargs):\n",
    "        self.pipe.send(('evalute_value', args, kwargs))\n",
    "        return self.pipe.recv()\n",
    "        \n",
    "    def get_action_prob(self, *args, **kwargs):\n",
    "        self.pipe.send(('get_action_prob', args, kwargs))\n",
    "        return self.pipe.recv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play(env, m, gamma=0.98, max_steps=1000, n_prev_states=8, verbose=False):\n",
    "    state_0 = env.reset()\n",
    "    state_null = np.zeros_like(state_0)\n",
    "    state_queue = []\n",
    "    episode = []\n",
    "    samples = []\n",
    "    action_probs = []\n",
    "    gamelen = 0\n",
    "    gamelen_max = 0\n",
    "    def get_prev_states(episode, idx):\n",
    "        states = [e.state for e in episode[(idx-n_prev_states)+1:idx+1]]\n",
    "        states = [state_null]*(max(0,n_prev_states-len(states))) + states\n",
    "        return states\n",
    "    def add_to_samples(episode, done):\n",
    "        if done:\n",
    "            discounted_reward = 0.\n",
    "        else:\n",
    "            discounted_reward = m.evalute_value(get_prev_states(episode, len(episode)-1))\n",
    "        episode[-1] = Model_Sample(\n",
    "                get_prev_states(episode, len(episode)-1),\n",
    "                episode[-1].action,\n",
    "                discounted_reward)\n",
    "        for i in reversed(range(len(episode)-1)):\n",
    "            discounted_reward = episode[i].reward + \\\n",
    "                gamma * discounted_reward\n",
    "            episode[i] = Model_Sample(\n",
    "                get_prev_states(episode, i),\n",
    "                episode[i].action,\n",
    "                discounted_reward)\n",
    "        samples.extend(episode)\n",
    "    for i in range(max_steps):\n",
    "        state_queue.append(state_0)\n",
    "        if len(state_queue) > n_prev_states:\n",
    "            state_queue.pop(0)\n",
    "        state_queue_padded = \\\n",
    "            [state_null]*(max(0,n_prev_states-len(state_queue))) + state_queue\n",
    "        action_prob = m.get_action_prob(state_queue_padded)\n",
    "        action_probs.append(action_prob)\n",
    "        action = int(np.random.choice(\n",
    "            list(range(action_prob.shape[-1])),\n",
    "            p=action_prob))\n",
    "        state_1, reward, done, _ = env.step(action)\n",
    "        episode.append(Model_Sample(state_0, action, reward))\n",
    "        state_0 = state_1\n",
    "        gamelen += 1\n",
    "        if done:\n",
    "            add_to_samples(episode, True)\n",
    "            episode = []\n",
    "            state_0 = env.reset()\n",
    "            state_null = np.zeros_like(state_0)\n",
    "            state_queue = []\n",
    "            gamelen_max = max(gamelen_max, gamelen)\n",
    "            gamelen = 0\n",
    "    if episode:\n",
    "        add_to_samples(episode, False)\n",
    "        gamelen_max = max(gamelen_max, gamelen)\n",
    "        gamelen = 0\n",
    "    if verbose:\n",
    "        print('std[action_prob]', np.mean(np.std(action_probs, ddof=1, axis=0)))\n",
    "        print('max game len', gamelen_max)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 8)           544       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 1,264\n",
      "Trainable params: 1,248\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 8)           544       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,185\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, 8)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 [(None, 1), (None, 8 1377        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9)            0           model_3[1][0]                    \n",
      "                                                                 model_3[1][1]                    \n",
      "==================================================================================================\n",
      "Total params: 1,377\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n",
      "controller inited\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.8508\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 452us/step - loss: 1.2198\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 375us/step - loss: 0.6252\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 407us/step - loss: 3.0960\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 438us/step - loss: 1.3666\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 367us/step - loss: 1.1499\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 486us/step - loss: 1.6372\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 402us/step - loss: 2.7466\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 341us/step - loss: 1.1557\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 408us/step - loss: 1.1587\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 394us/step - loss: 0.6651\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 456us/step - loss: 0.3190\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 396us/step - loss: 1.1015\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 394us/step - loss: 0.7740\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 452us/step - loss: 0.8237\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 373us/step - loss: 0.7229\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 297us/step - loss: 0.7246\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 452us/step - loss: 0.7546\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 417us/step - loss: 4.4508\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 356us/step - loss: 3.2046\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 468us/step - loss: 3.7341\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 442us/step - loss: 6.1212\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 415us/step - loss: 4.2969\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 338us/step - loss: 3.2492\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 396us/step - loss: 3.2416\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 296us/step - loss: 2.6468\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 482us/step - loss: 9.0381\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 350us/step - loss: 11.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-1504eed81e49>\", line 12, in run\n",
      "    cmd = pipe.recv()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "m = MultiprocessController(env_output_size, env_input_size, beta=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std[action_prob] 0.000418861\n",
      "max game len 4\n",
      "epoch 1 completed\n",
      "std[action_prob] 0.023231499\n",
      "max game len 5\n",
      "epoch 2 completed\n",
      "std[action_prob] 0.018206533\n",
      "max game len 4\n",
      "epoch 3 completed\n",
      "std[action_prob] 0.032376364\n",
      "max game len 11\n",
      "epoch 4 completed\n",
      "std[action_prob] 0.019401873\n",
      "max game len 4\n",
      "epoch 5 completed\n",
      "std[action_prob] 0.02163184\n",
      "max game len 5\n",
      "epoch 6 completed\n",
      "std[action_prob] 0.032833874\n",
      "max game len 7\n",
      "epoch 7 completed\n",
      "std[action_prob] 0.037556794\n",
      "max game len 10\n",
      "epoch 8 completed\n",
      "std[action_prob] 0.014217481\n",
      "max game len 3\n",
      "epoch 9 completed\n",
      "std[action_prob] 0.036053143\n",
      "max game len 5\n",
      "epoch 10 completed\n",
      "std[action_prob] 0.007757026\n",
      "max game len 2\n",
      "epoch 11 completed\n",
      "std[action_prob] 0.00756442\n",
      "max game len 2\n",
      "epoch 12 completed\n",
      "std[action_prob] 0.034670718\n",
      "max game len 7\n",
      "epoch 13 completed\n",
      "std[action_prob] 0.014230322\n",
      "max game len 4\n",
      "epoch 14 completed\n",
      "std[action_prob] 0.02109296\n",
      "max game len 5\n",
      "epoch 15 completed\n",
      "std[action_prob] 0.016026655\n",
      "max game len 4\n",
      "epoch 16 completed\n",
      "std[action_prob] 0.01822944\n",
      "max game len 5\n",
      "epoch 17 completed\n",
      "std[action_prob] 0.014935682\n",
      "max game len 4\n",
      "epoch 18 completed\n",
      "std[action_prob] 0.04702601\n",
      "max game len 12\n",
      "epoch 19 completed\n",
      "std[action_prob] 0.03863238\n",
      "max game len 6\n",
      "epoch 20 completed\n",
      "std[action_prob] 0.04814043\n",
      "max game len 10\n",
      "epoch 21 completed\n",
      "std[action_prob] 0.06815329\n",
      "max game len 12\n",
      "epoch 22 completed\n",
      "std[action_prob] 0.043575123\n",
      "max game len 8\n",
      "epoch 23 completed\n",
      "std[action_prob] 0.045866095\n",
      "max game len 7\n",
      "epoch 24 completed\n",
      "std[action_prob] 0.037442937\n",
      "max game len 7\n",
      "epoch 25 completed\n",
      "std[action_prob] 0.040787335\n",
      "max game len 6\n",
      "epoch 26 completed\n",
      "[{'previous_layer_a': 0, 'previous_layer_b': None, 'merge_method': 'sub'}, {'previous_layer_a': 0, 'previous_layer_b': 0, 'merge_method': 'add'}, {'previous_layer_a': 0, 'previous_layer_b': 0, 'merge_method': 'add'}, {'previous_layer_a': None, 'previous_layer_b': 0, 'merge_method': 'add'}, {'previous_layer_a': 2, 'previous_layer_b': 4, 'merge_method': 'mul_sigmoid(a)'}, {'previous_layer_a': 2, 'previous_layer_b': 1, 'merge_method': 'mul'}]\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 2.3255 - acc: 0.1542 - val_loss: 3.6402 - val_acc: 0.1490\n",
      "std[action_prob] 0.077774376\n",
      "max game len 18\n",
      "epoch 27 completed\n",
      "[{'previous_layer_a': 0, 'previous_layer_b': None, 'merge_method': 'sub'}, {'previous_layer_a': 0, 'previous_layer_b': 0, 'merge_method': 'add'}, {'previous_layer_a': 1, 'previous_layer_b': 0, 'merge_method': 'mul'}, {'previous_layer_a': 2, 'previous_layer_b': None, 'merge_method': 'mul_sigmoid(a)'}, {'previous_layer_a': None, 'previous_layer_b': 2, 'merge_method': 'add'}, {'previous_layer_a': 0, 'previous_layer_b': 2, 'merge_method': 'mul'}]\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 2.2697 - acc: 0.1530 - val_loss: 2.3378 - val_acc: 0.1730\n",
      "std[action_prob] 0.07601799\n",
      "max game len 18\n",
      "epoch 28 completed\n",
      "[{'previous_layer_a': 0, 'previous_layer_b': None, 'merge_method': 'sub'}, {'previous_layer_a': 0, 'previous_layer_b': None, 'merge_method': 'avg'}, {'previous_layer_a': 0, 'previous_layer_b': 0, 'merge_method': 'add'}, {'previous_layer_a': 0, 'previous_layer_b': 2, 'merge_method': 'add'}, {'previous_layer_a': 2, 'previous_layer_b': 0, 'merge_method': 'mul'}, {'previous_layer_a': 0, 'previous_layer_b': 0, 'merge_method': 'mul_1-sigmoid(a)'}]\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 12s 3ms/step - loss: 2.1695 - acc: 0.1953 - val_loss: 2.1337 - val_acc: 0.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-2-1e18f89191f0>\", line 141, in run\n",
      "    w = v.get_weights()\n",
      "  File \"/home/marco/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 1068, in get_weights\n",
      "    return K.batch_get_value(params)\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9b0710563b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     samples = play(env, m, max_steps=env.N*3*3,\n\u001b[0;32m----> 4\u001b[0;31m         n_prev_states=env_prev_states, verbose=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mreplays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f474d9d40ac1>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(env, m, gamma, max_steps, n_prev_states, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mstate_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mstate_queue_padded\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mstate_null\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_prev_states\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstate_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0maction_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_queue_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0maction_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         action = int(np.random.choice(\n",
      "\u001b[0;32m<ipython-input-6-1504eed81e49>\u001b[0m in \u001b[0;36mget_action_prob\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get_action_prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# Also note we want to avoid sending a 0-length buffer separately,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mremaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "replays = []\n",
    "for i in range(500):\n",
    "    samples = play(env, m, max_steps=env.N*3*3,\n",
    "        n_prev_states=env_prev_states, verbose=True)\n",
    "    replays.extend(samples)\n",
    "    m.train(replays, epochs=1, verbose=True)\n",
    "    if len(replays) > env.N*3*3:\n",
    "        random.shuffle(replays)\n",
    "        replays = list(replays[:env.N*3*3])\n",
    "    print('epoch {} completed'.format(i+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
