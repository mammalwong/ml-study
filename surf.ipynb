{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import numpy as np\n",
    "import PIL\n",
    "import cv2\n",
    "import cv2.xfeatures2d\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_path_itr(keyword):\n",
    "    dir_ = 'downloads/{}/'.format(keyword)\n",
    "    for f in os.listdir(dir_):\n",
    "        if not f.endswith('.jpg'):\n",
    "            continue\n",
    "        yield dir_ + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pil_image_to_numpy(im):\n",
    "    im = np.array(im.convert('RGB'), dtype=np.uint8)[:,:,::-1]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(keyword):\n",
    "    surf = cv2.xfeatures2d.SURF_create(10000)\n",
    "    features = []\n",
    "    for p in image_path_itr(keyword):\n",
    "        try:\n",
    "            im = pil_image_to_numpy(PIL.Image.open(p))\n",
    "            f = surf.detectAndCompute(im, None)\n",
    "            if not f[0]:\n",
    "                continue\n",
    "            features.append(f)\n",
    "        except:\n",
    "            pass\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = \\\n",
    "    [(f, 0) for f in extract_features('dragonfly')] + \\\n",
    "    [(f, 1) for f in extract_features('butterfly')]\n",
    "random.shuffle(samples)\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_samples = samples[:-40]\n",
    "valid_samples = samples[-40:]\n",
    "train_X = [s[0][1] for s in train_samples]\n",
    "train_Y = [keras.utils.to_categorical(s[1], num_classes=2) for s in train_samples]\n",
    "valid_X = [s[0][1] for s in valid_samples]\n",
    "valid_Y = [keras.utils.to_categorical(s[1], num_classes=2) for s in valid_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 64)     256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 256)    16640       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 128)    32896       time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 1)      129         time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, None, 1)      0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           softmax_1[0][0]                  \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            258         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50,179\n",
      "Trainable params: 50,051\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "X = X_input = keras.layers.Input((None, 64))\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "#X = keras.layers.Dropout(0.5)(X)\n",
    "X = keras.layers.TimeDistributed(keras.layers.Dense(256, activation='relu'))(X)\n",
    "X = X_desc = keras.layers.TimeDistributed(keras.layers.Dense(128, activation='relu'))(X)\n",
    "X = keras.layers.TimeDistributed(keras.layers.Dense(1, activation='relu'))(X)\n",
    "X = keras.layers.Softmax(axis=1)(X)\n",
    "X = keras.layers.Dot(1)([X, X_desc])\n",
    "X = keras.layers.Flatten()(X)\n",
    "X = keras.layers.Dense(2, activation='softmax')(X)\n",
    "M = keras.models.Model([X_input], [X])\n",
    "M.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predicting ratio on valid. set 0.675\n",
      "correct predicting ratio on valid. set 0.825\n",
      "correct predicting ratio on valid. set 0.85\n",
      "correct predicting ratio on valid. set 0.725\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.825\n",
      "correct predicting ratio on valid. set 0.775\n",
      "correct predicting ratio on valid. set 0.85\n",
      "correct predicting ratio on valid. set 0.875\n",
      "correct predicting ratio on valid. set 0.875\n",
      "correct predicting ratio on valid. set 0.875\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.9\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n",
      "correct predicting ratio on valid. set 0.925\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    trainning_set = list(zip(train_X, train_Y))\n",
    "    random.shuffle(trainning_set)\n",
    "    for X, Y in trainning_set:\n",
    "        M.fit(\n",
    "            np.expand_dims(X, axis=0),\n",
    "            np.expand_dims(Y, axis=0),\n",
    "            batch_size=1, verbose=False)\n",
    "    n_correct = 0\n",
    "    for X, Y in zip(valid_X, valid_Y):\n",
    "        pred = M.predict(\n",
    "            np.expand_dims(X, axis=0),\n",
    "            batch_size=1)[0]\n",
    "        if np.sum(pred * Y) > 0.5:\n",
    "            n_correct += 1\n",
    "    print('correct predicting ratio on valid. set', n_correct / len(valid_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
