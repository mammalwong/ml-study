{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marco/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to /home/marco/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to /home/marco/nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/marco/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to /home/marco/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('webtext')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('brown')\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for fileid in nltk.corpus.webtext.fileids():\n",
    "    data.extend(nltk.corpus.webtext.sents(fileid))\n",
    "for fileid in nltk.corpus.nps_chat.fileids():\n",
    "    data.extend(nltk.corpus.nps_chat.posts(fileid))\n",
    "for fileid in nltk.corpus.brown.fileids():\n",
    "    data.extend(nltk.corpus.brown.sents(fileid))\n",
    "for fileid in nltk.corpus.reuters.fileids():\n",
    "    data.extend(nltk.corpus.reuters.sents(fileid))\n",
    "for sent in data:\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = sent[i].lower()\n",
    "words = set()\n",
    "for sent in data:\n",
    "    words.update(sent)\n",
    "word_index_max = len(words)\n",
    "word_index = {w:i+1 for i,w in enumerate(words)}\n",
    "word_lookup = {i+1:w for i,w in enumerate(words)}\n",
    "for sent in data:\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = word_index[sent[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_embedding_dim = 50 #int(round(len(word_index)**(1/4)))\n",
    "best_embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampling_table = keras.preprocessing.sequence.make_sampling_table(word_index_max+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch():\n",
    "    while True:\n",
    "        i = np.random.randint(0, len(data))\n",
    "        ssamples, slabels = keras.preprocessing.sequence.skipgrams(\n",
    "            data[i], word_index_max+1, sampling_table=sampling_table, window_size=4)\n",
    "        if not ssamples:\n",
    "            continue\n",
    "        ssamples = np.array(ssamples)\n",
    "        yield [ssamples[:,0],ssamples[:,1]], np.array(slabels, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marco/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 50)           3734050     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,734,052\n",
      "Trainable params: 3,734,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_input = keras.layers.Input((1,), dtype='int32')\n",
    "X = X_embedding = keras.layers.Embedding(word_index_max+1, best_embedding_dim)(X)\n",
    "X = keras.layers.Flatten()(X)\n",
    "M_embedding = keras.Model(X_input, X)\n",
    "X_input_a = X_a = keras.layers.Input((1,), dtype='int32')\n",
    "X_input_b = X_b = keras.layers.Input((1,), dtype='int32')\n",
    "X_a = M_embedding(X_a)\n",
    "X_b = M_embedding(X_b)\n",
    "X = keras.layers.Dot(-1, normalize=True)([X_a,X_b])\n",
    "X = keras.layers.Dense(1, activation='sigmoid',\n",
    "                       kernel_constraint=keras.constraints.NonNeg())(X)\n",
    "M = keras.Model([X_input_a,X_input_b], X)\n",
    "M.compile('rmsprop', 'binary_crossentropy', ['acc', 'mae'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "148351/148351 [==============================] - 8348s 56ms/step - loss: 0.5659 - acc: 0.7286 - mean_absolute_error: 0.3785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10be1a8908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.fit_generator(generate_batch(), steps_per_epoch=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.save('./models/word-embedding-analogic/model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = keras.models.load_model('./models/word-embedding-analogic/model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = M.get_layer(index=2).get_layer(index=1).get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(a, b, c, use_cos=False):\n",
    "    v_a = embedding[word_index[a]]\n",
    "    v_b = embedding[word_index[b]]\n",
    "    v_c = embedding[word_index[c]]\n",
    "    v_d = v_c + (v_b - v_a)\n",
    "    if use_cos:\n",
    "        cos_sim = np.dot(embedding,\n",
    "            v_d / np.linalg.norm(v_d, axis=-1)) / np.linalg.norm(embedding, axis=-1)\n",
    "        i_d = np.argsort(cos_sim)\n",
    "        return [word_lookup.get(i_d_) for i_d_ in reversed(i_d[-25:])]\n",
    "    else:\n",
    "        norm = np.linalg.norm(embedding - v_d, axis=-1)\n",
    "        i_d = np.argsort(norm)\n",
    "        return [word_lookup.get(i_d_) for i_d_ in i_d[:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rome italy paris france\n",
      "anchorage alaska philadelphia pennsylvania\n",
      "boy girl husband wife\n",
      "brothers sisters he she\n",
      "brothers sisters his her\n",
      "dad mom his her\n",
      "dad mom husband wife\n",
      "father mother his her\n",
      "father mother husband wife\n",
      "grandfather grandmother his her\n",
      "grandfather grandmother boy girl\n",
      "grandfather grandmother father mother\n",
      "grandpa grandma his her\n",
      "grandpa grandma father mother\n",
      "grandson granddaughter his her\n",
      "grandson granddaughter boy girl\n",
      "he she his her\n",
      "his her he she\n",
      "husband wife boy girl\n",
      "king queen his her\n",
      "nephew niece boy girl\n",
      "nephew niece father mother\n",
      "nephew niece his her\n",
      "nephew niece husband wife\n",
      "policeman policewoman boy girl\n",
      "policeman policewoman father mother\n",
      "policeman policewoman his her\n",
      "prince princess boy girl\n",
      "prince princess father mother\n",
      "prince princess his her\n",
      "son daughter his her\n",
      "sons daughters boy girl\n",
      "sons daughters father mother\n",
      "sons daughters his her\n",
      "uncle aunt man woman\n",
      "most mostly lucky luckily\n",
      "possible possibly lucky luckily\n",
      "cheap cheaper good better\n",
      "good better high higher\n",
      "loud louder low lower\n",
      "loud louder good better\n",
      "loud louder high higher\n",
      "low lower high higher\n",
      "smart smarter high higher\n",
      "tight tighter good better\n",
      "tough tougher long longer\n",
      "warm warmer good better\n",
      "wide wider old older\n",
      "bright brightest large largest\n",
      "long longest small smallest\n",
      "weak weakest large largest\n",
      "wide widest high highest\n",
      "wide widest slow slowest\n",
      "code coding run running\n",
      "code coding say saying\n",
      "run running say saying\n",
      "say saying look looking\n",
      "denmark danish france french\n",
      "feeding fed saying said\n",
      "flying flew moving moved\n",
      "going went moving moved\n",
      "hitting hit increasing increased\n",
      "increasing increased falling fell\n",
      "knowing knew saying said\n",
      "looking looked moving moved\n",
      "moving moved going went\n",
      "paying paid increasing increased\n",
      "reading read moving moved\n",
      "saying said falling fell\n",
      "saying said increasing increased\n",
      "seeing saw increasing increased\n",
      "taking took saying said\n",
      "thinking thought falling fell\n",
      "walking walked looking looked\n",
      "building buildings horse horses\n",
      "cat cats banana bananas\n",
      "computer computers horse horses\n",
      "road roads horse horses\n",
      "speak speaks see sees\n"
     ]
    }
   ],
   "source": [
    "with open('./utils/questions-words.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if not line or line[0] == ':':\n",
    "            continue\n",
    "        a, b, c, d = line.strip().lower().split(' ')\n",
    "        if not all((w in word_index) for w in (a,b,c,d)):\n",
    "            continue\n",
    "        pred = test(a, b, c, use_cos=True) + test(a, b, c, use_cos=False)\n",
    "        if d in pred:\n",
    "            print(a, b, c, d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
