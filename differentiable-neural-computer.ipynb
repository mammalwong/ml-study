{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 16), (10000, 8), (1000, 16), (1000, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.random.randint(3, high=16, size=(11000,8))\n",
    "Y_train = np.sort(X_train, axis=-1)\n",
    "X_target = np.copy(Y_train)\n",
    "X_target[:,1:] = X_target[:,:-1]\n",
    "X_target[:,0] = 1\n",
    "X_train = np.concatenate([X_train, X_target], axis=-1)\n",
    "X_train,X_test = X_train[1000:],X_train[:1000]\n",
    "Y_train,Y_test = Y_train[1000:],Y_train[:1000]\n",
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input_dim = max(np.max(X_train), np.max(X_test)) + 1\n",
    "data_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output_dim = max(np.max(Y_train), np.max(Y_test)) + 1\n",
    "data_output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DNCCell(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 word_size,\n",
    "                 memory_size,\n",
    "                 register_size=2,\n",
    "                 write_head_count=2,\n",
    "                 read_head_count=2,\n",
    "                 enable_temporal=True,\n",
    "                 enable_controller_output_resize=True,\n",
    "                 enable_final_bias=True,\n",
    "                 bypass_dropout_factor=None,\n",
    "                 **kwargs):\n",
    "        self.output_size = output_size\n",
    "        self.word_size = word_size\n",
    "        self.memory_size = memory_size\n",
    "        self.register_size = register_size\n",
    "        self.write_head_count = write_head_count\n",
    "        self.read_head_count = read_head_count\n",
    "        self.enable_temporal = enable_temporal\n",
    "        self.enable_controller_output_resize = enable_controller_output_resize\n",
    "        self.enable_final_bias = enable_final_bias\n",
    "        self.bypass_dropout_factor = bypass_dropout_factor\n",
    "        self.state_size = (output_size,)\n",
    "        self.state_size += (register_size * word_size,)\n",
    "        self.state_size += (register_size * word_size,)\n",
    "        self.state_size += (memory_size * word_size,)\n",
    "        self.state_size += (read_head_count * memory_size,)\n",
    "        self.state_size += (read_head_count * word_size,)\n",
    "        self.state_size += (write_head_count * memory_size,)\n",
    "        self.state_size += (memory_size,)\n",
    "        if enable_temporal:\n",
    "            self.state_size += (write_head_count * memory_size,)\n",
    "            self.state_size += (write_head_count * memory_size**2,)\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        read_vec_size = self.word_size * self.read_head_count\n",
    "        controller_input_size = input_shape[-1]\n",
    "        controller_input_size += read_vec_size\n",
    "        controller_input_size += self.register_size*self.word_size\n",
    "        controller_kernel_size = self.register_size*self.word_size*4\n",
    "        controller_hidden_size = self.register_size*self.word_size\n",
    "        interface_vec_size = read_vec_size\n",
    "        interface_vec_size += self.read_head_count*2\n",
    "        if self.enable_temporal:\n",
    "            interface_vec_size += self.read_head_count*3\n",
    "        interface_vec_size += self.write_head_count*self.word_size*3\n",
    "        interface_vec_size += self.write_head_count*3\n",
    "        self.kernel_controller_hidden = self.add_weight(\n",
    "            shape=(controller_input_size, controller_kernel_size),\n",
    "            initializer='glorot_normal', name='kernel_controller_hidden')\n",
    "        self.bias_controller_hidden = self.add_weight(\n",
    "            shape=(controller_kernel_size,),\n",
    "            initializer='zeros', name='bias_controller_hidden')\n",
    "        self.kernel_controller_output = self.add_weight(\n",
    "            shape=(controller_hidden_size, self.output_size + interface_vec_size),\n",
    "            initializer='glorot_normal', name='kernel_controller_output')\n",
    "        self.kernel_read_vec_to_output = self.add_weight(\n",
    "            shape=(read_vec_size, self.output_size),\n",
    "            initializer='glorot_normal', name='kernel_read_vec_to_output')\n",
    "        if self.enable_controller_output_resize:\n",
    "            self.scalar_controller_output_resize = self.add_weight(\n",
    "                shape=(self.output_size,),\n",
    "                initializer='ones', name='scalar_controller_output_resize')\n",
    "        if self.enable_final_bias:\n",
    "            self.bias_final_output = self.add_weight(\n",
    "                shape=(self.output_size,),\n",
    "                initializer='zeros', name='bias_final_output')\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        def oneplus(x):\n",
    "            return K.softplus(x) + 1.\n",
    "        \n",
    "        def similarity(m, k, b):\n",
    "            dot = K.batch_dot(k, m, axes=2)\n",
    "            m_len = K.sqrt(K.sum(K.square(m), axis=-1))\n",
    "            k_len = K.sqrt(K.sum(K.square(k), axis=-1))\n",
    "            mk_len = K.expand_dims(k_len, axis=-1) @ K.expand_dims(m_len, axis=-2)\n",
    "            mk_len = K.switch(K.not_equal(mk_len, 0.), mk_len, K.ones_like(mk_len))\n",
    "            cos_sim = dot / mk_len\n",
    "            return K.softmax(cos_sim * K.expand_dims(b))\n",
    "        \n",
    "        def batch_invert_permutation(permutations):\n",
    "            # from https://github.com/deepmind/dnc/blob/master/dnc/util.py\n",
    "            perm = tf.cast(permutations, tf.float32)\n",
    "            dim = int(perm.get_shape()[-1])\n",
    "            size = tf.cast(tf.shape(perm)[0], tf.float32)\n",
    "            delta = tf.cast(tf.shape(perm)[-1], tf.float32)\n",
    "            rg = tf.range(0, size * delta, delta, dtype=tf.float32)\n",
    "            rg = tf.expand_dims(rg, 1)\n",
    "            rg = tf.tile(rg, [1, dim])\n",
    "            perm = tf.add(perm, rg)\n",
    "            flat = tf.reshape(perm, [-1])\n",
    "            perm = tf.invert_permutation(tf.cast(flat, tf.int32))\n",
    "            perm = tf.reshape(perm, [-1, dim])\n",
    "            return tf.subtract(perm, tf.cast(rg, tf.int32))\n",
    "\n",
    "        def batch_gather(values, indices):\n",
    "            # from https://github.com/deepmind/dnc/blob/master/dnc/util.py\n",
    "            idx = tf.expand_dims(indices, -1)\n",
    "            size = tf.shape(indices)[0]\n",
    "            rg = tf.range(size, dtype=tf.int32)\n",
    "            rg = tf.expand_dims(rg, -1)\n",
    "            rg = tf.tile(rg, [1, int(indices.get_shape()[-1])])\n",
    "            rg = tf.expand_dims(rg, -1)\n",
    "            gidx = tf.concat([rg, idx], -1)\n",
    "            return tf.gather_nd(values, gidx)\n",
    "        \n",
    "        _, register_s_last, register_h_last, memory_last, \\\n",
    "            read_weights_last, read_vec_last, write_weights_last, \\\n",
    "            usage_last, *temporal_states = states\n",
    "        memory_last = K.reshape(memory_last,\n",
    "            (-1,self.memory_size,self.word_size))\n",
    "        read_weights_last = K.reshape(read_weights_last,\n",
    "            (-1,self.read_head_count,self.memory_size))\n",
    "        write_weights_last = K.reshape(write_weights_last,\n",
    "            (-1,self.write_head_count,self.memory_size))\n",
    "        if not self.enable_temporal:\n",
    "            assert not temporal_states\n",
    "        else:\n",
    "            preced_last, link_last = temporal_states\n",
    "            preced_last = K.reshape(preced_last,\n",
    "                (-1,self.write_head_count,self.memory_size))\n",
    "            link_last = K.reshape(link_last,\n",
    "                (-1,self.write_head_count,self.memory_size,self.memory_size))\n",
    "        \n",
    "        # feeding controller with current input and last read vecs\n",
    "        output = K.concatenate([inputs, read_vec_last, register_h_last])\n",
    "        output = output @ self.kernel_controller_hidden\n",
    "        output = output + self.bias_controller_hidden\n",
    "        ctr_input_gate = output[:,:self.register_size*self.word_size]\n",
    "        ctr_input_gate = K.sigmoid(ctr_input_gate)\n",
    "        ctr_forget_gate = output[:,\n",
    "            self.register_size*self.word_size:\n",
    "            self.register_size*self.word_size*2]\n",
    "        ctr_forget_gate = K.sigmoid(ctr_forget_gate)\n",
    "        register_s = output[:,\n",
    "            self.register_size*self.word_size*2:\n",
    "            self.register_size*self.word_size*3]\n",
    "        register_s = ctr_input_gate * K.tanh(register_s)\n",
    "        register_s = register_s + ctr_forget_gate*register_s_last\n",
    "        ctr_output_gate = output[:,\n",
    "            self.register_size*self.word_size*3:\n",
    "            self.register_size*self.word_size*4]\n",
    "        ctr_output_gate = K.sigmoid(ctr_output_gate)\n",
    "        register_h = ctr_output_gate * K.tanh(register_s)\n",
    "        output = register_h @ self.kernel_controller_output\n",
    "        \n",
    "        # break down controller output into semi final output and interface vec\n",
    "        interface_vec = output[:,self.output_size:]\n",
    "        output = output[:,:self.output_size]\n",
    "        if self.bypass_dropout_factor is not None:\n",
    "            output = K.in_train_phase(K.dropout(\n",
    "                output,self.bypass_dropout_factor),output,training=training)\n",
    "        if self.enable_controller_output_resize:\n",
    "            output = output * self.scalar_controller_output_resize\n",
    "        \n",
    "        # break down interface vec\n",
    "        interface_pos_last = 0\n",
    "        interface_partition = []\n",
    "        for interface_part_len in [\n",
    "            self.read_head_count * self.word_size,\n",
    "            self.read_head_count,\n",
    "            self.write_head_count * self.word_size,\n",
    "            self.write_head_count,\n",
    "            self.write_head_count * self.word_size,\n",
    "            self.write_head_count * self.word_size,\n",
    "            self.read_head_count,\n",
    "            self.write_head_count,\n",
    "            self.write_head_count,\n",
    "            *([self.read_head_count * 3] if self.enable_temporal else [])]:\n",
    "            interface_pos = interface_pos_last + interface_part_len\n",
    "            interface_partition.append(\n",
    "                interface_vec[:,interface_pos_last:interface_pos])\n",
    "            interface_pos_last = interface_pos\n",
    "        read_keys, read_stre, write_keys, write_stre, erase_vecs, \\\n",
    "            write_vecs, free_gates, alloc_gates, write_gates, \\\n",
    "            *temporal_interface_partition = interface_partition\n",
    "        read_keys = K.reshape(read_keys,(-1,self.read_head_count,self.word_size))\n",
    "        read_stre = oneplus(read_stre)\n",
    "        write_keys = K.reshape(write_keys,(-1,self.write_head_count,self.word_size))\n",
    "        write_stre = oneplus(write_stre)\n",
    "        erase_vecs = K.reshape(erase_vecs,(-1,self.write_head_count,self.word_size))\n",
    "        erase_vecs = K.sigmoid(erase_vecs)\n",
    "        write_vecs = K.reshape(write_vecs,(-1,self.write_head_count,self.word_size))\n",
    "        free_gates = K.expand_dims(free_gates)\n",
    "        free_gates = K.sigmoid(free_gates)\n",
    "        alloc_gates = K.expand_dims(alloc_gates)\n",
    "        alloc_gates = K.sigmoid(alloc_gates)\n",
    "        write_gates = K.expand_dims(write_gates)\n",
    "        write_gates = K.sigmoid(write_gates)\n",
    "        if not self.enable_temporal:\n",
    "            assert not temporal_interface_partition\n",
    "        else:\n",
    "            read_modes, = temporal_interface_partition\n",
    "            read_modes = K.reshape(read_modes,(-1,self.read_head_count,3))\n",
    "            read_modes = K.softmax(read_modes,axis=-1)\n",
    "        \n",
    "        # compute allocation vector\n",
    "        retention = K.prod(1.-(free_gates*read_weights_last), axis=-2)\n",
    "        # https://github.com/deepmind/dnc/blob/master/dnc/addressing.py\n",
    "        # according to the deepmind implementation,\n",
    "        # only write weight is not differentiable\n",
    "        write_weights_last_nograd = K.stop_gradient(write_weights_last)\n",
    "        # reduce for multi-write-head, not presented in original papaer\n",
    "        write_weights_last_nograd = 1.-K.prod(1.-write_weights_last_nograd, axis=-2)\n",
    "        usage = ((usage_last+write_weights_last_nograd) - \\\n",
    "                usage_last*write_weights_last_nograd) * retention\n",
    "        # loop for multi-write-head support\n",
    "        mwh_write_gates = write_gates * alloc_gates\n",
    "        mwh_usage = usage\n",
    "        mwh_alloc = []\n",
    "        for i in range(self.write_head_count):\n",
    "            # quickfix for tf.cumprod grad bug\n",
    "            # https://github.com/tensorflow/tensorflow/issues/3862\n",
    "            usage_qfixed = 1e-6 + (1-1e-6) * mwh_usage\n",
    "            usage_asc,usage_perm = tf.nn.top_k(1.-usage_qfixed,k=self.memory_size)\n",
    "            usage_asc = 1.-usage_asc\n",
    "            alloc_asc = (1.-usage_asc) * tf.cumprod(usage_asc,axis=-1,exclusive=True)\n",
    "            alloc_perm = batch_invert_permutation(usage_perm)\n",
    "            alloc = batch_gather(alloc_asc, alloc_perm)\n",
    "            mwh_alloc.append(alloc)\n",
    "            mwh_usage += (1.-mwh_usage) * mwh_write_gates[:,i,:] * alloc\n",
    "        alloc = K.stack(mwh_alloc, axis=-2)\n",
    "        \n",
    "        # compute write weight\n",
    "        write_sims = similarity(memory_last,write_keys,write_stre)\n",
    "        write_weights = write_gates*(alloc_gates*alloc + (1.-alloc_gates)*write_sims)\n",
    "        \n",
    "        # compute precedence and temporal links\n",
    "        if self.enable_temporal:\n",
    "            write_weights_rep_h =  K.expand_dims(write_weights,axis=-1)\n",
    "            write_weights_rep_v =  K.expand_dims(write_weights,axis=-2)\n",
    "            link = (1.-(write_weights_rep_h+write_weights_rep_v))*link_last + \\\n",
    "                write_weights_rep_h * K.expand_dims(preced_last,axis=-2)\n",
    "            link = link * (1.-tf.eye(self.memory_size))\n",
    "            read_weights_last_rep = K.repeat_elements(\n",
    "                K.expand_dims(read_weights_last,axis=-3),self.write_head_count,-3)\n",
    "            # reduce sum for multi-write-head\n",
    "            link_forward = K.sum(read_weights_last_rep @ link,axis=-3)\n",
    "            link_backward = K.sum(K.permute_dimensions(link @ K.permute_dimensions(\n",
    "                read_weights_last_rep,(0,1,3,2)),(0,1,3,2)),axis=-3)\n",
    "            preced = (1.-K.sum(\n",
    "                write_weights,axis=-1,keepdims=True))*preced_last + write_weights\n",
    "        \n",
    "        # update memory\n",
    "        m_reset = K.expand_dims(write_weights,axis=-1) @ \\\n",
    "            K.expand_dims(erase_vecs,axis=-2)\n",
    "        # reduce prod for multi-write-head\n",
    "        m_keep = K.prod(1.-m_reset,axis=-3)\n",
    "        m_new = K.expand_dims(write_weights,axis=-1) @ \\\n",
    "            K.expand_dims(write_vecs,axis=-2)\n",
    "        # reduce sum for multi-write-head\n",
    "        m_new = K.sum(m_new, axis=-3)\n",
    "        memory = memory_last*m_keep + m_new\n",
    "        \n",
    "        # compute read weights and read vectors\n",
    "        read_sims = similarity(memory,read_keys,read_stre)\n",
    "        if not self.enable_temporal:\n",
    "            read_weights = read_sims\n",
    "        else:\n",
    "            read_weights = read_modes[:,:,0:1] * read_sims + \\\n",
    "                            read_modes[:,:,1:2] * link_forward + \\\n",
    "                            read_modes[:,:,2:3] * link_backward\n",
    "        read_vecs = read_weights @ memory\n",
    "        read_vec = K.reshape(read_vecs, (-1,self.read_head_count*self.word_size))\n",
    "        \n",
    "        # compute final output from controller output and current read vecs\n",
    "        output = output + read_vec @ self.kernel_read_vec_to_output\n",
    "        if self.enable_final_bias:\n",
    "            output = output + self.bias_final_output\n",
    "        \n",
    "        return output, [\n",
    "            output,\n",
    "            register_s,\n",
    "            register_h,\n",
    "            K.reshape(memory, (-1,self.memory_size*self.word_size)),\n",
    "            K.reshape(read_weights, (-1,self.read_head_count*self.memory_size)),\n",
    "            read_vec,\n",
    "            K.reshape(write_weights, (-1,self.write_head_count*self.memory_size)),\n",
    "            usage,\n",
    "            *([\n",
    "                K.reshape(preced, (-1,self.write_head_count*self.memory_size)),\n",
    "                K.reshape(link, (-1,self.write_head_count*self.memory_size**2))\n",
    "            ] if self.enable_temporal else [])]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 16)     256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, None, 16)     4960        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 16)     0           rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, None, 16)     0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "o1 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o2 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o3 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o4 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o5 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o6 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o7 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o8 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,216\n",
      "Trainable params: 5,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_inputs = keras.layers.Input((None,), dtype='int32')\n",
    "X = keras.layers.Embedding(data_input_dim, 16, mask_zero=True)(X)\n",
    "X = keras.layers.RNN(DNCCell(data_output_dim, 8, 16), return_sequences=True)(X)\n",
    "X = keras.layers.Lambda(lambda x,s: x[:,s:,:],\n",
    "    arguments={'s':X_train.shape[1]//2})(X)\n",
    "X = keras.layers.Softmax()(X)\n",
    "X = [keras.layers.Lambda(lambda x,s: x[:,s,:], name=f'o{i+1}',\n",
    "    arguments={'s':i}, output_shape=(data_output_dim,))(X)\n",
    "    for i in range(X_train.shape[1]//2)]\n",
    "M = keras.Model(X_inputs, X)\n",
    "M.compile('nadam', 'sparse_categorical_crossentropy', ['acc'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 18.7916 - o1_loss: 2.4331 - o2_loss: 2.4299 - o3_loss: 2.4456 - o4_loss: 2.4444 - o5_loss: 2.4089 - o6_loss: 2.3417 - o7_loss: 2.2272 - o8_loss: 2.0608 - o1_acc: 0.1253 - o2_acc: 0.1309 - o3_acc: 0.1583 - o4_acc: 0.1632 - o5_acc: 0.1419 - o6_acc: 0.1125 - o7_acc: 0.1458 - o8_acc: 0.4216 - val_loss: 15.6455 - val_o1_loss: 1.8693 - val_o2_loss: 1.9217 - val_o3_loss: 1.9935 - val_o4_loss: 2.0573 - val_o5_loss: 2.0784 - val_o6_loss: 2.0410 - val_o7_loss: 1.9415 - val_o8_loss: 1.7427 - val_o1_acc: 0.2410 - val_o2_acc: 0.2730 - val_o3_acc: 0.2650 - val_o4_acc: 0.3020 - val_o5_acc: 0.2370 - val_o6_acc: 0.2230 - val_o7_acc: 0.2220 - val_o8_acc: 0.3880\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 14.2192 - o1_loss: 1.6807 - o2_loss: 1.8043 - o3_loss: 1.8668 - o4_loss: 1.8813 - o5_loss: 1.8864 - o6_loss: 1.8677 - o7_loss: 1.7508 - o8_loss: 1.4813 - o1_acc: 0.3311 - o2_acc: 0.2855 - o3_acc: 0.3014 - o4_acc: 0.3172 - o5_acc: 0.2760 - o6_acc: 0.2249 - o7_acc: 0.2249 - o8_acc: 0.4419 - val_loss: 13.4885 - val_o1_loss: 1.5037 - val_o2_loss: 1.6811 - val_o3_loss: 1.7537 - val_o4_loss: 1.7832 - val_o5_loss: 1.8110 - val_o6_loss: 1.8126 - val_o7_loss: 1.7254 - val_o8_loss: 1.4178 - val_o1_acc: 0.4380 - val_o2_acc: 0.2780 - val_o3_acc: 0.2930 - val_o4_acc: 0.3210 - val_o5_acc: 0.2550 - val_o6_acc: 0.2380 - val_o7_acc: 0.2440 - val_o8_acc: 0.4570\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 12.8499 - o1_loss: 1.4209 - o2_loss: 1.6342 - o3_loss: 1.6706 - o4_loss: 1.6635 - o5_loss: 1.6952 - o6_loss: 1.7250 - o7_loss: 1.6726 - o8_loss: 1.3680 - o1_acc: 0.4475 - o2_acc: 0.3027 - o3_acc: 0.3294 - o4_acc: 0.3429 - o5_acc: 0.3046 - o6_acc: 0.2749 - o7_acc: 0.2586 - o8_acc: 0.4337 - val_loss: 12.3053 - val_o1_loss: 1.3911 - val_o2_loss: 1.5935 - val_o3_loss: 1.5714 - val_o4_loss: 1.5690 - val_o5_loss: 1.5738 - val_o6_loss: 1.6214 - val_o7_loss: 1.6292 - val_o8_loss: 1.3560 - val_o1_acc: 0.4710 - val_o2_acc: 0.3480 - val_o3_acc: 0.3660 - val_o4_acc: 0.3760 - val_o5_acc: 0.3410 - val_o6_acc: 0.2910 - val_o7_acc: 0.2640 - val_o8_acc: 0.4440\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 11.9222 - o1_loss: 1.2802 - o2_loss: 1.4932 - o3_loss: 1.4958 - o4_loss: 1.5043 - o5_loss: 1.5609 - o6_loss: 1.6232 - o7_loss: 1.6180 - o8_loss: 1.3466 - o1_acc: 0.4754 - o2_acc: 0.3596 - o3_acc: 0.3961 - o4_acc: 0.4015 - o5_acc: 0.3670 - o6_acc: 0.3157 - o7_acc: 0.2804 - o8_acc: 0.4282 - val_loss: 12.1768 - val_o1_loss: 1.3579 - val_o2_loss: 1.6082 - val_o3_loss: 1.5650 - val_o4_loss: 1.5562 - val_o5_loss: 1.5602 - val_o6_loss: 1.6167 - val_o7_loss: 1.5828 - val_o8_loss: 1.3298 - val_o1_acc: 0.4520 - val_o2_acc: 0.3390 - val_o3_acc: 0.3270 - val_o4_acc: 0.3630 - val_o5_acc: 0.3400 - val_o6_acc: 0.2840 - val_o7_acc: 0.2810 - val_o8_acc: 0.3470\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 11.2952 - o1_loss: 1.2126 - o2_loss: 1.4098 - o3_loss: 1.3863 - o4_loss: 1.4042 - o5_loss: 1.4712 - o6_loss: 1.5321 - o7_loss: 1.5569 - o8_loss: 1.3221 - o1_acc: 0.4828 - o2_acc: 0.3882 - o3_acc: 0.4314 - o4_acc: 0.4309 - o5_acc: 0.3945 - o6_acc: 0.3554 - o7_acc: 0.3101 - o8_acc: 0.4320 - val_loss: 11.1565 - val_o1_loss: 1.2345 - val_o2_loss: 1.4243 - val_o3_loss: 1.3960 - val_o4_loss: 1.4245 - val_o5_loss: 1.4226 - val_o6_loss: 1.4924 - val_o7_loss: 1.5252 - val_o8_loss: 1.2371 - val_o1_acc: 0.4720 - val_o2_acc: 0.3820 - val_o3_acc: 0.3720 - val_o4_acc: 0.3510 - val_o5_acc: 0.3870 - val_o6_acc: 0.3380 - val_o7_acc: 0.3220 - val_o8_acc: 0.4740\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 10.7558 - o1_loss: 1.1671 - o2_loss: 1.3317 - o3_loss: 1.3059 - o4_loss: 1.3311 - o5_loss: 1.3902 - o6_loss: 1.4435 - o7_loss: 1.4927 - o8_loss: 1.2937 - o1_acc: 0.4887 - o2_acc: 0.4201 - o3_acc: 0.4467 - o4_acc: 0.4442 - o5_acc: 0.4198 - o6_acc: 0.3884 - o7_acc: 0.3287 - o8_acc: 0.4317 - val_loss: 10.3256 - val_o1_loss: 1.1512 - val_o2_loss: 1.2803 - val_o3_loss: 1.2233 - val_o4_loss: 1.2497 - val_o5_loss: 1.3015 - val_o6_loss: 1.3693 - val_o7_loss: 1.4561 - val_o8_loss: 1.2941 - val_o1_acc: 0.5040 - val_o2_acc: 0.4530 - val_o3_acc: 0.4990 - val_o4_acc: 0.4750 - val_o5_acc: 0.4410 - val_o6_acc: 0.4050 - val_o7_acc: 0.3530 - val_o8_acc: 0.3750\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 10.4135 - o1_loss: 1.1366 - o2_loss: 1.2901 - o3_loss: 1.2469 - o4_loss: 1.2806 - o5_loss: 1.3331 - o6_loss: 1.3964 - o7_loss: 1.4558 - o8_loss: 1.2739 - o1_acc: 0.4950 - o2_acc: 0.4269 - o3_acc: 0.4656 - o4_acc: 0.4550 - o5_acc: 0.4375 - o6_acc: 0.4024 - o7_acc: 0.3451 - o8_acc: 0.4397 - val_loss: 10.2372 - val_o1_loss: 1.1254 - val_o2_loss: 1.2127 - val_o3_loss: 1.1740 - val_o4_loss: 1.2128 - val_o5_loss: 1.2617 - val_o6_loss: 1.3430 - val_o7_loss: 1.4807 - val_o8_loss: 1.4270 - val_o1_acc: 0.5100 - val_o2_acc: 0.4820 - val_o3_acc: 0.5070 - val_o4_acc: 0.4720 - val_o5_acc: 0.4350 - val_o6_acc: 0.3800 - val_o7_acc: 0.3020 - val_o8_acc: 0.3100\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 10.1442 - o1_loss: 1.1118 - o2_loss: 1.2372 - o3_loss: 1.2035 - o4_loss: 1.2269 - o5_loss: 1.2950 - o6_loss: 1.3616 - o7_loss: 1.4439 - o8_loss: 1.2642 - o1_acc: 0.5041 - o2_acc: 0.4477 - o3_acc: 0.4806 - o4_acc: 0.4760 - o5_acc: 0.4610 - o6_acc: 0.4220 - o7_acc: 0.3439 - o8_acc: 0.4405 - val_loss: 9.8147 - val_o1_loss: 1.1099 - val_o2_loss: 1.1525 - val_o3_loss: 1.1362 - val_o4_loss: 1.1945 - val_o5_loss: 1.2523 - val_o6_loss: 1.3589 - val_o7_loss: 1.4137 - val_o8_loss: 1.1968 - val_o1_acc: 0.5200 - val_o2_acc: 0.5070 - val_o3_acc: 0.4930 - val_o4_acc: 0.4930 - val_o5_acc: 0.4770 - val_o6_acc: 0.4050 - val_o7_acc: 0.3560 - val_o8_acc: 0.4620\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 9.9543 - o1_loss: 1.0923 - o2_loss: 1.2044 - o3_loss: 1.1617 - o4_loss: 1.2059 - o5_loss: 1.2677 - o6_loss: 1.3457 - o7_loss: 1.4232 - o8_loss: 1.2535 - o1_acc: 0.5124 - o2_acc: 0.4595 - o3_acc: 0.4932 - o4_acc: 0.4832 - o5_acc: 0.4587 - o6_acc: 0.4290 - o7_acc: 0.3516 - o8_acc: 0.4418 - val_loss: 9.9333 - val_o1_loss: 1.1059 - val_o2_loss: 1.2380 - val_o3_loss: 1.1978 - val_o4_loss: 1.1999 - val_o5_loss: 1.2063 - val_o6_loss: 1.2963 - val_o7_loss: 1.4044 - val_o8_loss: 1.2846 - val_o1_acc: 0.5320 - val_o2_acc: 0.4690 - val_o3_acc: 0.4990 - val_o4_acc: 0.4840 - val_o5_acc: 0.4520 - val_o6_acc: 0.4110 - val_o7_acc: 0.3220 - val_o8_acc: 0.3820\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 9.7707 - o1_loss: 1.0747 - o2_loss: 1.1710 - o3_loss: 1.1316 - o4_loss: 1.1788 - o5_loss: 1.2373 - o6_loss: 1.3177 - o7_loss: 1.4126 - o8_loss: 1.2472 - o1_acc: 0.5217 - o2_acc: 0.4771 - o3_acc: 0.5034 - o4_acc: 0.4923 - o5_acc: 0.4777 - o6_acc: 0.4343 - o7_acc: 0.3582 - o8_acc: 0.4475 - val_loss: 9.9102 - val_o1_loss: 1.1099 - val_o2_loss: 1.1563 - val_o3_loss: 1.1589 - val_o4_loss: 1.2138 - val_o5_loss: 1.2425 - val_o6_loss: 1.3000 - val_o7_loss: 1.4259 - val_o8_loss: 1.3028 - val_o1_acc: 0.4900 - val_o2_acc: 0.4670 - val_o3_acc: 0.4470 - val_o4_acc: 0.4560 - val_o5_acc: 0.4640 - val_o6_acc: 0.4390 - val_o7_acc: 0.3780 - val_o8_acc: 0.3820\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 9.6144 - o1_loss: 1.0476 - o2_loss: 1.1402 - o3_loss: 1.1078 - o4_loss: 1.1582 - o5_loss: 1.2087 - o6_loss: 1.3054 - o7_loss: 1.4060 - o8_loss: 1.2405 - o1_acc: 0.5292 - o2_acc: 0.4861 - o3_acc: 0.5111 - o4_acc: 0.4973 - o5_acc: 0.4815 - o6_acc: 0.4384 - o7_acc: 0.3640 - o8_acc: 0.4494 - val_loss: 9.4971 - val_o1_loss: 1.0574 - val_o2_loss: 1.0744 - val_o3_loss: 1.0732 - val_o4_loss: 1.1332 - val_o5_loss: 1.1978 - val_o6_loss: 1.2949 - val_o7_loss: 1.4069 - val_o8_loss: 1.2594 - val_o1_acc: 0.5250 - val_o2_acc: 0.5200 - val_o3_acc: 0.4910 - val_o4_acc: 0.4800 - val_o5_acc: 0.4760 - val_o6_acc: 0.4180 - val_o7_acc: 0.3530 - val_o8_acc: 0.3540\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 9.4494 - o1_loss: 1.0178 - o2_loss: 1.1051 - o3_loss: 1.0775 - o4_loss: 1.1347 - o5_loss: 1.1989 - o6_loss: 1.2870 - o7_loss: 1.3954 - o8_loss: 1.2330 - o1_acc: 0.5444 - o2_acc: 0.5004 - o3_acc: 0.5238 - o4_acc: 0.5054 - o5_acc: 0.4851 - o6_acc: 0.4492 - o7_acc: 0.3672 - o8_acc: 0.4537 - val_loss: 9.1129 - val_o1_loss: 1.0302 - val_o2_loss: 1.0375 - val_o3_loss: 1.0293 - val_o4_loss: 1.0897 - val_o5_loss: 1.1469 - val_o6_loss: 1.2329 - val_o7_loss: 1.3491 - val_o8_loss: 1.1974 - val_o1_acc: 0.5260 - val_o2_acc: 0.5530 - val_o3_acc: 0.5310 - val_o4_acc: 0.5120 - val_o5_acc: 0.5160 - val_o6_acc: 0.4640 - val_o7_acc: 0.3950 - val_o8_acc: 0.4360\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 9.2655 - o1_loss: 0.9808 - o2_loss: 1.0647 - o3_loss: 1.0536 - o4_loss: 1.1115 - o5_loss: 1.1724 - o6_loss: 1.2799 - o7_loss: 1.3787 - o8_loss: 1.2240 - o1_acc: 0.5584 - o2_acc: 0.5114 - o3_acc: 0.5335 - o4_acc: 0.5134 - o5_acc: 0.4910 - o6_acc: 0.4505 - o7_acc: 0.3730 - o8_acc: 0.4580 - val_loss: 8.8893 - val_o1_loss: 0.9700 - val_o2_loss: 1.0014 - val_o3_loss: 0.9948 - val_o4_loss: 1.0709 - val_o5_loss: 1.1082 - val_o6_loss: 1.2217 - val_o7_loss: 1.3395 - val_o8_loss: 1.1827 - val_o1_acc: 0.5720 - val_o2_acc: 0.5520 - val_o3_acc: 0.5560 - val_o4_acc: 0.5330 - val_o5_acc: 0.5260 - val_o6_acc: 0.4640 - val_o7_acc: 0.3580 - val_o8_acc: 0.4760\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 9.0349 - o1_loss: 0.9402 - o2_loss: 1.0244 - o3_loss: 1.0240 - o4_loss: 1.0935 - o5_loss: 1.1432 - o6_loss: 1.2405 - o7_loss: 1.3595 - o8_loss: 1.2096 - o1_acc: 0.5819 - o2_acc: 0.5392 - o3_acc: 0.5491 - o4_acc: 0.5209 - o5_acc: 0.5074 - o6_acc: 0.4636 - o7_acc: 0.3824 - o8_acc: 0.4668 - val_loss: 8.7972 - val_o1_loss: 0.9032 - val_o2_loss: 0.9462 - val_o3_loss: 0.9769 - val_o4_loss: 1.0841 - val_o5_loss: 1.1262 - val_o6_loss: 1.2188 - val_o7_loss: 1.3458 - val_o8_loss: 1.1961 - val_o1_acc: 0.5970 - val_o2_acc: 0.6010 - val_o3_acc: 0.5550 - val_o4_acc: 0.5300 - val_o5_acc: 0.4970 - val_o6_acc: 0.4580 - val_o7_acc: 0.3840 - val_o8_acc: 0.4480\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.9279 - o1_loss: 0.8920 - o2_loss: 0.9804 - o3_loss: 1.0146 - o4_loss: 1.0927 - o5_loss: 1.1471 - o6_loss: 1.2432 - o7_loss: 1.3515 - o8_loss: 1.2063 - o1_acc: 0.6089 - o2_acc: 0.5593 - o3_acc: 0.5482 - o4_acc: 0.5170 - o5_acc: 0.5046 - o6_acc: 0.4665 - o7_acc: 0.3838 - o8_acc: 0.4655 - val_loss: 11.7511 - val_o1_loss: 1.1182 - val_o2_loss: 1.4411 - val_o3_loss: 1.6644 - val_o4_loss: 1.7429 - val_o5_loss: 1.6083 - val_o6_loss: 1.4354 - val_o7_loss: 1.4710 - val_o8_loss: 1.2697 - val_o1_acc: 0.4950 - val_o2_acc: 0.3630 - val_o3_acc: 0.3570 - val_o4_acc: 0.3350 - val_o5_acc: 0.3680 - val_o6_acc: 0.3920 - val_o7_acc: 0.3420 - val_o8_acc: 0.4410\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.6719 - o1_loss: 0.8416 - o2_loss: 0.9215 - o3_loss: 0.9688 - o4_loss: 1.0490 - o5_loss: 1.1217 - o6_loss: 1.2259 - o7_loss: 1.3475 - o8_loss: 1.1958 - o1_acc: 0.6362 - o2_acc: 0.5922 - o3_acc: 0.5734 - o4_acc: 0.5386 - o5_acc: 0.5134 - o6_acc: 0.4676 - o7_acc: 0.3910 - o8_acc: 0.4685 - val_loss: 8.3208 - val_o1_loss: 0.7987 - val_o2_loss: 0.8408 - val_o3_loss: 0.9110 - val_o4_loss: 1.0378 - val_o5_loss: 1.0822 - val_o6_loss: 1.1801 - val_o7_loss: 1.3062 - val_o8_loss: 1.1639 - val_o1_acc: 0.6640 - val_o2_acc: 0.6510 - val_o3_acc: 0.5830 - val_o4_acc: 0.5360 - val_o5_acc: 0.5410 - val_o6_acc: 0.5040 - val_o7_acc: 0.3990 - val_o8_acc: 0.4810\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.4621 - o1_loss: 0.7914 - o2_loss: 0.8635 - o3_loss: 0.9428 - o4_loss: 1.0382 - o5_loss: 1.1040 - o6_loss: 1.2065 - o7_loss: 1.3293 - o8_loss: 1.1863 - o1_acc: 0.6585 - o2_acc: 0.6193 - o3_acc: 0.5874 - o4_acc: 0.5413 - o5_acc: 0.5207 - o6_acc: 0.4683 - o7_acc: 0.3984 - o8_acc: 0.4669 - val_loss: 8.3173 - val_o1_loss: 0.7788 - val_o2_loss: 0.8105 - val_o3_loss: 0.9064 - val_o4_loss: 1.0299 - val_o5_loss: 1.0593 - val_o6_loss: 1.1813 - val_o7_loss: 1.3331 - val_o8_loss: 1.2180 - val_o1_acc: 0.6620 - val_o2_acc: 0.6670 - val_o3_acc: 0.5930 - val_o4_acc: 0.5250 - val_o5_acc: 0.5000 - val_o6_acc: 0.4680 - val_o7_acc: 0.3550 - val_o8_acc: 0.4490\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.1481 - o1_loss: 0.7459 - o2_loss: 0.7845 - o3_loss: 0.8699 - o4_loss: 0.9871 - o5_loss: 1.0736 - o6_loss: 1.1948 - o7_loss: 1.3158 - o8_loss: 1.1764 - o1_acc: 0.6801 - o2_acc: 0.6518 - o3_acc: 0.6084 - o4_acc: 0.5621 - o5_acc: 0.5314 - o6_acc: 0.4763 - o7_acc: 0.4048 - o8_acc: 0.4700 - val_loss: 8.0024 - val_o1_loss: 0.7315 - val_o2_loss: 0.7412 - val_o3_loss: 0.8511 - val_o4_loss: 0.9844 - val_o5_loss: 1.0503 - val_o6_loss: 1.1502 - val_o7_loss: 1.2956 - val_o8_loss: 1.1982 - val_o1_acc: 0.6630 - val_o2_acc: 0.6770 - val_o3_acc: 0.6010 - val_o4_acc: 0.5610 - val_o5_acc: 0.5430 - val_o6_acc: 0.5050 - val_o7_acc: 0.3980 - val_o8_acc: 0.4450\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.2277 - o1_loss: 0.7362 - o2_loss: 0.7905 - o3_loss: 0.8992 - o4_loss: 1.0091 - o5_loss: 1.0940 - o6_loss: 1.2063 - o7_loss: 1.3242 - o8_loss: 1.1681 - o1_acc: 0.6837 - o2_acc: 0.6516 - o3_acc: 0.6098 - o4_acc: 0.5565 - o5_acc: 0.5274 - o6_acc: 0.4704 - o7_acc: 0.4048 - o8_acc: 0.4673 - val_loss: 7.9630 - val_o1_loss: 0.7320 - val_o2_loss: 0.7374 - val_o3_loss: 0.8453 - val_o4_loss: 0.9788 - val_o5_loss: 1.0276 - val_o6_loss: 1.1310 - val_o7_loss: 1.3079 - val_o8_loss: 1.2031 - val_o1_acc: 0.6660 - val_o2_acc: 0.6870 - val_o3_acc: 0.6060 - val_o4_acc: 0.5670 - val_o5_acc: 0.5250 - val_o6_acc: 0.5000 - val_o7_acc: 0.4280 - val_o8_acc: 0.4770\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.9222 - o1_loss: 0.7152 - o2_loss: 0.7637 - o3_loss: 0.8561 - o4_loss: 0.9628 - o5_loss: 1.0396 - o6_loss: 1.1540 - o7_loss: 1.2820 - o8_loss: 1.1488 - o1_acc: 0.6867 - o2_acc: 0.6659 - o3_acc: 0.6293 - o4_acc: 0.5827 - o5_acc: 0.5421 - o6_acc: 0.4956 - o7_acc: 0.4199 - o8_acc: 0.4748 - val_loss: 7.6778 - val_o1_loss: 0.6936 - val_o2_loss: 0.6924 - val_o3_loss: 0.8082 - val_o4_loss: 0.9474 - val_o5_loss: 1.0060 - val_o6_loss: 1.1156 - val_o7_loss: 1.2792 - val_o8_loss: 1.1354 - val_o1_acc: 0.6900 - val_o2_acc: 0.7180 - val_o3_acc: 0.6310 - val_o4_acc: 0.5760 - val_o5_acc: 0.5360 - val_o6_acc: 0.5160 - val_o7_acc: 0.4180 - val_o8_acc: 0.4970\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.8187 - o1_loss: 0.6893 - o2_loss: 0.7321 - o3_loss: 0.8363 - o4_loss: 0.9452 - o5_loss: 1.0344 - o6_loss: 1.1572 - o7_loss: 1.2786 - o8_loss: 1.1456 - o1_acc: 0.7033 - o2_acc: 0.6695 - o3_acc: 0.6338 - o4_acc: 0.5858 - o5_acc: 0.5485 - o6_acc: 0.4921 - o7_acc: 0.4150 - o8_acc: 0.4789 - val_loss: 7.5323 - val_o1_loss: 0.6796 - val_o2_loss: 0.6802 - val_o3_loss: 0.7832 - val_o4_loss: 0.9220 - val_o5_loss: 0.9778 - val_o6_loss: 1.0971 - val_o7_loss: 1.2568 - val_o8_loss: 1.1355 - val_o1_acc: 0.6890 - val_o2_acc: 0.7040 - val_o3_acc: 0.6480 - val_o4_acc: 0.5880 - val_o5_acc: 0.5550 - val_o6_acc: 0.5260 - val_o7_acc: 0.4260 - val_o8_acc: 0.4800\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.6907 - o1_loss: 0.6852 - o2_loss: 0.7319 - o3_loss: 0.8257 - o4_loss: 0.9291 - o5_loss: 1.0171 - o6_loss: 1.1215 - o7_loss: 1.2543 - o8_loss: 1.1259 - o1_acc: 0.6981 - o2_acc: 0.6717 - o3_acc: 0.6449 - o4_acc: 0.5985 - o5_acc: 0.5525 - o6_acc: 0.5058 - o7_acc: 0.4225 - o8_acc: 0.4874 - val_loss: 7.4809 - val_o1_loss: 0.6676 - val_o2_loss: 0.6765 - val_o3_loss: 0.7833 - val_o4_loss: 0.9106 - val_o5_loss: 0.9753 - val_o6_loss: 1.0748 - val_o7_loss: 1.2402 - val_o8_loss: 1.1525 - val_o1_acc: 0.7050 - val_o2_acc: 0.7060 - val_o3_acc: 0.6200 - val_o4_acc: 0.5760 - val_o5_acc: 0.5580 - val_o6_acc: 0.5220 - val_o7_acc: 0.4130 - val_o8_acc: 0.4280\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.5544 - o1_loss: 0.6641 - o2_loss: 0.6913 - o3_loss: 0.7807 - o4_loss: 0.8968 - o5_loss: 1.0005 - o6_loss: 1.1279 - o7_loss: 1.2653 - o8_loss: 1.1279 - o1_acc: 0.7069 - o2_acc: 0.6894 - o3_acc: 0.6545 - o4_acc: 0.5987 - o5_acc: 0.5580 - o6_acc: 0.5034 - o7_acc: 0.4263 - o8_acc: 0.4858 - val_loss: 7.5541 - val_o1_loss: 0.6609 - val_o2_loss: 0.6661 - val_o3_loss: 0.7687 - val_o4_loss: 0.9315 - val_o5_loss: 1.0108 - val_o6_loss: 1.0965 - val_o7_loss: 1.2681 - val_o8_loss: 1.1516 - val_o1_acc: 0.7020 - val_o2_acc: 0.7050 - val_o3_acc: 0.6280 - val_o4_acc: 0.5740 - val_o5_acc: 0.5630 - val_o6_acc: 0.4910 - val_o7_acc: 0.4100 - val_o8_acc: 0.4690\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.5017 - o1_loss: 0.6616 - o2_loss: 0.7018 - o3_loss: 0.7943 - o4_loss: 0.8993 - o5_loss: 0.9900 - o6_loss: 1.1046 - o7_loss: 1.2381 - o8_loss: 1.1120 - o1_acc: 0.7080 - o2_acc: 0.6793 - o3_acc: 0.6458 - o4_acc: 0.6060 - o5_acc: 0.5654 - o6_acc: 0.5140 - o7_acc: 0.4343 - o8_acc: 0.4901 - val_loss: 7.6136 - val_o1_loss: 0.6588 - val_o2_loss: 0.6426 - val_o3_loss: 0.7364 - val_o4_loss: 0.8828 - val_o5_loss: 0.9794 - val_o6_loss: 1.1287 - val_o7_loss: 1.3543 - val_o8_loss: 1.2306 - val_o1_acc: 0.6960 - val_o2_acc: 0.7250 - val_o3_acc: 0.6790 - val_o4_acc: 0.6010 - val_o5_acc: 0.5780 - val_o6_acc: 0.4960 - val_o7_acc: 0.3920 - val_o8_acc: 0.4680\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.2440 - o1_loss: 0.6407 - o2_loss: 0.6750 - o3_loss: 0.7504 - o4_loss: 0.8540 - o5_loss: 0.9445 - o6_loss: 1.0729 - o7_loss: 1.2122 - o8_loss: 1.0942 - o1_acc: 0.7255 - o2_acc: 0.6905 - o3_acc: 0.6653 - o4_acc: 0.6228 - o5_acc: 0.5853 - o6_acc: 0.5206 - o7_acc: 0.4417 - o8_acc: 0.4997 - val_loss: 7.3624 - val_o1_loss: 0.6524 - val_o2_loss: 0.6399 - val_o3_loss: 0.7234 - val_o4_loss: 0.8657 - val_o5_loss: 0.9468 - val_o6_loss: 1.0868 - val_o7_loss: 1.2963 - val_o8_loss: 1.1510 - val_o1_acc: 0.6910 - val_o2_acc: 0.7330 - val_o3_acc: 0.6810 - val_o4_acc: 0.6220 - val_o5_acc: 0.5630 - val_o6_acc: 0.5110 - val_o7_acc: 0.4130 - val_o8_acc: 0.4830\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.3185 - o1_loss: 0.6503 - o2_loss: 0.6953 - o3_loss: 0.7712 - o4_loss: 0.8701 - o5_loss: 0.9537 - o6_loss: 1.0766 - o7_loss: 1.2101 - o8_loss: 1.0913 - o1_acc: 0.7148 - o2_acc: 0.6875 - o3_acc: 0.6610 - o4_acc: 0.6201 - o5_acc: 0.5768 - o6_acc: 0.5260 - o7_acc: 0.4500 - o8_acc: 0.5039 - val_loss: 7.0770 - val_o1_loss: 0.6719 - val_o2_loss: 0.6650 - val_o3_loss: 0.7435 - val_o4_loss: 0.8672 - val_o5_loss: 0.8958 - val_o6_loss: 1.0010 - val_o7_loss: 1.1593 - val_o8_loss: 1.0734 - val_o1_acc: 0.6940 - val_o2_acc: 0.7280 - val_o3_acc: 0.6790 - val_o4_acc: 0.6220 - val_o5_acc: 0.6090 - val_o6_acc: 0.5740 - val_o7_acc: 0.4730 - val_o8_acc: 0.4890\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.9907 - o1_loss: 0.6274 - o2_loss: 0.6552 - o3_loss: 0.7352 - o4_loss: 0.8250 - o5_loss: 0.9067 - o6_loss: 1.0247 - o7_loss: 1.1560 - o8_loss: 1.0606 - o1_acc: 0.7314 - o2_acc: 0.6983 - o3_acc: 0.6698 - o4_acc: 0.6356 - o5_acc: 0.5989 - o6_acc: 0.5511 - o7_acc: 0.4739 - o8_acc: 0.5097 - val_loss: 7.1347 - val_o1_loss: 0.6419 - val_o2_loss: 0.6356 - val_o3_loss: 0.7322 - val_o4_loss: 0.8641 - val_o5_loss: 0.9165 - val_o6_loss: 1.0694 - val_o7_loss: 1.1951 - val_o8_loss: 1.0799 - val_o1_acc: 0.7280 - val_o2_acc: 0.7280 - val_o3_acc: 0.6710 - val_o4_acc: 0.6110 - val_o5_acc: 0.6110 - val_o6_acc: 0.5180 - val_o7_acc: 0.4610 - val_o8_acc: 0.4890\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.7470 - o1_loss: 0.6158 - o2_loss: 0.6374 - o3_loss: 0.7051 - o4_loss: 0.7985 - o5_loss: 0.8674 - o6_loss: 0.9790 - o7_loss: 1.1119 - o8_loss: 1.0318 - o1_acc: 0.7404 - o2_acc: 0.7116 - o3_acc: 0.6854 - o4_acc: 0.6508 - o5_acc: 0.6134 - o6_acc: 0.5636 - o7_acc: 0.4929 - o8_acc: 0.5211 - val_loss: 10.0808 - val_o1_loss: 0.6605 - val_o2_loss: 0.7558 - val_o3_loss: 0.9634 - val_o4_loss: 1.1778 - val_o5_loss: 1.4135 - val_o6_loss: 1.8094 - val_o7_loss: 1.8548 - val_o8_loss: 1.4456 - val_o1_acc: 0.7010 - val_o2_acc: 0.6590 - val_o3_acc: 0.5950 - val_o4_acc: 0.5000 - val_o5_acc: 0.4170 - val_o6_acc: 0.3140 - val_o7_acc: 0.3050 - val_o8_acc: 0.4900\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.8366 - o1_loss: 0.6135 - o2_loss: 0.6331 - o3_loss: 0.7024 - o4_loss: 0.7950 - o5_loss: 0.8911 - o6_loss: 1.0121 - o7_loss: 1.1400 - o8_loss: 1.0495 - o1_acc: 0.7443 - o2_acc: 0.7133 - o3_acc: 0.6874 - o4_acc: 0.6513 - o5_acc: 0.6140 - o6_acc: 0.5572 - o7_acc: 0.4980 - o8_acc: 0.5187 - val_loss: 6.5881 - val_o1_loss: 0.6238 - val_o2_loss: 0.6214 - val_o3_loss: 0.6783 - val_o4_loss: 0.7868 - val_o5_loss: 0.8223 - val_o6_loss: 0.9429 - val_o7_loss: 1.0974 - val_o8_loss: 1.0152 - val_o1_acc: 0.7260 - val_o2_acc: 0.7300 - val_o3_acc: 0.6970 - val_o4_acc: 0.6520 - val_o5_acc: 0.6270 - val_o6_acc: 0.5690 - val_o7_acc: 0.4980 - val_o8_acc: 0.5200\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.6149 - o1_loss: 0.6039 - o2_loss: 0.6257 - o3_loss: 0.6918 - o4_loss: 0.7738 - o5_loss: 0.8424 - o6_loss: 0.9634 - o7_loss: 1.0881 - o8_loss: 1.0256 - o1_acc: 0.7441 - o2_acc: 0.7120 - o3_acc: 0.6860 - o4_acc: 0.6589 - o5_acc: 0.6247 - o6_acc: 0.5682 - o7_acc: 0.5084 - o8_acc: 0.5220 - val_loss: 6.3851 - val_o1_loss: 0.6138 - val_o2_loss: 0.5889 - val_o3_loss: 0.6501 - val_o4_loss: 0.7681 - val_o5_loss: 0.8134 - val_o6_loss: 0.9033 - val_o7_loss: 1.0520 - val_o8_loss: 0.9956 - val_o1_acc: 0.7410 - val_o2_acc: 0.7480 - val_o3_acc: 0.7130 - val_o4_acc: 0.6510 - val_o5_acc: 0.6430 - val_o6_acc: 0.5710 - val_o7_acc: 0.5130 - val_o8_acc: 0.5380\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.3837 - o1_loss: 0.5909 - o2_loss: 0.6013 - o3_loss: 0.6697 - o4_loss: 0.7490 - o5_loss: 0.8186 - o6_loss: 0.9172 - o7_loss: 1.0408 - o8_loss: 0.9962 - o1_acc: 0.7553 - o2_acc: 0.7291 - o3_acc: 0.6973 - o4_acc: 0.6692 - o5_acc: 0.6361 - o6_acc: 0.5885 - o7_acc: 0.5287 - o8_acc: 0.5336 - val_loss: 6.8379 - val_o1_loss: 0.6052 - val_o2_loss: 0.5703 - val_o3_loss: 0.6283 - val_o4_loss: 0.7789 - val_o5_loss: 0.8691 - val_o6_loss: 0.9725 - val_o7_loss: 1.2329 - val_o8_loss: 1.1807 - val_o1_acc: 0.7290 - val_o2_acc: 0.7720 - val_o3_acc: 0.7230 - val_o4_acc: 0.6390 - val_o5_acc: 0.6060 - val_o6_acc: 0.5760 - val_o7_acc: 0.4240 - val_o8_acc: 0.5030\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 6.3714 - o1_loss: 0.5856 - o2_loss: 0.5949 - o3_loss: 0.6661 - o4_loss: 0.7543 - o5_loss: 0.8255 - o6_loss: 0.9280 - o7_loss: 1.0349 - o8_loss: 0.9821 - o1_acc: 0.7549 - o2_acc: 0.7324 - o3_acc: 0.7049 - o4_acc: 0.6746 - o5_acc: 0.6350 - o6_acc: 0.5927 - o7_acc: 0.5426 - o8_acc: 0.5469 - val_loss: 7.9456 - val_o1_loss: 0.6456 - val_o2_loss: 0.6912 - val_o3_loss: 0.7910 - val_o4_loss: 0.8955 - val_o5_loss: 0.9736 - val_o6_loss: 1.2419 - val_o7_loss: 1.4439 - val_o8_loss: 1.2629 - val_o1_acc: 0.7180 - val_o2_acc: 0.7070 - val_o3_acc: 0.6410 - val_o4_acc: 0.6180 - val_o5_acc: 0.5470 - val_o6_acc: 0.4860 - val_o7_acc: 0.3880 - val_o8_acc: 0.4910\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 6.0511 - o1_loss: 0.5682 - o2_loss: 0.5673 - o3_loss: 0.6313 - o4_loss: 0.7136 - o5_loss: 0.7727 - o6_loss: 0.8659 - o7_loss: 0.9774 - o8_loss: 0.9546 - o1_acc: 0.7601 - o2_acc: 0.7524 - o3_acc: 0.7224 - o4_acc: 0.6918 - o5_acc: 0.6595 - o6_acc: 0.6100 - o7_acc: 0.5576 - o8_acc: 0.5561 - val_loss: 6.0516 - val_o1_loss: 0.5856 - val_o2_loss: 0.5403 - val_o3_loss: 0.5872 - val_o4_loss: 0.7010 - val_o5_loss: 0.7863 - val_o6_loss: 0.8558 - val_o7_loss: 1.0025 - val_o8_loss: 0.9929 - val_o1_acc: 0.7470 - val_o2_acc: 0.7640 - val_o3_acc: 0.7400 - val_o4_acc: 0.6860 - val_o5_acc: 0.6440 - val_o6_acc: 0.6220 - val_o7_acc: 0.5370 - val_o8_acc: 0.5480\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step - loss: 5.9749 - o1_loss: 0.5571 - o2_loss: 0.5494 - o3_loss: 0.6055 - o4_loss: 0.6951 - o5_loss: 0.7753 - o6_loss: 0.8659 - o7_loss: 0.9776 - o8_loss: 0.9489 - o1_acc: 0.7625 - o2_acc: 0.7640 - o3_acc: 0.7345 - o4_acc: 0.7015 - o5_acc: 0.6556 - o6_acc: 0.6139 - o7_acc: 0.5557 - o8_acc: 0.5601 - val_loss: 5.6580 - val_o1_loss: 0.5655 - val_o2_loss: 0.5198 - val_o3_loss: 0.5472 - val_o4_loss: 0.6517 - val_o5_loss: 0.7288 - val_o6_loss: 0.7864 - val_o7_loss: 0.9222 - val_o8_loss: 0.9364 - val_o1_acc: 0.7610 - val_o2_acc: 0.7810 - val_o3_acc: 0.7630 - val_o4_acc: 0.7040 - val_o5_acc: 0.6630 - val_o6_acc: 0.6500 - val_o7_acc: 0.5690 - val_o8_acc: 0.5500\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 5.9375 - o1_loss: 0.5519 - o2_loss: 0.5487 - o3_loss: 0.6005 - o4_loss: 0.7043 - o5_loss: 0.7701 - o6_loss: 0.8597 - o7_loss: 0.9650 - o8_loss: 0.9372 - o1_acc: 0.7666 - o2_acc: 0.7591 - o3_acc: 0.7385 - o4_acc: 0.6963 - o5_acc: 0.6616 - o6_acc: 0.6198 - o7_acc: 0.5648 - o8_acc: 0.5675 - val_loss: 5.6021 - val_o1_loss: 0.5673 - val_o2_loss: 0.5145 - val_o3_loss: 0.5505 - val_o4_loss: 0.6573 - val_o5_loss: 0.7267 - val_o6_loss: 0.7970 - val_o7_loss: 0.9021 - val_o8_loss: 0.8866 - val_o1_acc: 0.7390 - val_o2_acc: 0.7890 - val_o3_acc: 0.7640 - val_o4_acc: 0.7220 - val_o5_acc: 0.7010 - val_o6_acc: 0.6340 - val_o7_acc: 0.5910 - val_o8_acc: 0.5980\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 5.5174 - o1_loss: 0.5340 - o2_loss: 0.5105 - o3_loss: 0.5510 - o4_loss: 0.6453 - o5_loss: 0.7121 - o6_loss: 0.7966 - o7_loss: 0.8877 - o8_loss: 0.8803 - o1_acc: 0.7799 - o2_acc: 0.7814 - o3_acc: 0.7605 - o4_acc: 0.7214 - o5_acc: 0.6841 - o6_acc: 0.6403 - o7_acc: 0.5959 - o8_acc: 0.5895 - val_loss: 6.3152 - val_o1_loss: 0.7347 - val_o2_loss: 0.8074 - val_o3_loss: 0.7690 - val_o4_loss: 0.7512 - val_o5_loss: 0.7446 - val_o6_loss: 0.7701 - val_o7_loss: 0.8644 - val_o8_loss: 0.8740 - val_o1_acc: 0.6580 - val_o2_acc: 0.6480 - val_o3_acc: 0.6590 - val_o4_acc: 0.6530 - val_o5_acc: 0.6650 - val_o6_acc: 0.6490 - val_o7_acc: 0.6100 - val_o8_acc: 0.6000\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.5423 - o1_loss: 0.5370 - o2_loss: 0.5113 - o3_loss: 0.5513 - o4_loss: 0.6449 - o5_loss: 0.7087 - o6_loss: 0.7950 - o7_loss: 0.9028 - o8_loss: 0.8914 - o1_acc: 0.7786 - o2_acc: 0.7821 - o3_acc: 0.7611 - o4_acc: 0.7192 - o5_acc: 0.6838 - o6_acc: 0.6421 - o7_acc: 0.5880 - o8_acc: 0.5891 - val_loss: 5.2946 - val_o1_loss: 0.5432 - val_o2_loss: 0.4818 - val_o3_loss: 0.5162 - val_o4_loss: 0.6108 - val_o5_loss: 0.6843 - val_o6_loss: 0.7597 - val_o7_loss: 0.8593 - val_o8_loss: 0.8394 - val_o1_acc: 0.7630 - val_o2_acc: 0.8010 - val_o3_acc: 0.7700 - val_o4_acc: 0.7270 - val_o5_acc: 0.7000 - val_o6_acc: 0.6570 - val_o7_acc: 0.6060 - val_o8_acc: 0.6140\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 5.3903 - o1_loss: 0.5238 - o2_loss: 0.4936 - o3_loss: 0.5272 - o4_loss: 0.6208 - o5_loss: 0.6933 - o6_loss: 0.7827 - o7_loss: 0.8786 - o8_loss: 0.8703 - o1_acc: 0.7841 - o2_acc: 0.7907 - o3_acc: 0.7708 - o4_acc: 0.7302 - o5_acc: 0.6906 - o6_acc: 0.6435 - o7_acc: 0.5923 - o8_acc: 0.5889 - val_loss: 5.1955 - val_o1_loss: 0.5342 - val_o2_loss: 0.4729 - val_o3_loss: 0.5004 - val_o4_loss: 0.6047 - val_o5_loss: 0.6665 - val_o6_loss: 0.7393 - val_o7_loss: 0.8442 - val_o8_loss: 0.8333 - val_o1_acc: 0.7680 - val_o2_acc: 0.7980 - val_o3_acc: 0.7800 - val_o4_acc: 0.7280 - val_o5_acc: 0.7030 - val_o6_acc: 0.6620 - val_o7_acc: 0.5960 - val_o8_acc: 0.5920\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 5.3207 - o1_loss: 0.5205 - o2_loss: 0.4921 - o3_loss: 0.5260 - o4_loss: 0.6172 - o5_loss: 0.6883 - o6_loss: 0.7721 - o7_loss: 0.8592 - o8_loss: 0.8452 - o1_acc: 0.7884 - o2_acc: 0.7907 - o3_acc: 0.7740 - o4_acc: 0.7311 - o5_acc: 0.6923 - o6_acc: 0.6532 - o7_acc: 0.6080 - o8_acc: 0.6055 - val_loss: 13.5796 - val_o1_loss: 0.8633 - val_o2_loss: 1.2634 - val_o3_loss: 1.8087 - val_o4_loss: 2.1030 - val_o5_loss: 2.2119 - val_o6_loss: 2.3044 - val_o7_loss: 1.7983 - val_o8_loss: 1.2267 - val_o1_acc: 0.6210 - val_o2_acc: 0.5390 - val_o3_acc: 0.4770 - val_o4_acc: 0.3990 - val_o5_acc: 0.3870 - val_o6_acc: 0.3620 - val_o7_acc: 0.4020 - val_o8_acc: 0.5180\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 5.2801 - o1_loss: 0.5247 - o2_loss: 0.4905 - o3_loss: 0.5172 - o4_loss: 0.6101 - o5_loss: 0.6901 - o6_loss: 0.7795 - o7_loss: 0.8470 - o8_loss: 0.8211 - o1_acc: 0.7845 - o2_acc: 0.7936 - o3_acc: 0.7835 - o4_acc: 0.7402 - o5_acc: 0.7016 - o6_acc: 0.6599 - o7_acc: 0.6229 - o8_acc: 0.6127 - val_loss: 5.2502 - val_o1_loss: 0.5213 - val_o2_loss: 0.4589 - val_o3_loss: 0.4887 - val_o4_loss: 0.5779 - val_o5_loss: 0.6756 - val_o6_loss: 0.7988 - val_o7_loss: 0.9049 - val_o8_loss: 0.8242 - val_o1_acc: 0.7800 - val_o2_acc: 0.8110 - val_o3_acc: 0.7820 - val_o4_acc: 0.7490 - val_o5_acc: 0.6780 - val_o6_acc: 0.6410 - val_o7_acc: 0.5810 - val_o8_acc: 0.5940\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.1063 - o1_loss: 0.5028 - o2_loss: 0.4618 - o3_loss: 0.4833 - o4_loss: 0.5734 - o5_loss: 0.6538 - o6_loss: 0.7517 - o7_loss: 0.8424 - o8_loss: 0.8371 - o1_acc: 0.8006 - o2_acc: 0.8053 - o3_acc: 0.7952 - o4_acc: 0.7505 - o5_acc: 0.7099 - o6_acc: 0.6587 - o7_acc: 0.6124 - o8_acc: 0.6074 - val_loss: 10.6249 - val_o1_loss: 0.5637 - val_o2_loss: 0.5298 - val_o3_loss: 0.6271 - val_o4_loss: 0.9401 - val_o5_loss: 1.4182 - val_o6_loss: 1.9031 - val_o7_loss: 2.3719 - val_o8_loss: 2.2710 - val_o1_acc: 0.7550 - val_o2_acc: 0.7770 - val_o3_acc: 0.7410 - val_o4_acc: 0.6130 - val_o5_acc: 0.4870 - val_o6_acc: 0.4020 - val_o7_acc: 0.2610 - val_o8_acc: 0.2170\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.0863 - o1_loss: 0.5023 - o2_loss: 0.4611 - o3_loss: 0.4854 - o4_loss: 0.5767 - o5_loss: 0.6613 - o6_loss: 0.7551 - o7_loss: 0.8303 - o8_loss: 0.8142 - o1_acc: 0.7994 - o2_acc: 0.8057 - o3_acc: 0.7937 - o4_acc: 0.7550 - o5_acc: 0.7104 - o6_acc: 0.6641 - o7_acc: 0.6359 - o8_acc: 0.6204 - val_loss: 5.1407 - val_o1_loss: 0.5201 - val_o2_loss: 0.4796 - val_o3_loss: 0.5223 - val_o4_loss: 0.6202 - val_o5_loss: 0.6798 - val_o6_loss: 0.7365 - val_o7_loss: 0.7944 - val_o8_loss: 0.7878 - val_o1_acc: 0.8040 - val_o2_acc: 0.7960 - val_o3_acc: 0.7770 - val_o4_acc: 0.7190 - val_o5_acc: 0.6860 - val_o6_acc: 0.6600 - val_o7_acc: 0.6240 - val_o8_acc: 0.6190\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.9034 - o1_loss: 0.4892 - o2_loss: 0.4433 - o3_loss: 0.4573 - o4_loss: 0.5438 - o5_loss: 0.6282 - o6_loss: 0.7201 - o7_loss: 0.8122 - o8_loss: 0.8093 - o1_acc: 0.8076 - o2_acc: 0.8115 - o3_acc: 0.8069 - o4_acc: 0.7672 - o5_acc: 0.7216 - o6_acc: 0.6760 - o7_acc: 0.6279 - o8_acc: 0.6171 - val_loss: 5.3471 - val_o1_loss: 0.5345 - val_o2_loss: 0.5105 - val_o3_loss: 0.5790 - val_o4_loss: 0.6588 - val_o5_loss: 0.7006 - val_o6_loss: 0.7529 - val_o7_loss: 0.8186 - val_o8_loss: 0.7922 - val_o1_acc: 0.7820 - val_o2_acc: 0.7730 - val_o3_acc: 0.7360 - val_o4_acc: 0.7000 - val_o5_acc: 0.6840 - val_o6_acc: 0.6650 - val_o7_acc: 0.6340 - val_o8_acc: 0.6260\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.0808 - o1_loss: 0.4873 - o2_loss: 0.4465 - o3_loss: 0.4641 - o4_loss: 0.5632 - o5_loss: 0.6628 - o6_loss: 0.7773 - o7_loss: 0.8559 - o8_loss: 0.8237 - o1_acc: 0.8103 - o2_acc: 0.8078 - o3_acc: 0.8014 - o4_acc: 0.7621 - o5_acc: 0.7097 - o6_acc: 0.6558 - o7_acc: 0.6216 - o8_acc: 0.6164 - val_loss: 4.9074 - val_o1_loss: 0.5011 - val_o2_loss: 0.4330 - val_o3_loss: 0.4551 - val_o4_loss: 0.5335 - val_o5_loss: 0.6306 - val_o6_loss: 0.7300 - val_o7_loss: 0.8121 - val_o8_loss: 0.8120 - val_o1_acc: 0.8010 - val_o2_acc: 0.8180 - val_o3_acc: 0.7930 - val_o4_acc: 0.7650 - val_o5_acc: 0.7380 - val_o6_acc: 0.6690 - val_o7_acc: 0.6240 - val_o8_acc: 0.6250\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.7378 - o1_loss: 0.4758 - o2_loss: 0.4323 - o3_loss: 0.4501 - o4_loss: 0.5268 - o5_loss: 0.6115 - o6_loss: 0.6987 - o7_loss: 0.7781 - o8_loss: 0.7645 - o1_acc: 0.8168 - o2_acc: 0.8131 - o3_acc: 0.8105 - o4_acc: 0.7753 - o5_acc: 0.7280 - o6_acc: 0.6890 - o7_acc: 0.6444 - o8_acc: 0.6352 - val_loss: 4.6281 - val_o1_loss: 0.4740 - val_o2_loss: 0.4083 - val_o3_loss: 0.4296 - val_o4_loss: 0.5213 - val_o5_loss: 0.6111 - val_o6_loss: 0.7048 - val_o7_loss: 0.7576 - val_o8_loss: 0.7213 - val_o1_acc: 0.8170 - val_o2_acc: 0.8290 - val_o3_acc: 0.8200 - val_o4_acc: 0.7730 - val_o5_acc: 0.7330 - val_o6_acc: 0.6970 - val_o7_acc: 0.6720 - val_o8_acc: 0.6510\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.6714 - o1_loss: 0.4609 - o2_loss: 0.4180 - o3_loss: 0.4288 - o4_loss: 0.5102 - o5_loss: 0.5990 - o6_loss: 0.7025 - o7_loss: 0.7812 - o8_loss: 0.7707 - o1_acc: 0.8218 - o2_acc: 0.8223 - o3_acc: 0.8208 - o4_acc: 0.7845 - o5_acc: 0.7325 - o6_acc: 0.6830 - o7_acc: 0.6444 - o8_acc: 0.6329 - val_loss: 4.9167 - val_o1_loss: 0.4832 - val_o2_loss: 0.4134 - val_o3_loss: 0.4284 - val_o4_loss: 0.5039 - val_o5_loss: 0.6044 - val_o6_loss: 0.7703 - val_o7_loss: 0.8957 - val_o8_loss: 0.8176 - val_o1_acc: 0.8050 - val_o2_acc: 0.8220 - val_o3_acc: 0.8110 - val_o4_acc: 0.7980 - val_o5_acc: 0.7370 - val_o6_acc: 0.6420 - val_o7_acc: 0.5690 - val_o8_acc: 0.5880\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.8512 - o1_loss: 0.4610 - o2_loss: 0.4219 - o3_loss: 0.4388 - o4_loss: 0.5188 - o5_loss: 0.6347 - o6_loss: 0.7437 - o7_loss: 0.8254 - o8_loss: 0.8068 - o1_acc: 0.8230 - o2_acc: 0.8186 - o3_acc: 0.8151 - o4_acc: 0.7812 - o5_acc: 0.7233 - o6_acc: 0.6748 - o7_acc: 0.6376 - o8_acc: 0.6248 - val_loss: 5.0747 - val_o1_loss: 0.5078 - val_o2_loss: 0.5022 - val_o3_loss: 0.5702 - val_o4_loss: 0.6020 - val_o5_loss: 0.6371 - val_o6_loss: 0.7166 - val_o7_loss: 0.8016 - val_o8_loss: 0.7372 - val_o1_acc: 0.8010 - val_o2_acc: 0.7830 - val_o3_acc: 0.7510 - val_o4_acc: 0.7350 - val_o5_acc: 0.7080 - val_o6_acc: 0.6890 - val_o7_acc: 0.6260 - val_o8_acc: 0.6180\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.5569 - o1_loss: 0.4479 - o2_loss: 0.4104 - o3_loss: 0.4199 - o4_loss: 0.4924 - o5_loss: 0.5831 - o6_loss: 0.6819 - o7_loss: 0.7638 - o8_loss: 0.7576 - o1_acc: 0.8276 - o2_acc: 0.8219 - o3_acc: 0.8228 - o4_acc: 0.7887 - o5_acc: 0.7442 - o6_acc: 0.6932 - o7_acc: 0.6569 - o8_acc: 0.6392 - val_loss: 4.4147 - val_o1_loss: 0.4548 - val_o2_loss: 0.3958 - val_o3_loss: 0.3856 - val_o4_loss: 0.4727 - val_o5_loss: 0.5533 - val_o6_loss: 0.6617 - val_o7_loss: 0.7423 - val_o8_loss: 0.7484 - val_o1_acc: 0.8240 - val_o2_acc: 0.8300 - val_o3_acc: 0.8390 - val_o4_acc: 0.8000 - val_o5_acc: 0.7620 - val_o6_acc: 0.6990 - val_o7_acc: 0.6770 - val_o8_acc: 0.6510\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.4596 - o1_loss: 0.4303 - o2_loss: 0.3970 - o3_loss: 0.4025 - o4_loss: 0.4780 - o5_loss: 0.5704 - o6_loss: 0.6744 - o7_loss: 0.7596 - o8_loss: 0.7474 - o1_acc: 0.8351 - o2_acc: 0.8306 - o3_acc: 0.8326 - o4_acc: 0.7986 - o5_acc: 0.7479 - o6_acc: 0.6963 - o7_acc: 0.6568 - o8_acc: 0.6383 - val_loss: 4.3139 - val_o1_loss: 0.4390 - val_o2_loss: 0.3797 - val_o3_loss: 0.3923 - val_o4_loss: 0.4677 - val_o5_loss: 0.5463 - val_o6_loss: 0.6626 - val_o7_loss: 0.7303 - val_o8_loss: 0.6961 - val_o1_acc: 0.8280 - val_o2_acc: 0.8520 - val_o3_acc: 0.8320 - val_o4_acc: 0.7970 - val_o5_acc: 0.7560 - val_o6_acc: 0.7200 - val_o7_acc: 0.6780 - val_o8_acc: 0.6660\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.4388 - o1_loss: 0.4174 - o2_loss: 0.3894 - o3_loss: 0.4003 - o4_loss: 0.4745 - o5_loss: 0.5662 - o6_loss: 0.6793 - o7_loss: 0.7577 - o8_loss: 0.7542 - o1_acc: 0.8401 - o2_acc: 0.8355 - o3_acc: 0.8345 - o4_acc: 0.7967 - o5_acc: 0.7494 - o6_acc: 0.6951 - o7_acc: 0.6643 - o8_acc: 0.6440 - val_loss: 4.6978 - val_o1_loss: 0.4309 - val_o2_loss: 0.3915 - val_o3_loss: 0.4208 - val_o4_loss: 0.4920 - val_o5_loss: 0.5946 - val_o6_loss: 0.7113 - val_o7_loss: 0.8130 - val_o8_loss: 0.8437 - val_o1_acc: 0.8380 - val_o2_acc: 0.8450 - val_o3_acc: 0.8180 - val_o4_acc: 0.7940 - val_o5_acc: 0.7540 - val_o6_acc: 0.6880 - val_o7_acc: 0.6240 - val_o8_acc: 0.6220\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.8037 - o1_loss: 0.4256 - o2_loss: 0.4149 - o3_loss: 0.4459 - o4_loss: 0.5288 - o5_loss: 0.6326 - o6_loss: 0.7471 - o7_loss: 0.8200 - o8_loss: 0.7889 - o1_acc: 0.8341 - o2_acc: 0.8283 - o3_acc: 0.8182 - o4_acc: 0.7807 - o5_acc: 0.7286 - o6_acc: 0.6760 - o7_acc: 0.6387 - o8_acc: 0.6304 - val_loss: 4.4783 - val_o1_loss: 0.4078 - val_o2_loss: 0.3650 - val_o3_loss: 0.3745 - val_o4_loss: 0.4591 - val_o5_loss: 0.5484 - val_o6_loss: 0.7175 - val_o7_loss: 0.8493 - val_o8_loss: 0.7567 - val_o1_acc: 0.8400 - val_o2_acc: 0.8590 - val_o3_acc: 0.8430 - val_o4_acc: 0.8110 - val_o5_acc: 0.7520 - val_o6_acc: 0.6740 - val_o7_acc: 0.6080 - val_o8_acc: 0.6140\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.4968 - o1_loss: 0.3992 - o2_loss: 0.4025 - o3_loss: 0.4330 - o4_loss: 0.4976 - o5_loss: 0.5770 - o6_loss: 0.6756 - o7_loss: 0.7603 - o8_loss: 0.7516 - o1_acc: 0.8486 - o2_acc: 0.8358 - o3_acc: 0.8274 - o4_acc: 0.7987 - o5_acc: 0.7508 - o6_acc: 0.7054 - o7_acc: 0.6637 - o8_acc: 0.6410 - val_loss: 4.6199 - val_o1_loss: 0.4176 - val_o2_loss: 0.3762 - val_o3_loss: 0.3961 - val_o4_loss: 0.4833 - val_o5_loss: 0.5704 - val_o6_loss: 0.6859 - val_o7_loss: 0.8030 - val_o8_loss: 0.8875 - val_o1_acc: 0.8250 - val_o2_acc: 0.8410 - val_o3_acc: 0.8320 - val_o4_acc: 0.8100 - val_o5_acc: 0.7530 - val_o6_acc: 0.6950 - val_o7_acc: 0.6420 - val_o8_acc: 0.5860\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.1615 - o1_loss: 0.3761 - o2_loss: 0.3598 - o3_loss: 0.3686 - o4_loss: 0.4419 - o5_loss: 0.5368 - o6_loss: 0.6415 - o7_loss: 0.7213 - o8_loss: 0.7155 - o1_acc: 0.8576 - o2_acc: 0.8590 - o3_acc: 0.8539 - o4_acc: 0.8194 - o5_acc: 0.7671 - o6_acc: 0.7132 - o7_acc: 0.6806 - o8_acc: 0.6560 - val_loss: 4.2628 - val_o1_loss: 0.3802 - val_o2_loss: 0.3575 - val_o3_loss: 0.3771 - val_o4_loss: 0.4669 - val_o5_loss: 0.5352 - val_o6_loss: 0.6680 - val_o7_loss: 0.7611 - val_o8_loss: 0.7168 - val_o1_acc: 0.8520 - val_o2_acc: 0.8680 - val_o3_acc: 0.8300 - val_o4_acc: 0.7960 - val_o5_acc: 0.7640 - val_o6_acc: 0.7110 - val_o7_acc: 0.6440 - val_o8_acc: 0.6430\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.0826 - o1_loss: 0.3569 - o2_loss: 0.3459 - o3_loss: 0.3558 - o4_loss: 0.4267 - o5_loss: 0.5250 - o6_loss: 0.6341 - o7_loss: 0.7214 - o8_loss: 0.7166 - o1_acc: 0.8698 - o2_acc: 0.8642 - o3_acc: 0.8577 - o4_acc: 0.8251 - o5_acc: 0.7718 - o6_acc: 0.7168 - o7_acc: 0.6799 - o8_acc: 0.6575 - val_loss: 4.0425 - val_o1_loss: 0.3589 - val_o2_loss: 0.3334 - val_o3_loss: 0.3478 - val_o4_loss: 0.4357 - val_o5_loss: 0.5105 - val_o6_loss: 0.6360 - val_o7_loss: 0.7081 - val_o8_loss: 0.7123 - val_o1_acc: 0.8660 - val_o2_acc: 0.8760 - val_o3_acc: 0.8490 - val_o4_acc: 0.8180 - val_o5_acc: 0.7730 - val_o6_acc: 0.7240 - val_o7_acc: 0.6920 - val_o8_acc: 0.6510\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.3359 - o1_loss: 0.3460 - o2_loss: 0.3499 - o3_loss: 0.3676 - o4_loss: 0.4463 - o5_loss: 0.5679 - o6_loss: 0.6933 - o7_loss: 0.7892 - o8_loss: 0.7756 - o1_acc: 0.8764 - o2_acc: 0.8633 - o3_acc: 0.8488 - o4_acc: 0.8169 - o5_acc: 0.7534 - o6_acc: 0.7015 - o7_acc: 0.6630 - o8_acc: 0.6452 - val_loss: 4.0820 - val_o1_loss: 0.3542 - val_o2_loss: 0.3442 - val_o3_loss: 0.3634 - val_o4_loss: 0.4521 - val_o5_loss: 0.5233 - val_o6_loss: 0.6369 - val_o7_loss: 0.7272 - val_o8_loss: 0.6807 - val_o1_acc: 0.8690 - val_o2_acc: 0.8780 - val_o3_acc: 0.8460 - val_o4_acc: 0.8100 - val_o5_acc: 0.7510 - val_o6_acc: 0.7200 - val_o7_acc: 0.6820 - val_o8_acc: 0.6610\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.9673 - o1_loss: 0.3272 - o2_loss: 0.3272 - o3_loss: 0.3382 - o4_loss: 0.4108 - o5_loss: 0.5104 - o6_loss: 0.6235 - o7_loss: 0.7137 - o8_loss: 0.7162 - o1_acc: 0.8863 - o2_acc: 0.8782 - o3_acc: 0.8675 - o4_acc: 0.8337 - o5_acc: 0.7796 - o6_acc: 0.7247 - o7_acc: 0.6828 - o8_acc: 0.6563 - val_loss: 3.8785 - val_o1_loss: 0.3402 - val_o2_loss: 0.3110 - val_o3_loss: 0.3335 - val_o4_loss: 0.4064 - val_o5_loss: 0.4938 - val_o6_loss: 0.6178 - val_o7_loss: 0.7128 - val_o8_loss: 0.6630 - val_o1_acc: 0.8740 - val_o2_acc: 0.8860 - val_o3_acc: 0.8620 - val_o4_acc: 0.8410 - val_o5_acc: 0.7780 - val_o6_acc: 0.7410 - val_o7_acc: 0.6910 - val_o8_acc: 0.6750\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.9450 - o1_loss: 0.3113 - o2_loss: 0.3152 - o3_loss: 0.3300 - o4_loss: 0.4007 - o5_loss: 0.5085 - o6_loss: 0.6275 - o7_loss: 0.7247 - o8_loss: 0.7271 - o1_acc: 0.8934 - o2_acc: 0.8891 - o3_acc: 0.8728 - o4_acc: 0.8428 - o5_acc: 0.7780 - o6_acc: 0.7210 - o7_acc: 0.6769 - o8_acc: 0.6521 - val_loss: 3.9949 - val_o1_loss: 0.3243 - val_o2_loss: 0.3039 - val_o3_loss: 0.3152 - val_o4_loss: 0.4171 - val_o5_loss: 0.5047 - val_o6_loss: 0.6387 - val_o7_loss: 0.7720 - val_o8_loss: 0.7190 - val_o1_acc: 0.8770 - val_o2_acc: 0.8900 - val_o3_acc: 0.8720 - val_o4_acc: 0.8280 - val_o5_acc: 0.7740 - val_o6_acc: 0.7320 - val_o7_acc: 0.6380 - val_o8_acc: 0.6580\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.1809 - o1_loss: 0.3031 - o2_loss: 0.3196 - o3_loss: 0.3477 - o4_loss: 0.4347 - o5_loss: 0.5609 - o6_loss: 0.6809 - o7_loss: 0.7821 - o8_loss: 0.7520 - o1_acc: 0.8978 - o2_acc: 0.8867 - o3_acc: 0.8669 - o4_acc: 0.8302 - o5_acc: 0.7691 - o6_acc: 0.7073 - o7_acc: 0.6720 - o8_acc: 0.6519 - val_loss: 3.9817 - val_o1_loss: 0.3158 - val_o2_loss: 0.3291 - val_o3_loss: 0.3644 - val_o4_loss: 0.4349 - val_o5_loss: 0.5165 - val_o6_loss: 0.6222 - val_o7_loss: 0.7252 - val_o8_loss: 0.6735 - val_o1_acc: 0.8850 - val_o2_acc: 0.8740 - val_o3_acc: 0.8530 - val_o4_acc: 0.8250 - val_o5_acc: 0.7670 - val_o6_acc: 0.7210 - val_o7_acc: 0.6760 - val_o8_acc: 0.6770\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.7635 - o1_loss: 0.2796 - o2_loss: 0.2936 - o3_loss: 0.3147 - o4_loss: 0.3870 - o5_loss: 0.4880 - o6_loss: 0.6070 - o7_loss: 0.6919 - o8_loss: 0.7016 - o1_acc: 0.9079 - o2_acc: 0.9000 - o3_acc: 0.8791 - o4_acc: 0.8454 - o5_acc: 0.7902 - o6_acc: 0.7330 - o7_acc: 0.6933 - o8_acc: 0.6648 - val_loss: 3.9151 - val_o1_loss: 0.3155 - val_o2_loss: 0.3077 - val_o3_loss: 0.3322 - val_o4_loss: 0.3995 - val_o5_loss: 0.4981 - val_o6_loss: 0.6313 - val_o7_loss: 0.7431 - val_o8_loss: 0.6877 - val_o1_acc: 0.8890 - val_o2_acc: 0.8810 - val_o3_acc: 0.8620 - val_o4_acc: 0.8490 - val_o5_acc: 0.7770 - val_o6_acc: 0.7190 - val_o7_acc: 0.6650 - val_o8_acc: 0.6740\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.2920 - o1_loss: 0.2947 - o2_loss: 0.3335 - o3_loss: 0.3853 - o4_loss: 0.4657 - o5_loss: 0.5703 - o6_loss: 0.6939 - o7_loss: 0.7876 - o8_loss: 0.7611 - o1_acc: 0.9016 - o2_acc: 0.8858 - o3_acc: 0.8575 - o4_acc: 0.8233 - o5_acc: 0.7681 - o6_acc: 0.7047 - o7_acc: 0.6554 - o8_acc: 0.6465 - val_loss: 3.7846 - val_o1_loss: 0.2921 - val_o2_loss: 0.2854 - val_o3_loss: 0.3126 - val_o4_loss: 0.3923 - val_o5_loss: 0.4940 - val_o6_loss: 0.6072 - val_o7_loss: 0.7146 - val_o8_loss: 0.6863 - val_o1_acc: 0.9000 - val_o2_acc: 0.9140 - val_o3_acc: 0.8770 - val_o4_acc: 0.8500 - val_o5_acc: 0.7870 - val_o6_acc: 0.7340 - val_o7_acc: 0.6890 - val_o8_acc: 0.6650\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.6263 - o1_loss: 0.2576 - o2_loss: 0.2721 - o3_loss: 0.2942 - o4_loss: 0.3655 - o5_loss: 0.4742 - o6_loss: 0.5955 - o7_loss: 0.6820 - o8_loss: 0.6851 - o1_acc: 0.9193 - o2_acc: 0.9136 - o3_acc: 0.8918 - o4_acc: 0.8603 - o5_acc: 0.7978 - o6_acc: 0.7406 - o7_acc: 0.7006 - o8_acc: 0.6775 - val_loss: 3.7763 - val_o1_loss: 0.2686 - val_o2_loss: 0.2747 - val_o3_loss: 0.3111 - val_o4_loss: 0.4179 - val_o5_loss: 0.5104 - val_o6_loss: 0.6252 - val_o7_loss: 0.7079 - val_o8_loss: 0.6605 - val_o1_acc: 0.9120 - val_o2_acc: 0.9130 - val_o3_acc: 0.8730 - val_o4_acc: 0.8360 - val_o5_acc: 0.7700 - val_o6_acc: 0.7240 - val_o7_acc: 0.6840 - val_o8_acc: 0.6820\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.5838 - o1_loss: 0.2437 - o2_loss: 0.2601 - o3_loss: 0.2852 - o4_loss: 0.3573 - o5_loss: 0.4653 - o6_loss: 0.5906 - o7_loss: 0.6875 - o8_loss: 0.6940 - o1_acc: 0.9261 - o2_acc: 0.9195 - o3_acc: 0.8950 - o4_acc: 0.8558 - o5_acc: 0.8012 - o6_acc: 0.7369 - o7_acc: 0.6941 - o8_acc: 0.6735 - val_loss: 3.6373 - val_o1_loss: 0.2501 - val_o2_loss: 0.2440 - val_o3_loss: 0.2779 - val_o4_loss: 0.3712 - val_o5_loss: 0.4645 - val_o6_loss: 0.6016 - val_o7_loss: 0.7080 - val_o8_loss: 0.7201 - val_o1_acc: 0.9180 - val_o2_acc: 0.9370 - val_o3_acc: 0.8970 - val_o4_acc: 0.8460 - val_o5_acc: 0.8010 - val_o6_acc: 0.7420 - val_o7_acc: 0.6850 - val_o8_acc: 0.6660\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 3.7613 - o1_loss: 0.2331 - o2_loss: 0.2574 - o3_loss: 0.2926 - o4_loss: 0.3763 - o5_loss: 0.5046 - o6_loss: 0.6408 - o7_loss: 0.7312 - o8_loss: 0.7252 - o1_acc: 0.9310 - o2_acc: 0.9231 - o3_acc: 0.8943 - o4_acc: 0.8573 - o5_acc: 0.7935 - o6_acc: 0.7281 - o7_acc: 0.6865 - o8_acc: 0.6567 - val_loss: 3.6888 - val_o1_loss: 0.2381 - val_o2_loss: 0.2414 - val_o3_loss: 0.2683 - val_o4_loss: 0.3625 - val_o5_loss: 0.4589 - val_o6_loss: 0.6107 - val_o7_loss: 0.7429 - val_o8_loss: 0.7660 - val_o1_acc: 0.9260 - val_o2_acc: 0.9310 - val_o3_acc: 0.9010 - val_o4_acc: 0.8530 - val_o5_acc: 0.8000 - val_o6_acc: 0.7250 - val_o7_acc: 0.6720 - val_o8_acc: 0.6360\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.5120 - o1_loss: 0.2210 - o2_loss: 0.2423 - o3_loss: 0.2682 - o4_loss: 0.3414 - o5_loss: 0.4532 - o6_loss: 0.5843 - o7_loss: 0.6950 - o8_loss: 0.7068 - o1_acc: 0.9353 - o2_acc: 0.9290 - o3_acc: 0.9048 - o4_acc: 0.8669 - o5_acc: 0.8084 - o6_acc: 0.7391 - o7_acc: 0.6895 - o8_acc: 0.6639 - val_loss: 3.6244 - val_o1_loss: 0.2417 - val_o2_loss: 0.2488 - val_o3_loss: 0.2832 - val_o4_loss: 0.3643 - val_o5_loss: 0.4794 - val_o6_loss: 0.6154 - val_o7_loss: 0.7255 - val_o8_loss: 0.6661 - val_o1_acc: 0.9230 - val_o2_acc: 0.9260 - val_o3_acc: 0.8850 - val_o4_acc: 0.8530 - val_o5_acc: 0.7850 - val_o6_acc: 0.7390 - val_o7_acc: 0.6910 - val_o8_acc: 0.6830\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.5753 - o1_loss: 0.2160 - o2_loss: 0.2405 - o3_loss: 0.2700 - o4_loss: 0.3533 - o5_loss: 0.4740 - o6_loss: 0.6130 - o7_loss: 0.7048 - o8_loss: 0.7037 - o1_acc: 0.9371 - o2_acc: 0.9294 - o3_acc: 0.9040 - o4_acc: 0.8643 - o5_acc: 0.8004 - o6_acc: 0.7354 - o7_acc: 0.6930 - o8_acc: 0.6716 - val_loss: 6.6625 - val_o1_loss: 0.2472 - val_o2_loss: 0.3237 - val_o3_loss: 0.4687 - val_o4_loss: 0.6524 - val_o5_loss: 0.8665 - val_o6_loss: 1.2958 - val_o7_loss: 1.5467 - val_o8_loss: 1.2614 - val_o1_acc: 0.9230 - val_o2_acc: 0.8780 - val_o3_acc: 0.8060 - val_o4_acc: 0.7170 - val_o5_acc: 0.6340 - val_o6_acc: 0.4910 - val_o7_acc: 0.4340 - val_o8_acc: 0.5320\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.6048 - o1_loss: 0.2117 - o2_loss: 0.2443 - o3_loss: 0.2858 - o4_loss: 0.3595 - o5_loss: 0.4786 - o6_loss: 0.6051 - o7_loss: 0.7059 - o8_loss: 0.7137 - o1_acc: 0.9397 - o2_acc: 0.9253 - o3_acc: 0.9012 - o4_acc: 0.8617 - o5_acc: 0.7991 - o6_acc: 0.7436 - o7_acc: 0.6987 - o8_acc: 0.6769 - val_loss: 3.3455 - val_o1_loss: 0.2255 - val_o2_loss: 0.2268 - val_o3_loss: 0.2587 - val_o4_loss: 0.3363 - val_o5_loss: 0.4289 - val_o6_loss: 0.5627 - val_o7_loss: 0.6663 - val_o8_loss: 0.6403 - val_o1_acc: 0.9310 - val_o2_acc: 0.9330 - val_o3_acc: 0.9040 - val_o4_acc: 0.8770 - val_o5_acc: 0.8220 - val_o6_acc: 0.7580 - val_o7_acc: 0.7140 - val_o8_acc: 0.7030\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.5002 - o1_loss: 0.2058 - o2_loss: 0.2427 - o3_loss: 0.2864 - o4_loss: 0.3599 - o5_loss: 0.4656 - o6_loss: 0.5829 - o7_loss: 0.6761 - o8_loss: 0.6808 - o1_acc: 0.9405 - o2_acc: 0.9243 - o3_acc: 0.8977 - o4_acc: 0.8634 - o5_acc: 0.8067 - o6_acc: 0.7420 - o7_acc: 0.7052 - o8_acc: 0.6821 - val_loss: 3.4478 - val_o1_loss: 0.2151 - val_o2_loss: 0.2232 - val_o3_loss: 0.2603 - val_o4_loss: 0.3541 - val_o5_loss: 0.4464 - val_o6_loss: 0.5892 - val_o7_loss: 0.6820 - val_o8_loss: 0.6775 - val_o1_acc: 0.9360 - val_o2_acc: 0.9350 - val_o3_acc: 0.9130 - val_o4_acc: 0.8600 - val_o5_acc: 0.8020 - val_o6_acc: 0.7430 - val_o7_acc: 0.6990 - val_o8_acc: 0.6700\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.2558 - o1_loss: 0.1891 - o2_loss: 0.2101 - o3_loss: 0.2371 - o4_loss: 0.3066 - o5_loss: 0.4242 - o6_loss: 0.5603 - o7_loss: 0.6553 - o8_loss: 0.6732 - o1_acc: 0.9487 - o2_acc: 0.9416 - o3_acc: 0.9210 - o4_acc: 0.8859 - o5_acc: 0.8214 - o6_acc: 0.7527 - o7_acc: 0.7078 - o8_acc: 0.6839 - val_loss: 3.3134 - val_o1_loss: 0.1992 - val_o2_loss: 0.2066 - val_o3_loss: 0.2381 - val_o4_loss: 0.3186 - val_o5_loss: 0.4135 - val_o6_loss: 0.5620 - val_o7_loss: 0.6870 - val_o8_loss: 0.6884 - val_o1_acc: 0.9390 - val_o2_acc: 0.9450 - val_o3_acc: 0.9180 - val_o4_acc: 0.8750 - val_o5_acc: 0.8180 - val_o6_acc: 0.7550 - val_o7_acc: 0.6860 - val_o8_acc: 0.6730\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.3516 - o1_loss: 0.1820 - o2_loss: 0.2061 - o3_loss: 0.2380 - o4_loss: 0.3112 - o5_loss: 0.4433 - o6_loss: 0.5920 - o7_loss: 0.6855 - o8_loss: 0.6935 - o1_acc: 0.9514 - o2_acc: 0.9429 - o3_acc: 0.9212 - o4_acc: 0.8825 - o5_acc: 0.8152 - o6_acc: 0.7440 - o7_acc: 0.7037 - o8_acc: 0.6740 - val_loss: 3.4360 - val_o1_loss: 0.1965 - val_o2_loss: 0.2035 - val_o3_loss: 0.2542 - val_o4_loss: 0.3373 - val_o5_loss: 0.4607 - val_o6_loss: 0.5880 - val_o7_loss: 0.6890 - val_o8_loss: 0.7067 - val_o1_acc: 0.9400 - val_o2_acc: 0.9440 - val_o3_acc: 0.8990 - val_o4_acc: 0.8600 - val_o5_acc: 0.7990 - val_o6_acc: 0.7370 - val_o7_acc: 0.7060 - val_o8_acc: 0.6740\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.1911 - o1_loss: 0.1742 - o2_loss: 0.1967 - o3_loss: 0.2269 - o4_loss: 0.2967 - o5_loss: 0.4165 - o6_loss: 0.5579 - o7_loss: 0.6541 - o8_loss: 0.6681 - o1_acc: 0.9534 - o2_acc: 0.9457 - o3_acc: 0.9248 - o4_acc: 0.8888 - o5_acc: 0.8251 - o6_acc: 0.7485 - o7_acc: 0.7145 - o8_acc: 0.6916 - val_loss: 3.2938 - val_o1_loss: 0.1940 - val_o2_loss: 0.2049 - val_o3_loss: 0.2468 - val_o4_loss: 0.3400 - val_o5_loss: 0.4575 - val_o6_loss: 0.5727 - val_o7_loss: 0.6554 - val_o8_loss: 0.6225 - val_o1_acc: 0.9380 - val_o2_acc: 0.9430 - val_o3_acc: 0.9140 - val_o4_acc: 0.8640 - val_o5_acc: 0.8010 - val_o6_acc: 0.7530 - val_o7_acc: 0.7100 - val_o8_acc: 0.7140\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 3.1003 - o1_loss: 0.1677 - o2_loss: 0.1886 - o3_loss: 0.2160 - o4_loss: 0.2852 - o5_loss: 0.4059 - o6_loss: 0.5431 - o7_loss: 0.6368 - o8_loss: 0.6569 - o1_acc: 0.9556 - o2_acc: 0.9468 - o3_acc: 0.9290 - o4_acc: 0.8931 - o5_acc: 0.8282 - o6_acc: 0.7588 - o7_acc: 0.7244 - o8_acc: 0.6982 - val_loss: 3.2256 - val_o1_loss: 0.1820 - val_o2_loss: 0.1952 - val_o3_loss: 0.2272 - val_o4_loss: 0.3053 - val_o5_loss: 0.4235 - val_o6_loss: 0.5579 - val_o7_loss: 0.6796 - val_o8_loss: 0.6549 - val_o1_acc: 0.9420 - val_o2_acc: 0.9490 - val_o3_acc: 0.9180 - val_o4_acc: 0.8820 - val_o5_acc: 0.8100 - val_o6_acc: 0.7490 - val_o7_acc: 0.6900 - val_o8_acc: 0.6990\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.2494 - o1_loss: 0.1660 - o2_loss: 0.1912 - o3_loss: 0.2276 - o4_loss: 0.3039 - o5_loss: 0.4331 - o6_loss: 0.5796 - o7_loss: 0.6738 - o8_loss: 0.6741 - o1_acc: 0.9543 - o2_acc: 0.9466 - o3_acc: 0.9257 - o4_acc: 0.8891 - o5_acc: 0.8195 - o6_acc: 0.7495 - o7_acc: 0.7055 - o8_acc: 0.6842 - val_loss: 3.4822 - val_o1_loss: 0.1938 - val_o2_loss: 0.2469 - val_o3_loss: 0.3402 - val_o4_loss: 0.4086 - val_o5_loss: 0.4725 - val_o6_loss: 0.5711 - val_o7_loss: 0.6433 - val_o8_loss: 0.6058 - val_o1_acc: 0.9430 - val_o2_acc: 0.9100 - val_o3_acc: 0.8610 - val_o4_acc: 0.8350 - val_o5_acc: 0.8010 - val_o6_acc: 0.7520 - val_o7_acc: 0.7230 - val_o8_acc: 0.7190\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.2706 - o1_loss: 0.1698 - o2_loss: 0.2143 - o3_loss: 0.2580 - o4_loss: 0.3322 - o5_loss: 0.4373 - o6_loss: 0.5597 - o7_loss: 0.6408 - o8_loss: 0.6586 - o1_acc: 0.9527 - o2_acc: 0.9346 - o3_acc: 0.9136 - o4_acc: 0.8798 - o5_acc: 0.8239 - o6_acc: 0.7541 - o7_acc: 0.7259 - o8_acc: 0.6972 - val_loss: 3.1068 - val_o1_loss: 0.1744 - val_o2_loss: 0.1886 - val_o3_loss: 0.2179 - val_o4_loss: 0.2959 - val_o5_loss: 0.4191 - val_o6_loss: 0.5452 - val_o7_loss: 0.6398 - val_o8_loss: 0.6259 - val_o1_acc: 0.9540 - val_o2_acc: 0.9540 - val_o3_acc: 0.9280 - val_o4_acc: 0.8820 - val_o5_acc: 0.8180 - val_o6_acc: 0.7620 - val_o7_acc: 0.7230 - val_o8_acc: 0.7160\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.9642 - o1_loss: 0.1505 - o2_loss: 0.1733 - o3_loss: 0.2027 - o4_loss: 0.2660 - o5_loss: 0.3897 - o6_loss: 0.5249 - o7_loss: 0.6191 - o8_loss: 0.6381 - o1_acc: 0.9599 - o2_acc: 0.9531 - o3_acc: 0.9354 - o4_acc: 0.9013 - o5_acc: 0.8347 - o6_acc: 0.7698 - o7_acc: 0.7327 - o8_acc: 0.7093 - val_loss: 3.1399 - val_o1_loss: 0.1792 - val_o2_loss: 0.1940 - val_o3_loss: 0.2332 - val_o4_loss: 0.2963 - val_o5_loss: 0.3961 - val_o6_loss: 0.5419 - val_o7_loss: 0.6494 - val_o8_loss: 0.6498 - val_o1_acc: 0.9490 - val_o2_acc: 0.9390 - val_o3_acc: 0.9160 - val_o4_acc: 0.8820 - val_o5_acc: 0.8360 - val_o6_acc: 0.7710 - val_o7_acc: 0.7180 - val_o8_acc: 0.6910\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.9158 - o1_loss: 0.1454 - o2_loss: 0.1701 - o3_loss: 0.1959 - o4_loss: 0.2618 - o5_loss: 0.3853 - o6_loss: 0.5228 - o7_loss: 0.6107 - o8_loss: 0.6238 - o1_acc: 0.9612 - o2_acc: 0.9521 - o3_acc: 0.9383 - o4_acc: 0.9045 - o5_acc: 0.8370 - o6_acc: 0.7669 - o7_acc: 0.7463 - o8_acc: 0.7205 - val_loss: 3.1570 - val_o1_loss: 0.1695 - val_o2_loss: 0.1866 - val_o3_loss: 0.2136 - val_o4_loss: 0.3004 - val_o5_loss: 0.4477 - val_o6_loss: 0.5644 - val_o7_loss: 0.6568 - val_o8_loss: 0.6180 - val_o1_acc: 0.9490 - val_o2_acc: 0.9520 - val_o3_acc: 0.9270 - val_o4_acc: 0.8880 - val_o5_acc: 0.8050 - val_o6_acc: 0.7460 - val_o7_acc: 0.7120 - val_o8_acc: 0.7180\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.1154 - o1_loss: 0.1410 - o2_loss: 0.1696 - o3_loss: 0.1988 - o4_loss: 0.2879 - o5_loss: 0.4454 - o6_loss: 0.5780 - o7_loss: 0.6557 - o8_loss: 0.6390 - o1_acc: 0.9626 - o2_acc: 0.9569 - o3_acc: 0.9344 - o4_acc: 0.8991 - o5_acc: 0.8301 - o6_acc: 0.7626 - o7_acc: 0.7287 - o8_acc: 0.7171 - val_loss: 3.0814 - val_o1_loss: 0.1672 - val_o2_loss: 0.1748 - val_o3_loss: 0.2109 - val_o4_loss: 0.2988 - val_o5_loss: 0.4078 - val_o6_loss: 0.5528 - val_o7_loss: 0.6660 - val_o8_loss: 0.6030 - val_o1_acc: 0.9500 - val_o2_acc: 0.9530 - val_o3_acc: 0.9180 - val_o4_acc: 0.8840 - val_o5_acc: 0.8260 - val_o6_acc: 0.7750 - val_o7_acc: 0.7190 - val_o8_acc: 0.7410\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.7866 - o1_loss: 0.1381 - o2_loss: 0.1612 - o3_loss: 0.1873 - o4_loss: 0.2497 - o5_loss: 0.3740 - o6_loss: 0.5049 - o7_loss: 0.5806 - o8_loss: 0.5909 - o1_acc: 0.9647 - o2_acc: 0.9591 - o3_acc: 0.9412 - o4_acc: 0.9094 - o5_acc: 0.8474 - o6_acc: 0.7865 - o7_acc: 0.7652 - o8_acc: 0.7379 - val_loss: 2.8396 - val_o1_loss: 0.1537 - val_o2_loss: 0.1621 - val_o3_loss: 0.1999 - val_o4_loss: 0.2736 - val_o5_loss: 0.3970 - val_o6_loss: 0.5195 - val_o7_loss: 0.5896 - val_o8_loss: 0.5443 - val_o1_acc: 0.9530 - val_o2_acc: 0.9600 - val_o3_acc: 0.9270 - val_o4_acc: 0.8980 - val_o5_acc: 0.8310 - val_o6_acc: 0.7610 - val_o7_acc: 0.7470 - val_o8_acc: 0.7530\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.7773 - o1_loss: 0.1321 - o2_loss: 0.1540 - o3_loss: 0.1835 - o4_loss: 0.2467 - o5_loss: 0.3667 - o6_loss: 0.5046 - o7_loss: 0.5888 - o8_loss: 0.6008 - o1_acc: 0.9653 - o2_acc: 0.9597 - o3_acc: 0.9452 - o4_acc: 0.9079 - o5_acc: 0.8490 - o6_acc: 0.7757 - o7_acc: 0.7501 - o8_acc: 0.7323 - val_loss: 3.6951 - val_o1_loss: 0.1679 - val_o2_loss: 0.2182 - val_o3_loss: 0.2843 - val_o4_loss: 0.3821 - val_o5_loss: 0.5235 - val_o6_loss: 0.6320 - val_o7_loss: 0.7521 - val_o8_loss: 0.7350 - val_o1_acc: 0.9530 - val_o2_acc: 0.9360 - val_o3_acc: 0.8880 - val_o4_acc: 0.8350 - val_o5_acc: 0.7760 - val_o6_acc: 0.7300 - val_o7_acc: 0.6470 - val_o8_acc: 0.6710\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.0445 - o1_loss: 0.1335 - o2_loss: 0.1703 - o3_loss: 0.2083 - o4_loss: 0.2842 - o5_loss: 0.4141 - o6_loss: 0.5743 - o7_loss: 0.6288 - o8_loss: 0.6311 - o1_acc: 0.9652 - o2_acc: 0.9534 - o3_acc: 0.9307 - o4_acc: 0.8981 - o5_acc: 0.8302 - o6_acc: 0.7651 - o7_acc: 0.7483 - o8_acc: 0.7305 - val_loss: 2.8197 - val_o1_loss: 0.1487 - val_o2_loss: 0.1594 - val_o3_loss: 0.2020 - val_o4_loss: 0.2665 - val_o5_loss: 0.4091 - val_o6_loss: 0.5063 - val_o7_loss: 0.5893 - val_o8_loss: 0.5385 - val_o1_acc: 0.9560 - val_o2_acc: 0.9520 - val_o3_acc: 0.9300 - val_o4_acc: 0.9020 - val_o5_acc: 0.8260 - val_o6_acc: 0.7790 - val_o7_acc: 0.7610 - val_o8_acc: 0.7680\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.6063 - o1_loss: 0.1243 - o2_loss: 0.1468 - o3_loss: 0.1693 - o4_loss: 0.2307 - o5_loss: 0.3548 - o6_loss: 0.4833 - o7_loss: 0.5493 - o8_loss: 0.5477 - o1_acc: 0.9684 - o2_acc: 0.9626 - o3_acc: 0.9483 - o4_acc: 0.9166 - o5_acc: 0.8565 - o6_acc: 0.7915 - o7_acc: 0.7757 - o8_acc: 0.7665 - val_loss: 2.6774 - val_o1_loss: 0.1425 - val_o2_loss: 0.1496 - val_o3_loss: 0.1746 - val_o4_loss: 0.2261 - val_o5_loss: 0.3661 - val_o6_loss: 0.4881 - val_o7_loss: 0.5823 - val_o8_loss: 0.5481 - val_o1_acc: 0.9580 - val_o2_acc: 0.9650 - val_o3_acc: 0.9390 - val_o4_acc: 0.9200 - val_o5_acc: 0.8470 - val_o6_acc: 0.7860 - val_o7_acc: 0.7500 - val_o8_acc: 0.7700\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.8806 - o1_loss: 0.1276 - o2_loss: 0.1562 - o3_loss: 0.1929 - o4_loss: 0.2754 - o5_loss: 0.4049 - o6_loss: 0.5427 - o7_loss: 0.6044 - o8_loss: 0.5766 - o1_acc: 0.9640 - o2_acc: 0.9579 - o3_acc: 0.9357 - o4_acc: 0.9008 - o5_acc: 0.8362 - o6_acc: 0.7719 - o7_acc: 0.7545 - o8_acc: 0.7540 - val_loss: 2.6234 - val_o1_loss: 0.1450 - val_o2_loss: 0.1472 - val_o3_loss: 0.1778 - val_o4_loss: 0.2343 - val_o5_loss: 0.3670 - val_o6_loss: 0.4855 - val_o7_loss: 0.5610 - val_o8_loss: 0.5056 - val_o1_acc: 0.9540 - val_o2_acc: 0.9660 - val_o3_acc: 0.9400 - val_o4_acc: 0.9160 - val_o5_acc: 0.8450 - val_o6_acc: 0.8010 - val_o7_acc: 0.7530 - val_o8_acc: 0.7830\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.4690 - o1_loss: 0.1154 - o2_loss: 0.1382 - o3_loss: 0.1620 - o4_loss: 0.2201 - o5_loss: 0.3389 - o6_loss: 0.4675 - o7_loss: 0.5201 - o8_loss: 0.5068 - o1_acc: 0.9710 - o2_acc: 0.9659 - o3_acc: 0.9507 - o4_acc: 0.9218 - o5_acc: 0.8612 - o6_acc: 0.7959 - o7_acc: 0.7889 - o8_acc: 0.7822 - val_loss: 2.6222 - val_o1_loss: 0.1395 - val_o2_loss: 0.1551 - val_o3_loss: 0.1807 - val_o4_loss: 0.2345 - val_o5_loss: 0.3799 - val_o6_loss: 0.4778 - val_o7_loss: 0.5700 - val_o8_loss: 0.4846 - val_o1_acc: 0.9610 - val_o2_acc: 0.9670 - val_o3_acc: 0.9370 - val_o4_acc: 0.9220 - val_o5_acc: 0.8420 - val_o6_acc: 0.8070 - val_o7_acc: 0.7600 - val_o8_acc: 0.7940\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.4762 - o1_loss: 0.1109 - o2_loss: 0.1348 - o3_loss: 0.1603 - o4_loss: 0.2175 - o5_loss: 0.3376 - o6_loss: 0.4714 - o7_loss: 0.5298 - o8_loss: 0.5140 - o1_acc: 0.9717 - o2_acc: 0.9661 - o3_acc: 0.9508 - o4_acc: 0.9230 - o5_acc: 0.8634 - o6_acc: 0.7950 - o7_acc: 0.7815 - o8_acc: 0.7776 - val_loss: 2.5596 - val_o1_loss: 0.1279 - val_o2_loss: 0.1359 - val_o3_loss: 0.1720 - val_o4_loss: 0.2275 - val_o5_loss: 0.3472 - val_o6_loss: 0.4754 - val_o7_loss: 0.5697 - val_o8_loss: 0.5040 - val_o1_acc: 0.9620 - val_o2_acc: 0.9630 - val_o3_acc: 0.9420 - val_o4_acc: 0.9210 - val_o5_acc: 0.8510 - val_o6_acc: 0.7890 - val_o7_acc: 0.7500 - val_o8_acc: 0.7620\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.4197 - o1_loss: 0.1067 - o2_loss: 0.1308 - o3_loss: 0.1590 - o4_loss: 0.2164 - o5_loss: 0.3362 - o6_loss: 0.4680 - o7_loss: 0.5168 - o8_loss: 0.4858 - o1_acc: 0.9724 - o2_acc: 0.9680 - o3_acc: 0.9511 - o4_acc: 0.9249 - o5_acc: 0.8585 - o6_acc: 0.7943 - o7_acc: 0.7831 - o8_acc: 0.7946 - val_loss: 2.8293 - val_o1_loss: 0.1285 - val_o2_loss: 0.1504 - val_o3_loss: 0.2274 - val_o4_loss: 0.3361 - val_o5_loss: 0.4544 - val_o6_loss: 0.5268 - val_o7_loss: 0.5553 - val_o8_loss: 0.4505 - val_o1_acc: 0.9610 - val_o2_acc: 0.9520 - val_o3_acc: 0.9160 - val_o4_acc: 0.8750 - val_o5_acc: 0.8020 - val_o6_acc: 0.7870 - val_o7_acc: 0.7600 - val_o8_acc: 0.8080\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.3739 - o1_loss: 0.1062 - o2_loss: 0.1277 - o3_loss: 0.1545 - o4_loss: 0.2100 - o5_loss: 0.3301 - o6_loss: 0.4642 - o7_loss: 0.5123 - o8_loss: 0.4690 - o1_acc: 0.9722 - o2_acc: 0.9680 - o3_acc: 0.9527 - o4_acc: 0.9254 - o5_acc: 0.8642 - o6_acc: 0.7951 - o7_acc: 0.7888 - o8_acc: 0.8078 - val_loss: 2.4044 - val_o1_loss: 0.1331 - val_o2_loss: 0.1465 - val_o3_loss: 0.1646 - val_o4_loss: 0.2115 - val_o5_loss: 0.3418 - val_o6_loss: 0.4504 - val_o7_loss: 0.5249 - val_o8_loss: 0.4316 - val_o1_acc: 0.9600 - val_o2_acc: 0.9600 - val_o3_acc: 0.9470 - val_o4_acc: 0.9250 - val_o5_acc: 0.8490 - val_o6_acc: 0.8060 - val_o7_acc: 0.7800 - val_o8_acc: 0.8210\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.2631 - o1_loss: 0.1017 - o2_loss: 0.1215 - o3_loss: 0.1472 - o4_loss: 0.1992 - o5_loss: 0.3180 - o6_loss: 0.4448 - o7_loss: 0.4865 - o8_loss: 0.4441 - o1_acc: 0.9745 - o2_acc: 0.9708 - o3_acc: 0.9562 - o4_acc: 0.9309 - o5_acc: 0.8693 - o6_acc: 0.8093 - o7_acc: 0.8016 - o8_acc: 0.8144 - val_loss: 2.3396 - val_o1_loss: 0.1259 - val_o2_loss: 0.1451 - val_o3_loss: 0.1829 - val_o4_loss: 0.2452 - val_o5_loss: 0.3352 - val_o6_loss: 0.4401 - val_o7_loss: 0.4769 - val_o8_loss: 0.3882 - val_o1_acc: 0.9610 - val_o2_acc: 0.9600 - val_o3_acc: 0.9340 - val_o4_acc: 0.9170 - val_o5_acc: 0.8550 - val_o6_acc: 0.8200 - val_o7_acc: 0.8140 - val_o8_acc: 0.8460\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 2.4664 - o1_loss: 0.1045 - o2_loss: 0.1288 - o3_loss: 0.1639 - o4_loss: 0.2429 - o5_loss: 0.3901 - o6_loss: 0.5001 - o7_loss: 0.5106 - o8_loss: 0.4255 - o1_acc: 0.9736 - o2_acc: 0.9684 - o3_acc: 0.9500 - o4_acc: 0.9198 - o5_acc: 0.8574 - o6_acc: 0.8024 - o7_acc: 0.8079 - o8_acc: 0.8330 - val_loss: 2.1974 - val_o1_loss: 0.1195 - val_o2_loss: 0.1314 - val_o3_loss: 0.1637 - val_o4_loss: 0.2152 - val_o5_loss: 0.3258 - val_o6_loss: 0.4266 - val_o7_loss: 0.4555 - val_o8_loss: 0.3597 - val_o1_acc: 0.9640 - val_o2_acc: 0.9680 - val_o3_acc: 0.9510 - val_o4_acc: 0.9200 - val_o5_acc: 0.8550 - val_o6_acc: 0.8240 - val_o7_acc: 0.8170 - val_o8_acc: 0.8560\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 2.1916 - o1_loss: 0.0968 - o2_loss: 0.1170 - o3_loss: 0.1403 - o4_loss: 0.1956 - o5_loss: 0.3154 - o6_loss: 0.4426 - o7_loss: 0.4706 - o8_loss: 0.4134 - o1_acc: 0.9775 - o2_acc: 0.9706 - o3_acc: 0.9588 - o4_acc: 0.9309 - o5_acc: 0.8709 - o6_acc: 0.8040 - o7_acc: 0.8068 - o8_acc: 0.8307 - val_loss: 2.1948 - val_o1_loss: 0.1148 - val_o2_loss: 0.1221 - val_o3_loss: 0.1534 - val_o4_loss: 0.2037 - val_o5_loss: 0.3317 - val_o6_loss: 0.4398 - val_o7_loss: 0.4847 - val_o8_loss: 0.3446 - val_o1_acc: 0.9670 - val_o2_acc: 0.9680 - val_o3_acc: 0.9500 - val_o4_acc: 0.9350 - val_o5_acc: 0.8600 - val_o6_acc: 0.8080 - val_o7_acc: 0.7950 - val_o8_acc: 0.8560\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.0335 - o1_loss: 0.0930 - o2_loss: 0.1125 - o3_loss: 0.1352 - o4_loss: 0.1885 - o5_loss: 0.2975 - o6_loss: 0.4195 - o7_loss: 0.4324 - o8_loss: 0.3548 - o1_acc: 0.9786 - o2_acc: 0.9735 - o3_acc: 0.9589 - o4_acc: 0.9337 - o5_acc: 0.8769 - o6_acc: 0.8192 - o7_acc: 0.8249 - o8_acc: 0.8601 - val_loss: 2.0568 - val_o1_loss: 0.1119 - val_o2_loss: 0.1368 - val_o3_loss: 0.1694 - val_o4_loss: 0.2021 - val_o5_loss: 0.3107 - val_o6_loss: 0.3981 - val_o7_loss: 0.4048 - val_o8_loss: 0.3231 - val_o1_acc: 0.9720 - val_o2_acc: 0.9640 - val_o3_acc: 0.9330 - val_o4_acc: 0.9280 - val_o5_acc: 0.8620 - val_o6_acc: 0.8460 - val_o7_acc: 0.8510 - val_o8_acc: 0.8730\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.0050 - o1_loss: 0.0906 - o2_loss: 0.1089 - o3_loss: 0.1302 - o4_loss: 0.1851 - o5_loss: 0.2936 - o6_loss: 0.4167 - o7_loss: 0.4304 - o8_loss: 0.3494 - o1_acc: 0.9778 - o2_acc: 0.9733 - o3_acc: 0.9605 - o4_acc: 0.9360 - o5_acc: 0.8775 - o6_acc: 0.8197 - o7_acc: 0.8255 - o8_acc: 0.8669 - val_loss: 3.6783 - val_o1_loss: 0.1237 - val_o2_loss: 0.1587 - val_o3_loss: 0.2639 - val_o4_loss: 0.4465 - val_o5_loss: 0.6762 - val_o6_loss: 0.8533 - val_o7_loss: 0.6888 - val_o8_loss: 0.4673 - val_o1_acc: 0.9650 - val_o2_acc: 0.9550 - val_o3_acc: 0.9150 - val_o4_acc: 0.8540 - val_o5_acc: 0.7560 - val_o6_acc: 0.7110 - val_o7_acc: 0.7790 - val_o8_acc: 0.8550\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 2.5248 - o1_loss: 0.1063 - o2_loss: 0.1595 - o3_loss: 0.2090 - o4_loss: 0.2821 - o5_loss: 0.3926 - o6_loss: 0.4939 - o7_loss: 0.4930 - o8_loss: 0.3885 - o1_acc: 0.9702 - o2_acc: 0.9574 - o3_acc: 0.9378 - o4_acc: 0.9110 - o5_acc: 0.8600 - o6_acc: 0.8056 - o7_acc: 0.8243 - o8_acc: 0.8694 - val_loss: 1.8816 - val_o1_loss: 0.1042 - val_o2_loss: 0.1181 - val_o3_loss: 0.1430 - val_o4_loss: 0.1923 - val_o5_loss: 0.3046 - val_o6_loss: 0.3795 - val_o7_loss: 0.3711 - val_o8_loss: 0.2688 - val_o1_acc: 0.9690 - val_o2_acc: 0.9640 - val_o3_acc: 0.9550 - val_o4_acc: 0.9310 - val_o5_acc: 0.8660 - val_o6_acc: 0.8590 - val_o7_acc: 0.8720 - val_o8_acc: 0.9080\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.8359 - o1_loss: 0.0868 - o2_loss: 0.1057 - o3_loss: 0.1256 - o4_loss: 0.1744 - o5_loss: 0.2818 - o6_loss: 0.3843 - o7_loss: 0.3858 - o8_loss: 0.2913 - o1_acc: 0.9790 - o2_acc: 0.9737 - o3_acc: 0.9624 - o4_acc: 0.9403 - o5_acc: 0.8835 - o6_acc: 0.8341 - o7_acc: 0.8539 - o8_acc: 0.8972 - val_loss: 2.0754 - val_o1_loss: 0.0974 - val_o2_loss: 0.1171 - val_o3_loss: 0.1553 - val_o4_loss: 0.1841 - val_o5_loss: 0.3005 - val_o6_loss: 0.4090 - val_o7_loss: 0.4356 - val_o8_loss: 0.3765 - val_o1_acc: 0.9740 - val_o2_acc: 0.9680 - val_o3_acc: 0.9520 - val_o4_acc: 0.9350 - val_o5_acc: 0.8680 - val_o6_acc: 0.8360 - val_o7_acc: 0.8260 - val_o8_acc: 0.8690\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.7871 - o1_loss: 0.0824 - o2_loss: 0.1002 - o3_loss: 0.1209 - o4_loss: 0.1689 - o5_loss: 0.2750 - o6_loss: 0.3797 - o7_loss: 0.3788 - o8_loss: 0.2811 - o1_acc: 0.9813 - o2_acc: 0.9754 - o3_acc: 0.9648 - o4_acc: 0.9405 - o5_acc: 0.8889 - o6_acc: 0.8342 - o7_acc: 0.8477 - o8_acc: 0.9017 - val_loss: 2.6831 - val_o1_loss: 0.0932 - val_o2_loss: 0.1275 - val_o3_loss: 0.1744 - val_o4_loss: 0.2347 - val_o5_loss: 0.3834 - val_o6_loss: 0.5470 - val_o7_loss: 0.6571 - val_o8_loss: 0.4657 - val_o1_acc: 0.9740 - val_o2_acc: 0.9600 - val_o3_acc: 0.9420 - val_o4_acc: 0.9090 - val_o5_acc: 0.8270 - val_o6_acc: 0.7560 - val_o7_acc: 0.7190 - val_o8_acc: 0.7960\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.7416 - o1_loss: 0.0821 - o2_loss: 0.0972 - o3_loss: 0.1174 - o4_loss: 0.1653 - o5_loss: 0.2666 - o6_loss: 0.3751 - o7_loss: 0.3683 - o8_loss: 0.2695 - o1_acc: 0.9798 - o2_acc: 0.9775 - o3_acc: 0.9653 - o4_acc: 0.9452 - o5_acc: 0.8906 - o6_acc: 0.8358 - o7_acc: 0.8536 - o8_acc: 0.9060 - val_loss: 2.1073 - val_o1_loss: 0.0872 - val_o2_loss: 0.1153 - val_o3_loss: 0.1688 - val_o4_loss: 0.2696 - val_o5_loss: 0.4142 - val_o6_loss: 0.4468 - val_o7_loss: 0.3736 - val_o8_loss: 0.2317 - val_o1_acc: 0.9760 - val_o2_acc: 0.9650 - val_o3_acc: 0.9440 - val_o4_acc: 0.8890 - val_o5_acc: 0.8290 - val_o6_acc: 0.8250 - val_o7_acc: 0.8640 - val_o8_acc: 0.9200\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.7016 - o1_loss: 0.0787 - o2_loss: 0.0945 - o3_loss: 0.1154 - o4_loss: 0.1632 - o5_loss: 0.2635 - o6_loss: 0.3660 - o7_loss: 0.3600 - o8_loss: 0.2601 - o1_acc: 0.9827 - o2_acc: 0.9780 - o3_acc: 0.9648 - o4_acc: 0.9419 - o5_acc: 0.8886 - o6_acc: 0.8412 - o7_acc: 0.8597 - o8_acc: 0.9109 - val_loss: 2.2084 - val_o1_loss: 0.0938 - val_o2_loss: 0.1050 - val_o3_loss: 0.1264 - val_o4_loss: 0.1643 - val_o5_loss: 0.2893 - val_o6_loss: 0.4316 - val_o7_loss: 0.4945 - val_o8_loss: 0.5035 - val_o1_acc: 0.9750 - val_o2_acc: 0.9680 - val_o3_acc: 0.9610 - val_o4_acc: 0.9450 - val_o5_acc: 0.8700 - val_o6_acc: 0.8080 - val_o7_acc: 0.7830 - val_o8_acc: 0.8080\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.6082 - o1_loss: 0.0761 - o2_loss: 0.0926 - o3_loss: 0.1111 - o4_loss: 0.1578 - o5_loss: 0.2567 - o6_loss: 0.3534 - o7_loss: 0.3332 - o8_loss: 0.2274 - o1_acc: 0.9830 - o2_acc: 0.9780 - o3_acc: 0.9669 - o4_acc: 0.9456 - o5_acc: 0.8938 - o6_acc: 0.8483 - o7_acc: 0.8728 - o8_acc: 0.9256 - val_loss: 1.6794 - val_o1_loss: 0.0870 - val_o2_loss: 0.1102 - val_o3_loss: 0.1539 - val_o4_loss: 0.1796 - val_o5_loss: 0.2874 - val_o6_loss: 0.3486 - val_o7_loss: 0.3003 - val_o8_loss: 0.2124 - val_o1_acc: 0.9760 - val_o2_acc: 0.9690 - val_o3_acc: 0.9490 - val_o4_acc: 0.9330 - val_o5_acc: 0.8790 - val_o6_acc: 0.8570 - val_o7_acc: 0.8900 - val_o8_acc: 0.9310\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.1751 - o1_loss: 0.0874 - o2_loss: 0.1227 - o3_loss: 0.1711 - o4_loss: 0.2568 - o5_loss: 0.3709 - o6_loss: 0.4666 - o7_loss: 0.4216 - o8_loss: 0.2779 - o1_acc: 0.9794 - o2_acc: 0.9671 - o3_acc: 0.9488 - o4_acc: 0.9256 - o5_acc: 0.8787 - o6_acc: 0.8317 - o7_acc: 0.8646 - o8_acc: 0.9186 - val_loss: 1.5532 - val_o1_loss: 0.0874 - val_o2_loss: 0.1012 - val_o3_loss: 0.1235 - val_o4_loss: 0.1622 - val_o5_loss: 0.2672 - val_o6_loss: 0.3208 - val_o7_loss: 0.2962 - val_o8_loss: 0.1948 - val_o1_acc: 0.9740 - val_o2_acc: 0.9780 - val_o3_acc: 0.9620 - val_o4_acc: 0.9370 - val_o5_acc: 0.8830 - val_o6_acc: 0.8740 - val_o7_acc: 0.8890 - val_o8_acc: 0.9510\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.5139 - o1_loss: 0.0723 - o2_loss: 0.0900 - o3_loss: 0.1073 - o4_loss: 0.1520 - o5_loss: 0.2398 - o6_loss: 0.3305 - o7_loss: 0.3099 - o8_loss: 0.2122 - o1_acc: 0.9829 - o2_acc: 0.9786 - o3_acc: 0.9690 - o4_acc: 0.9495 - o5_acc: 0.9034 - o6_acc: 0.8592 - o7_acc: 0.8862 - o8_acc: 0.9360 - val_loss: 2.8303 - val_o1_loss: 0.0790 - val_o2_loss: 0.0977 - val_o3_loss: 0.1265 - val_o4_loss: 0.1701 - val_o5_loss: 0.3409 - val_o6_loss: 0.5907 - val_o7_loss: 0.8097 - val_o8_loss: 0.6157 - val_o1_acc: 0.9800 - val_o2_acc: 0.9720 - val_o3_acc: 0.9580 - val_o4_acc: 0.9450 - val_o5_acc: 0.8500 - val_o6_acc: 0.7580 - val_o7_acc: 0.6790 - val_o8_acc: 0.7570\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.5276 - o1_loss: 0.0700 - o2_loss: 0.0863 - o3_loss: 0.1027 - o4_loss: 0.1447 - o5_loss: 0.2371 - o6_loss: 0.3367 - o7_loss: 0.3231 - o8_loss: 0.2270 - o1_acc: 0.9835 - o2_acc: 0.9801 - o3_acc: 0.9696 - o4_acc: 0.9525 - o5_acc: 0.9033 - o6_acc: 0.8557 - o7_acc: 0.8748 - o8_acc: 0.9260 - val_loss: 1.7418 - val_o1_loss: 0.0740 - val_o2_loss: 0.0943 - val_o3_loss: 0.1233 - val_o4_loss: 0.1655 - val_o5_loss: 0.2572 - val_o6_loss: 0.3492 - val_o7_loss: 0.3921 - val_o8_loss: 0.2862 - val_o1_acc: 0.9810 - val_o2_acc: 0.9700 - val_o3_acc: 0.9620 - val_o4_acc: 0.9420 - val_o5_acc: 0.8890 - val_o6_acc: 0.8510 - val_o7_acc: 0.8310 - val_o8_acc: 0.8860\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.3875 - o1_loss: 0.0663 - o2_loss: 0.0831 - o3_loss: 0.0988 - o4_loss: 0.1414 - o5_loss: 0.2231 - o6_loss: 0.3080 - o7_loss: 0.2781 - o8_loss: 0.1886 - o1_acc: 0.9857 - o2_acc: 0.9794 - o3_acc: 0.9697 - o4_acc: 0.9529 - o5_acc: 0.9102 - o6_acc: 0.8678 - o7_acc: 0.8931 - o8_acc: 0.9411 - val_loss: 1.5990 - val_o1_loss: 0.0728 - val_o2_loss: 0.0943 - val_o3_loss: 0.1168 - val_o4_loss: 0.1609 - val_o5_loss: 0.2545 - val_o6_loss: 0.3555 - val_o7_loss: 0.3037 - val_o8_loss: 0.2405 - val_o1_acc: 0.9840 - val_o2_acc: 0.9710 - val_o3_acc: 0.9650 - val_o4_acc: 0.9450 - val_o5_acc: 0.8890 - val_o6_acc: 0.8470 - val_o7_acc: 0.8820 - val_o8_acc: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4546640f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.fit(X_train, np.split(Y_train,Y_train.shape[-1],axis=-1),\n",
    "    validation_data=(X_test,np.split(Y_test,Y_test.shape[-1],axis=-1)),\n",
    "    batch_size=128, epochs=100, callbacks=[\n",
    "    keras.callbacks.ReduceLROnPlateau('loss', patience=3, verbose=1)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
