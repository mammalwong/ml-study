{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 16), (10000, 8), (1000, 16), (1000, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.random.randint(3, high=16, size=(11000,8))\n",
    "Y_train = np.sort(X_train, axis=-1)\n",
    "X_target = np.copy(Y_train)\n",
    "X_target[:,1:] = X_target[:,:-1]\n",
    "X_target[:,0] = 1\n",
    "X_train = np.concatenate([X_train, X_target], axis=-1)\n",
    "X_train,X_test = X_train[1000:],X_train[:1000]\n",
    "Y_train,Y_test = Y_train[1000:],Y_train[:1000]\n",
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input_dim = max(np.max(X_train), np.max(X_test)) + 1\n",
    "data_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output_dim = max(np.max(Y_train), np.max(Y_test)) + 1\n",
    "data_output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DNCCell(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 word_size,\n",
    "                 memory_size,\n",
    "                 register_size=2,\n",
    "                 write_head_count=2,\n",
    "                 read_head_count=2,\n",
    "                 enable_temporal=True,\n",
    "                 enable_controller_output_resize=True,\n",
    "                 enable_final_bias=True,\n",
    "                 bypass_dropout_factor=None,\n",
    "                 **kwargs):\n",
    "        self.output_size = output_size\n",
    "        self.word_size = word_size\n",
    "        self.memory_size = memory_size\n",
    "        self.register_size = register_size\n",
    "        self.write_head_count = write_head_count\n",
    "        self.read_head_count = read_head_count\n",
    "        self.enable_temporal = enable_temporal\n",
    "        self.enable_controller_output_resize = enable_controller_output_resize\n",
    "        self.enable_final_bias = enable_final_bias\n",
    "        self.bypass_dropout_factor = bypass_dropout_factor\n",
    "        self.state_size = (output_size,)\n",
    "        self.state_size += (register_size * word_size,)\n",
    "        self.state_size += (register_size * word_size,)\n",
    "        self.state_size += (memory_size * word_size,)\n",
    "        self.state_size += (read_head_count * memory_size,)\n",
    "        self.state_size += (read_head_count * word_size,)\n",
    "        self.state_size += (write_head_count * memory_size,)\n",
    "        self.state_size += (memory_size,)\n",
    "        if enable_temporal:\n",
    "            self.state_size += (write_head_count * memory_size,)\n",
    "            self.state_size += (write_head_count * memory_size**2,)\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        read_vec_size = self.word_size * self.read_head_count\n",
    "        controller_input_size = input_shape[-1]\n",
    "        controller_input_size += read_vec_size\n",
    "        controller_input_size += self.register_size*self.word_size\n",
    "        controller_kernel_size = self.register_size*self.word_size*4\n",
    "        controller_hidden_size = self.register_size*self.word_size\n",
    "        interface_vec_size = read_vec_size\n",
    "        interface_vec_size += self.read_head_count*2\n",
    "        if self.enable_temporal:\n",
    "            interface_vec_size += self.read_head_count*3\n",
    "        interface_vec_size += self.write_head_count*self.word_size*3\n",
    "        interface_vec_size += self.write_head_count*3\n",
    "        self.kernel_controller_hidden = self.add_weight(\n",
    "            shape=(controller_input_size, controller_kernel_size),\n",
    "            initializer='glorot_normal', name='kernel_controller_hidden')\n",
    "        self.bias_controller_hidden = self.add_weight(\n",
    "            shape=(controller_kernel_size,),\n",
    "            initializer='zeros', name='bias_controller_hidden')\n",
    "        self.kernel_controller_output = self.add_weight(\n",
    "            shape=(controller_hidden_size, self.output_size + interface_vec_size),\n",
    "            initializer='glorot_normal', name='kernel_controller_output')\n",
    "        self.kernel_read_vec_to_output = self.add_weight(\n",
    "            shape=(read_vec_size, self.output_size),\n",
    "            initializer='glorot_normal', name='kernel_read_vec_to_output')\n",
    "        if self.enable_controller_output_resize:\n",
    "            self.scalar_controller_output_resize = self.add_weight(shape=(),\n",
    "                initializer='ones', name='scalar_controller_output_resize')\n",
    "        if self.enable_final_bias:\n",
    "            self.bias_final_output = self.add_weight(\n",
    "                shape=(self.output_size,),\n",
    "                initializer='zeros', name='bias_final_output')\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, states, training=None):\n",
    "        \n",
    "        def oneplus(x):\n",
    "            return K.softplus(x) + 1.\n",
    "        \n",
    "        def similarity(m, k, b):\n",
    "            dot = K.batch_dot(k, m, axes=2)\n",
    "            m_len = K.sqrt(K.sum(K.square(m), axis=-1))\n",
    "            k_len = K.sqrt(K.sum(K.square(k), axis=-1))\n",
    "            mk_len = K.expand_dims(k_len, axis=-1) @ K.expand_dims(m_len, axis=-2)\n",
    "            mk_len = K.switch(K.not_equal(mk_len, 0.), mk_len, K.ones_like(mk_len))\n",
    "            cos_sim = dot / mk_len\n",
    "            return K.softmax(cos_sim * K.expand_dims(b))\n",
    "        \n",
    "        def batch_invert_permutation(permutations):\n",
    "            # from https://github.com/deepmind/dnc/blob/master/dnc/util.py\n",
    "            perm = tf.cast(permutations, tf.float32)\n",
    "            dim = int(perm.get_shape()[-1])\n",
    "            size = tf.cast(tf.shape(perm)[0], tf.float32)\n",
    "            delta = tf.cast(tf.shape(perm)[-1], tf.float32)\n",
    "            rg = tf.range(0, size * delta, delta, dtype=tf.float32)\n",
    "            rg = tf.expand_dims(rg, 1)\n",
    "            rg = tf.tile(rg, [1, dim])\n",
    "            perm = tf.add(perm, rg)\n",
    "            flat = tf.reshape(perm, [-1])\n",
    "            perm = tf.invert_permutation(tf.cast(flat, tf.int32))\n",
    "            perm = tf.reshape(perm, [-1, dim])\n",
    "            return tf.subtract(perm, tf.cast(rg, tf.int32))\n",
    "\n",
    "        def batch_gather(values, indices):\n",
    "            # from https://github.com/deepmind/dnc/blob/master/dnc/util.py\n",
    "            idx = tf.expand_dims(indices, -1)\n",
    "            size = tf.shape(indices)[0]\n",
    "            rg = tf.range(size, dtype=tf.int32)\n",
    "            rg = tf.expand_dims(rg, -1)\n",
    "            rg = tf.tile(rg, [1, int(indices.get_shape()[-1])])\n",
    "            rg = tf.expand_dims(rg, -1)\n",
    "            gidx = tf.concat([rg, idx], -1)\n",
    "            return tf.gather_nd(values, gidx)\n",
    "        \n",
    "        _, register_s_last, register_h_last, memory_last, \\\n",
    "            read_weights_last, read_vec_last, write_weights_last, \\\n",
    "            usage_last, *temporal_states = states\n",
    "        memory_last = K.reshape(memory_last,\n",
    "            (-1,self.memory_size,self.word_size))\n",
    "        read_weights_last = K.reshape(read_weights_last,\n",
    "            (-1,self.read_head_count,self.memory_size))\n",
    "        write_weights_last = K.reshape(write_weights_last,\n",
    "            (-1,self.write_head_count,self.memory_size))\n",
    "        if not self.enable_temporal:\n",
    "            assert not temporal_states\n",
    "        else:\n",
    "            preced_last, link_last = temporal_states\n",
    "            preced_last = K.reshape(preced_last,\n",
    "                (-1,self.write_head_count,self.memory_size))\n",
    "            link_last = K.reshape(link_last,\n",
    "                (-1,self.write_head_count,self.memory_size,self.memory_size))\n",
    "        \n",
    "        # feeding controller with current input and last read vecs\n",
    "        output = K.concatenate([inputs, read_vec_last, register_h_last])\n",
    "        output = output @ self.kernel_controller_hidden\n",
    "        output = output + self.bias_controller_hidden\n",
    "        ctr_input_gate = output[:,:self.register_size*self.word_size]\n",
    "        ctr_input_gate = K.sigmoid(ctr_input_gate)\n",
    "        ctr_forget_gate = output[:,\n",
    "            self.register_size*self.word_size:\n",
    "            self.register_size*self.word_size*2]\n",
    "        ctr_forget_gate = K.sigmoid(ctr_forget_gate)\n",
    "        register_s = output[:,\n",
    "            self.register_size*self.word_size*2:\n",
    "            self.register_size*self.word_size*3]\n",
    "        register_s = ctr_input_gate * K.tanh(register_s)\n",
    "        register_s = register_s + ctr_forget_gate*register_s_last\n",
    "        ctr_output_gate = output[:,\n",
    "            self.register_size*self.word_size*3:\n",
    "            self.register_size*self.word_size*4]\n",
    "        ctr_output_gate = K.sigmoid(ctr_output_gate)\n",
    "        register_h = ctr_output_gate * K.tanh(register_s)\n",
    "        output = register_h @ self.kernel_controller_output\n",
    "        \n",
    "        # break down controller output into semi final output and interface vec\n",
    "        interface_vec = output[:,self.output_size:]\n",
    "        output = output[:,:self.output_size]\n",
    "        if self.bypass_dropout_factor is not None:\n",
    "            output = K.in_train_phase(K.dropout(\n",
    "                output,self.bypass_dropout_factor),output,training=training)\n",
    "        if self.enable_controller_output_resize:\n",
    "            output = output * self.scalar_controller_output_resize\n",
    "        \n",
    "        # break down interface vec\n",
    "        interface_pos_last = 0\n",
    "        interface_partition = []\n",
    "        for interface_part_len in [\n",
    "            self.read_head_count * self.word_size,\n",
    "            self.read_head_count,\n",
    "            self.write_head_count * self.word_size,\n",
    "            self.write_head_count,\n",
    "            self.write_head_count * self.word_size,\n",
    "            self.write_head_count * self.word_size,\n",
    "            self.read_head_count,\n",
    "            self.write_head_count,\n",
    "            self.write_head_count,\n",
    "            *([self.read_head_count * 3] if self.enable_temporal else [])]:\n",
    "            interface_pos = interface_pos_last + interface_part_len\n",
    "            interface_partition.append(\n",
    "                interface_vec[:,interface_pos_last:interface_pos])\n",
    "            interface_pos_last = interface_pos\n",
    "        read_keys, read_stre, write_keys, write_stre, erase_vecs, \\\n",
    "            write_vecs, free_gates, alloc_gates, write_gates, \\\n",
    "            *temporal_interface_partition = interface_partition\n",
    "        read_keys = K.reshape(read_keys,(-1,self.read_head_count,self.word_size))\n",
    "        read_stre = oneplus(read_stre)\n",
    "        write_keys = K.reshape(write_keys,(-1,self.write_head_count,self.word_size))\n",
    "        write_stre = oneplus(write_stre)\n",
    "        erase_vecs = K.reshape(erase_vecs,(-1,self.write_head_count,self.word_size))\n",
    "        erase_vecs = K.sigmoid(erase_vecs)\n",
    "        write_vecs = K.reshape(write_vecs,(-1,self.write_head_count,self.word_size))\n",
    "        free_gates = K.expand_dims(free_gates)\n",
    "        free_gates = K.sigmoid(free_gates)\n",
    "        alloc_gates = K.expand_dims(alloc_gates)\n",
    "        alloc_gates = K.sigmoid(alloc_gates)\n",
    "        write_gates = K.expand_dims(write_gates)\n",
    "        write_gates = K.sigmoid(write_gates)\n",
    "        if not self.enable_temporal:\n",
    "            assert not temporal_interface_partition\n",
    "        else:\n",
    "            read_modes, = temporal_interface_partition\n",
    "            read_modes = K.reshape(read_modes,(-1,self.read_head_count,3))\n",
    "            read_modes = K.softmax(read_modes,axis=-1)\n",
    "        \n",
    "        # compute allocation vector\n",
    "        retention = K.prod(1.-(free_gates*read_weights_last), axis=-2)\n",
    "        # https://github.com/deepmind/dnc/blob/master/dnc/addressing.py\n",
    "        # according to the deepmind implementation,\n",
    "        # only write weight is not differentiable\n",
    "        write_weights_last_nograd = K.stop_gradient(write_weights_last)\n",
    "        # reduce for multi-write-head, not presented in original papaer\n",
    "        write_weights_last_nograd = 1.-K.prod(1.-write_weights_last_nograd, axis=-2)\n",
    "        usage = ((usage_last+write_weights_last_nograd) - \\\n",
    "                usage_last*write_weights_last_nograd) * retention\n",
    "        # loop for multi-write-head support\n",
    "        mwh_write_gates = write_gates * alloc_gates\n",
    "        mwh_usage = usage\n",
    "        mwh_alloc = []\n",
    "        for i in range(self.write_head_count):\n",
    "            # quickfix for tf.cumprod grad bug\n",
    "            # https://github.com/tensorflow/tensorflow/issues/3862\n",
    "            usage_qfixed = 1e-6 + (1-1e-6) * mwh_usage\n",
    "            usage_asc,usage_perm = tf.nn.top_k(1.-usage_qfixed,k=self.memory_size)\n",
    "            usage_asc = 1.-usage_asc\n",
    "            alloc_asc = (1.-usage_asc) * tf.cumprod(usage_asc,axis=-1,exclusive=True)\n",
    "            alloc_perm = batch_invert_permutation(usage_perm)\n",
    "            alloc = batch_gather(alloc_asc, alloc_perm)\n",
    "            mwh_alloc.append(alloc)\n",
    "            mwh_usage += (1.-mwh_usage) * mwh_write_gates[:,i,:] * alloc\n",
    "        alloc = K.stack(mwh_alloc, axis=-2)\n",
    "        \n",
    "        # compute write weight\n",
    "        write_sims = similarity(memory_last,write_keys,write_stre)\n",
    "        write_weights = write_gates*(alloc_gates*alloc + (1.-alloc_gates)*write_sims)\n",
    "        \n",
    "        # compute precedence and temporal links\n",
    "        if self.enable_temporal:\n",
    "            write_weights_rep_h =  K.expand_dims(write_weights,axis=-1)\n",
    "            write_weights_rep_v =  K.expand_dims(write_weights,axis=-2)\n",
    "            link = (1.-(write_weights_rep_h+write_weights_rep_v))*link_last + \\\n",
    "                write_weights_rep_h * K.expand_dims(preced_last,axis=-2)\n",
    "            link = link * (1.-tf.eye(self.memory_size))\n",
    "            read_weights_last_rep = K.repeat_elements(\n",
    "                K.expand_dims(read_weights_last,axis=-3),self.write_head_count,-3)\n",
    "            # reduce sum for multi-write-head\n",
    "            link_forward = K.sum(read_weights_last_rep @ link,axis=-3)\n",
    "            link_backward = K.sum(K.permute_dimensions(link @ K.permute_dimensions(\n",
    "                read_weights_last_rep,(0,1,3,2)),(0,1,3,2)),axis=-3)\n",
    "            preced = (1.-K.sum(\n",
    "                write_weights,axis=-1,keepdims=True))*preced_last + write_weights\n",
    "        \n",
    "        # update memory\n",
    "        m_reset = K.expand_dims(write_weights,axis=-1) @ \\\n",
    "            K.expand_dims(erase_vecs,axis=-2)\n",
    "        # reduce prod for multi-write-head\n",
    "        m_keep = K.prod(1.-m_reset,axis=-3)\n",
    "        m_new = K.expand_dims(write_weights,axis=-1) @ \\\n",
    "            K.expand_dims(write_vecs,axis=-2)\n",
    "        # reduce sum for multi-write-head\n",
    "        m_new = K.sum(m_new, axis=-3)\n",
    "        memory = memory_last*m_keep + m_new\n",
    "        \n",
    "        # compute read weights and read vectors\n",
    "        read_sims = similarity(memory,read_keys,read_stre)\n",
    "        if not self.enable_temporal:\n",
    "            read_weights = read_sims\n",
    "        else:\n",
    "            read_weights = read_modes[:,:,0:1] * read_sims + \\\n",
    "                            read_modes[:,:,1:2] * link_forward + \\\n",
    "                            read_modes[:,:,2:3] * link_backward\n",
    "        read_vecs = read_weights @ memory\n",
    "        read_vec = K.reshape(read_vecs, (-1,self.read_head_count*self.word_size))\n",
    "        \n",
    "        # compute final output from controller output and current read vecs\n",
    "        output = output + read_vec @ self.kernel_read_vec_to_output\n",
    "        if self.enable_final_bias:\n",
    "            output = output + self.bias_final_output\n",
    "        \n",
    "        return output, [\n",
    "            output,\n",
    "            register_s,\n",
    "            register_h,\n",
    "            K.reshape(memory, (-1,self.memory_size*self.word_size)),\n",
    "            K.reshape(read_weights, (-1,self.read_head_count*self.memory_size)),\n",
    "            read_vec,\n",
    "            K.reshape(write_weights, (-1,self.write_head_count*self.memory_size)),\n",
    "            usage,\n",
    "            *([\n",
    "                K.reshape(preced, (-1,self.write_head_count*self.memory_size)),\n",
    "                K.reshape(link, (-1,self.write_head_count*self.memory_size**2))\n",
    "            ] if self.enable_temporal else [])]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 16)     256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, None, 16)     4945        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 16)     0           rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, None, 16)     0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "o1 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o2 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o3 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o4 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o5 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o6 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o7 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "o8 (Lambda)                     (None, 16)           0           softmax_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,201\n",
      "Trainable params: 5,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_inputs = keras.layers.Input((None,), dtype='int32')\n",
    "X = keras.layers.Embedding(data_input_dim, 16, mask_zero=True)(X)\n",
    "X = keras.layers.RNN(DNCCell(data_output_dim, 8, 16), return_sequences=True)(X)\n",
    "X = keras.layers.Lambda(lambda x,s: x[:,s:,:],\n",
    "    arguments={'s':X_train.shape[1]//2})(X)\n",
    "X = keras.layers.Softmax()(X)\n",
    "X = [keras.layers.Lambda(lambda x,s: x[:,s,:], name=f'o{i+1}',\n",
    "    arguments={'s':i}, output_shape=(data_output_dim,))(X)\n",
    "    for i in range(X_train.shape[1]//2)]\n",
    "M = keras.Model(X_inputs, X)\n",
    "M.compile('nadam', 'sparse_categorical_crossentropy', ['acc'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 18.9151 - o1_loss: 2.4605 - o2_loss: 2.4534 - o3_loss: 2.4658 - o4_loss: 2.4738 - o5_loss: 2.4407 - o6_loss: 2.3633 - o7_loss: 2.2358 - o8_loss: 2.0217 - o1_acc: 0.1201 - o2_acc: 0.1344 - o3_acc: 0.1313 - o4_acc: 0.1236 - o5_acc: 0.1337 - o6_acc: 0.1346 - o7_acc: 0.1765 - o8_acc: 0.3308 - val_loss: 15.3592 - val_o1_loss: 1.9534 - val_o2_loss: 1.9923 - val_o3_loss: 2.0347 - val_o4_loss: 2.0325 - val_o5_loss: 1.9969 - val_o6_loss: 1.9339 - val_o7_loss: 1.8003 - val_o8_loss: 1.6152 - val_o1_acc: 0.2240 - val_o2_acc: 0.2070 - val_o3_acc: 0.2260 - val_o4_acc: 0.2760 - val_o5_acc: 0.2790 - val_o6_acc: 0.2480 - val_o7_acc: 0.2730 - val_o8_acc: 0.3240\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 14.2194 - o1_loss: 1.7552 - o2_loss: 1.8469 - o3_loss: 1.8969 - o4_loss: 1.8885 - o5_loss: 1.8635 - o6_loss: 1.8365 - o7_loss: 1.7228 - o8_loss: 1.4090 - o1_acc: 0.2654 - o2_acc: 0.2681 - o3_acc: 0.2749 - o4_acc: 0.3006 - o5_acc: 0.2840 - o6_acc: 0.2390 - o7_acc: 0.2310 - o8_acc: 0.4153 - val_loss: 13.6286 - val_o1_loss: 1.6135 - val_o2_loss: 1.7485 - val_o3_loss: 1.8143 - val_o4_loss: 1.7830 - val_o5_loss: 1.8221 - val_o6_loss: 1.8500 - val_o7_loss: 1.7247 - val_o8_loss: 1.2725 - val_o1_acc: 0.2810 - val_o2_acc: 0.2980 - val_o3_acc: 0.2540 - val_o4_acc: 0.3170 - val_o5_acc: 0.2710 - val_o6_acc: 0.1960 - val_o7_acc: 0.2310 - val_o8_acc: 0.4560\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 12.8357 - o1_loss: 1.4923 - o2_loss: 1.6478 - o3_loss: 1.6878 - o4_loss: 1.6499 - o5_loss: 1.6459 - o6_loss: 1.6952 - o7_loss: 1.6664 - o8_loss: 1.3504 - o1_acc: 0.3824 - o2_acc: 0.3128 - o3_acc: 0.3303 - o4_acc: 0.3483 - o5_acc: 0.3466 - o6_acc: 0.2968 - o7_acc: 0.2609 - o8_acc: 0.4280 - val_loss: 13.0418 - val_o1_loss: 1.3484 - val_o2_loss: 1.6084 - val_o3_loss: 1.6925 - val_o4_loss: 1.6884 - val_o5_loss: 1.6753 - val_o6_loss: 1.7577 - val_o7_loss: 1.7450 - val_o8_loss: 1.5261 - val_o1_acc: 0.4760 - val_o2_acc: 0.2250 - val_o3_acc: 0.2880 - val_o4_acc: 0.3030 - val_o5_acc: 0.2940 - val_o6_acc: 0.2940 - val_o7_acc: 0.2840 - val_o8_acc: 0.3260\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 12.1382 - o1_loss: 1.3481 - o2_loss: 1.5320 - o3_loss: 1.5618 - o4_loss: 1.5229 - o5_loss: 1.5473 - o6_loss: 1.6257 - o7_loss: 1.6434 - o8_loss: 1.3570 - o1_acc: 0.4815 - o2_acc: 0.3298 - o3_acc: 0.3652 - o4_acc: 0.3895 - o5_acc: 0.3732 - o6_acc: 0.3279 - o7_acc: 0.2702 - o8_acc: 0.4190 - val_loss: 12.0248 - val_o1_loss: 1.3116 - val_o2_loss: 1.4736 - val_o3_loss: 1.5189 - val_o4_loss: 1.5085 - val_o5_loss: 1.6090 - val_o6_loss: 1.6700 - val_o7_loss: 1.6325 - val_o8_loss: 1.3009 - val_o1_acc: 0.4830 - val_o2_acc: 0.3790 - val_o3_acc: 0.3980 - val_o4_acc: 0.3980 - val_o5_acc: 0.3580 - val_o6_acc: 0.3060 - val_o7_acc: 0.2450 - val_o8_acc: 0.4340\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 11.5382 - o1_loss: 1.2407 - o2_loss: 1.4123 - o3_loss: 1.4426 - o4_loss: 1.4342 - o5_loss: 1.4779 - o6_loss: 1.5734 - o7_loss: 1.6147 - o8_loss: 1.3424 - o1_acc: 0.5029 - o2_acc: 0.3890 - o3_acc: 0.4120 - o4_acc: 0.4065 - o5_acc: 0.3882 - o6_acc: 0.3428 - o7_acc: 0.2823 - o8_acc: 0.4173 - val_loss: 11.4128 - val_o1_loss: 1.1834 - val_o2_loss: 1.3560 - val_o3_loss: 1.4129 - val_o4_loss: 1.4509 - val_o5_loss: 1.4653 - val_o6_loss: 1.5576 - val_o7_loss: 1.5980 - val_o8_loss: 1.3887 - val_o1_acc: 0.5170 - val_o2_acc: 0.4160 - val_o3_acc: 0.4170 - val_o4_acc: 0.3870 - val_o5_acc: 0.3590 - val_o6_acc: 0.3170 - val_o7_acc: 0.3140 - val_o8_acc: 0.4330\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 11.0859 - o1_loss: 1.1456 - o2_loss: 1.3106 - o3_loss: 1.3563 - o4_loss: 1.3668 - o5_loss: 1.4393 - o6_loss: 1.5428 - o7_loss: 1.5925 - o8_loss: 1.3320 - o1_acc: 0.5289 - o2_acc: 0.4407 - o3_acc: 0.4457 - o4_acc: 0.4293 - o5_acc: 0.3968 - o6_acc: 0.3448 - o7_acc: 0.2921 - o8_acc: 0.4189 - val_loss: 10.6691 - val_o1_loss: 1.1184 - val_o2_loss: 1.2546 - val_o3_loss: 1.2797 - val_o4_loss: 1.2842 - val_o5_loss: 1.3743 - val_o6_loss: 1.5190 - val_o7_loss: 1.5787 - val_o8_loss: 1.2602 - val_o1_acc: 0.5400 - val_o2_acc: 0.5060 - val_o3_acc: 0.4900 - val_o4_acc: 0.4600 - val_o5_acc: 0.4180 - val_o6_acc: 0.3290 - val_o7_acc: 0.3230 - val_o8_acc: 0.4560\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 10.7062 - o1_loss: 1.0739 - o2_loss: 1.2371 - o3_loss: 1.2799 - o4_loss: 1.3104 - o5_loss: 1.3889 - o6_loss: 1.5184 - o7_loss: 1.5861 - o8_loss: 1.3115 - o1_acc: 0.5513 - o2_acc: 0.4730 - o3_acc: 0.4742 - o4_acc: 0.4485 - o5_acc: 0.4201 - o6_acc: 0.3639 - o7_acc: 0.2931 - o8_acc: 0.4311 - val_loss: 10.6131 - val_o1_loss: 1.0337 - val_o2_loss: 1.1988 - val_o3_loss: 1.2415 - val_o4_loss: 1.3265 - val_o5_loss: 1.3827 - val_o6_loss: 1.5108 - val_o7_loss: 1.5725 - val_o8_loss: 1.3466 - val_o1_acc: 0.5670 - val_o2_acc: 0.4660 - val_o3_acc: 0.4760 - val_o4_acc: 0.4210 - val_o5_acc: 0.4010 - val_o6_acc: 0.3470 - val_o7_acc: 0.2820 - val_o8_acc: 0.4120\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 10.5093 - o1_loss: 1.0307 - o2_loss: 1.1937 - o3_loss: 1.2421 - o4_loss: 1.3022 - o5_loss: 1.3825 - o6_loss: 1.5003 - o7_loss: 1.5683 - o8_loss: 1.2895 - o1_acc: 0.5614 - o2_acc: 0.4880 - o3_acc: 0.4838 - o4_acc: 0.4552 - o5_acc: 0.4240 - o6_acc: 0.3688 - o7_acc: 0.3044 - o8_acc: 0.4421 - val_loss: 10.2566 - val_o1_loss: 1.0342 - val_o2_loss: 1.1624 - val_o3_loss: 1.1900 - val_o4_loss: 1.2564 - val_o5_loss: 1.3733 - val_o6_loss: 1.5086 - val_o7_loss: 1.5078 - val_o8_loss: 1.2239 - val_o1_acc: 0.5570 - val_o2_acc: 0.5190 - val_o3_acc: 0.5160 - val_o4_acc: 0.4610 - val_o5_acc: 0.4240 - val_o6_acc: 0.3630 - val_o7_acc: 0.3430 - val_o8_acc: 0.4540\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 10.0785 - o1_loss: 0.9812 - o2_loss: 1.1433 - o3_loss: 1.1802 - o4_loss: 1.2542 - o5_loss: 1.3295 - o6_loss: 1.4518 - o7_loss: 1.5037 - o8_loss: 1.2348 - o1_acc: 0.5813 - o2_acc: 0.5161 - o3_acc: 0.5142 - o4_acc: 0.4729 - o5_acc: 0.4358 - o6_acc: 0.3847 - o7_acc: 0.3296 - o8_acc: 0.4625 - val_loss: 10.0674 - val_o1_loss: 0.9422 - val_o2_loss: 1.0966 - val_o3_loss: 1.1400 - val_o4_loss: 1.2299 - val_o5_loss: 1.3162 - val_o6_loss: 1.4811 - val_o7_loss: 1.5024 - val_o8_loss: 1.3590 - val_o1_acc: 0.6000 - val_o2_acc: 0.5290 - val_o3_acc: 0.5270 - val_o4_acc: 0.4460 - val_o5_acc: 0.4120 - val_o6_acc: 0.3610 - val_o7_acc: 0.3440 - val_o8_acc: 0.4300\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 9.6635 - o1_loss: 0.9441 - o2_loss: 1.1031 - o3_loss: 1.1404 - o4_loss: 1.2172 - o5_loss: 1.2954 - o6_loss: 1.3998 - o7_loss: 1.4184 - o8_loss: 1.1450 - o1_acc: 0.6006 - o2_acc: 0.5302 - o3_acc: 0.5181 - o4_acc: 0.4849 - o5_acc: 0.4556 - o6_acc: 0.4024 - o7_acc: 0.3757 - o8_acc: 0.4926 - val_loss: 10.5551 - val_o1_loss: 1.0174 - val_o2_loss: 1.2938 - val_o3_loss: 1.3974 - val_o4_loss: 1.3871 - val_o5_loss: 1.4394 - val_o6_loss: 1.5052 - val_o7_loss: 1.4374 - val_o8_loss: 1.0774 - val_o1_acc: 0.5690 - val_o2_acc: 0.4840 - val_o3_acc: 0.4380 - val_o4_acc: 0.4560 - val_o5_acc: 0.4260 - val_o6_acc: 0.3510 - val_o7_acc: 0.3440 - val_o8_acc: 0.4840\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 9.2432 - o1_loss: 0.9094 - o2_loss: 1.0615 - o3_loss: 1.1012 - o4_loss: 1.1704 - o5_loss: 1.2525 - o6_loss: 1.3434 - o7_loss: 1.3361 - o8_loss: 1.0688 - o1_acc: 0.6194 - o2_acc: 0.5462 - o3_acc: 0.5308 - o4_acc: 0.4974 - o5_acc: 0.4590 - o6_acc: 0.4254 - o7_acc: 0.4049 - o8_acc: 0.5187 - val_loss: 8.6521 - val_o1_loss: 0.8763 - val_o2_loss: 0.9804 - val_o3_loss: 1.0223 - val_o4_loss: 1.0993 - val_o5_loss: 1.1616 - val_o6_loss: 1.2719 - val_o7_loss: 1.2493 - val_o8_loss: 0.9909 - val_o1_acc: 0.6500 - val_o2_acc: 0.6410 - val_o3_acc: 0.5700 - val_o4_acc: 0.5050 - val_o5_acc: 0.5020 - val_o6_acc: 0.4360 - val_o7_acc: 0.4320 - val_o8_acc: 0.5250\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.8535 - o1_loss: 0.8780 - o2_loss: 1.0102 - o3_loss: 1.0541 - o4_loss: 1.1291 - o5_loss: 1.2065 - o6_loss: 1.2800 - o7_loss: 1.2624 - o8_loss: 1.0332 - o1_acc: 0.6336 - o2_acc: 0.5813 - o3_acc: 0.5527 - o4_acc: 0.5122 - o5_acc: 0.4751 - o6_acc: 0.4498 - o7_acc: 0.4371 - o8_acc: 0.5236 - val_loss: 8.8935 - val_o1_loss: 0.9092 - val_o2_loss: 1.0089 - val_o3_loss: 1.0705 - val_o4_loss: 1.1211 - val_o5_loss: 1.2064 - val_o6_loss: 1.3204 - val_o7_loss: 1.2846 - val_o8_loss: 0.9725 - val_o1_acc: 0.5970 - val_o2_acc: 0.5820 - val_o3_acc: 0.5430 - val_o4_acc: 0.4880 - val_o5_acc: 0.4720 - val_o6_acc: 0.4300 - val_o7_acc: 0.4230 - val_o8_acc: 0.5340\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.5495 - o1_loss: 0.8458 - o2_loss: 0.9743 - o3_loss: 1.0104 - o4_loss: 1.0808 - o5_loss: 1.1634 - o6_loss: 1.2397 - o7_loss: 1.2236 - o8_loss: 1.0115 - o1_acc: 0.6542 - o2_acc: 0.6000 - o3_acc: 0.5667 - o4_acc: 0.5305 - o5_acc: 0.5049 - o6_acc: 0.4684 - o7_acc: 0.4567 - o8_acc: 0.5257 - val_loss: 8.2237 - val_o1_loss: 0.8323 - val_o2_loss: 0.9198 - val_o3_loss: 0.9656 - val_o4_loss: 1.0428 - val_o5_loss: 1.0858 - val_o6_loss: 1.1702 - val_o7_loss: 1.1887 - val_o8_loss: 1.0186 - val_o1_acc: 0.6620 - val_o2_acc: 0.6500 - val_o3_acc: 0.6000 - val_o4_acc: 0.5290 - val_o5_acc: 0.5340 - val_o6_acc: 0.4800 - val_o7_acc: 0.4490 - val_o8_acc: 0.5250\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 8.3400 - o1_loss: 0.8194 - o2_loss: 0.9384 - o3_loss: 0.9885 - o4_loss: 1.0582 - o5_loss: 1.1345 - o6_loss: 1.2044 - o7_loss: 1.1984 - o8_loss: 0.9984 - o1_acc: 0.6604 - o2_acc: 0.6169 - o3_acc: 0.5845 - o4_acc: 0.5463 - o5_acc: 0.5188 - o6_acc: 0.4949 - o7_acc: 0.4648 - o8_acc: 0.5323 - val_loss: 8.3031 - val_o1_loss: 0.8182 - val_o2_loss: 0.9351 - val_o3_loss: 0.9658 - val_o4_loss: 1.0197 - val_o5_loss: 1.0707 - val_o6_loss: 1.1398 - val_o7_loss: 1.2037 - val_o8_loss: 1.1501 - val_o1_acc: 0.6520 - val_o2_acc: 0.6270 - val_o3_acc: 0.6120 - val_o4_acc: 0.5450 - val_o5_acc: 0.5560 - val_o6_acc: 0.5100 - val_o7_acc: 0.4660 - val_o8_acc: 0.4710\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.9803 - o1_loss: 0.7859 - o2_loss: 0.8976 - o3_loss: 0.9349 - o4_loss: 0.9998 - o5_loss: 1.0835 - o6_loss: 1.1486 - o7_loss: 1.1535 - o8_loss: 0.9766 - o1_acc: 0.6774 - o2_acc: 0.6359 - o3_acc: 0.6139 - o4_acc: 0.5789 - o5_acc: 0.5432 - o6_acc: 0.5180 - o7_acc: 0.4889 - o8_acc: 0.5423 - val_loss: 7.7392 - val_o1_loss: 0.8113 - val_o2_loss: 0.8881 - val_o3_loss: 0.8929 - val_o4_loss: 0.9361 - val_o5_loss: 0.9985 - val_o6_loss: 1.0910 - val_o7_loss: 1.1161 - val_o8_loss: 1.0053 - val_o1_acc: 0.6720 - val_o2_acc: 0.6540 - val_o3_acc: 0.6470 - val_o4_acc: 0.5860 - val_o5_acc: 0.5760 - val_o6_acc: 0.5380 - val_o7_acc: 0.5090 - val_o8_acc: 0.5150\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.9238 - o1_loss: 0.7633 - o2_loss: 0.8760 - o3_loss: 0.9245 - o4_loss: 0.9965 - o5_loss: 1.0700 - o6_loss: 1.1451 - o7_loss: 1.1650 - o8_loss: 0.9834 - o1_acc: 0.6896 - o2_acc: 0.6465 - o3_acc: 0.6173 - o4_acc: 0.5705 - o5_acc: 0.5490 - o6_acc: 0.5104 - o7_acc: 0.4830 - o8_acc: 0.5404 - val_loss: 7.7072 - val_o1_loss: 0.7439 - val_o2_loss: 0.8126 - val_o3_loss: 0.8828 - val_o4_loss: 0.9863 - val_o5_loss: 1.0321 - val_o6_loss: 1.1072 - val_o7_loss: 1.1336 - val_o8_loss: 1.0088 - val_o1_acc: 0.6890 - val_o2_acc: 0.6830 - val_o3_acc: 0.6420 - val_o4_acc: 0.5700 - val_o5_acc: 0.5690 - val_o6_acc: 0.5210 - val_o7_acc: 0.4970 - val_o8_acc: 0.5230\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.4852 - o1_loss: 0.7271 - o2_loss: 0.8295 - o3_loss: 0.8593 - o4_loss: 0.9278 - o5_loss: 1.0056 - o6_loss: 1.0803 - o7_loss: 1.1052 - o8_loss: 0.9503 - o1_acc: 0.7053 - o2_acc: 0.6659 - o3_acc: 0.6418 - o4_acc: 0.6073 - o5_acc: 0.5684 - o6_acc: 0.5356 - o7_acc: 0.4996 - o8_acc: 0.5480 - val_loss: 8.1373 - val_o1_loss: 0.7311 - val_o2_loss: 0.8699 - val_o3_loss: 0.9765 - val_o4_loss: 1.0650 - val_o5_loss: 1.1833 - val_o6_loss: 1.1630 - val_o7_loss: 1.1733 - val_o8_loss: 0.9751 - val_o1_acc: 0.7280 - val_o2_acc: 0.6480 - val_o3_acc: 0.6090 - val_o4_acc: 0.5530 - val_o5_acc: 0.5330 - val_o6_acc: 0.5140 - val_o7_acc: 0.5040 - val_o8_acc: 0.5260\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.6008 - o1_loss: 0.7083 - o2_loss: 0.8157 - o3_loss: 0.8727 - o4_loss: 0.9610 - o5_loss: 1.0382 - o6_loss: 1.1018 - o7_loss: 1.1281 - o8_loss: 0.9750 - o1_acc: 0.7131 - o2_acc: 0.6687 - o3_acc: 0.6354 - o4_acc: 0.5899 - o5_acc: 0.5532 - o6_acc: 0.5221 - o7_acc: 0.4922 - o8_acc: 0.5359 - val_loss: 7.2397 - val_o1_loss: 0.6852 - val_o2_loss: 0.7490 - val_o3_loss: 0.8043 - val_o4_loss: 0.8779 - val_o5_loss: 0.9443 - val_o6_loss: 1.0308 - val_o7_loss: 1.0914 - val_o8_loss: 1.0567 - val_o1_acc: 0.7170 - val_o2_acc: 0.7160 - val_o3_acc: 0.6880 - val_o4_acc: 0.6330 - val_o5_acc: 0.6200 - val_o6_acc: 0.5410 - val_o7_acc: 0.4900 - val_o8_acc: 0.5000\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.1372 - o1_loss: 0.6671 - o2_loss: 0.7584 - o3_loss: 0.7976 - o4_loss: 0.8715 - o5_loss: 0.9567 - o6_loss: 1.0438 - o7_loss: 1.0871 - o8_loss: 0.9549 - o1_acc: 0.7366 - o2_acc: 0.7003 - o3_acc: 0.6643 - o4_acc: 0.6265 - o5_acc: 0.5891 - o6_acc: 0.5425 - o7_acc: 0.5029 - o8_acc: 0.5376 - val_loss: 7.6967 - val_o1_loss: 0.6492 - val_o2_loss: 0.7191 - val_o3_loss: 0.8170 - val_o4_loss: 1.0001 - val_o5_loss: 1.0777 - val_o6_loss: 1.1665 - val_o7_loss: 1.1859 - val_o8_loss: 1.0811 - val_o1_acc: 0.7390 - val_o2_acc: 0.7280 - val_o3_acc: 0.6440 - val_o4_acc: 0.5470 - val_o5_acc: 0.5330 - val_o6_acc: 0.5040 - val_o7_acc: 0.4710 - val_o8_acc: 0.4860\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.0589 - o1_loss: 0.6333 - o2_loss: 0.7309 - o3_loss: 0.7847 - o4_loss: 0.8660 - o5_loss: 0.9562 - o6_loss: 1.0397 - o7_loss: 1.0872 - o8_loss: 0.9610 - o1_acc: 0.7550 - o2_acc: 0.7101 - o3_acc: 0.6724 - o4_acc: 0.6285 - o5_acc: 0.5841 - o6_acc: 0.5486 - o7_acc: 0.5067 - o8_acc: 0.5326 - val_loss: 6.7510 - val_o1_loss: 0.6214 - val_o2_loss: 0.6842 - val_o3_loss: 0.7392 - val_o4_loss: 0.8191 - val_o5_loss: 0.9024 - val_o6_loss: 0.9616 - val_o7_loss: 1.0446 - val_o8_loss: 0.9784 - val_o1_acc: 0.7710 - val_o2_acc: 0.7500 - val_o3_acc: 0.7010 - val_o4_acc: 0.6410 - val_o5_acc: 0.6240 - val_o6_acc: 0.5570 - val_o7_acc: 0.5160 - val_o8_acc: 0.5070\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 7.0568 - o1_loss: 0.6116 - o2_loss: 0.7105 - o3_loss: 0.7762 - o4_loss: 0.8730 - o5_loss: 0.9617 - o6_loss: 1.0514 - o7_loss: 1.0941 - o8_loss: 0.9783 - o1_acc: 0.7649 - o2_acc: 0.7166 - o3_acc: 0.6738 - o4_acc: 0.6271 - o5_acc: 0.5871 - o6_acc: 0.5460 - o7_acc: 0.5089 - o8_acc: 0.5348 - val_loss: 6.7656 - val_o1_loss: 0.5869 - val_o2_loss: 0.6678 - val_o3_loss: 0.7448 - val_o4_loss: 0.8267 - val_o5_loss: 0.9080 - val_o6_loss: 0.9974 - val_o7_loss: 1.0502 - val_o8_loss: 0.9836 - val_o1_acc: 0.7840 - val_o2_acc: 0.7280 - val_o3_acc: 0.6950 - val_o4_acc: 0.6370 - val_o5_acc: 0.6250 - val_o6_acc: 0.5510 - val_o7_acc: 0.5290 - val_o8_acc: 0.5260\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.7393 - o1_loss: 0.5706 - o2_loss: 0.6736 - o3_loss: 0.7267 - o4_loss: 0.8153 - o5_loss: 0.9133 - o6_loss: 1.0120 - o7_loss: 1.0713 - o8_loss: 0.9563 - o1_acc: 0.7913 - o2_acc: 0.7335 - o3_acc: 0.6981 - o4_acc: 0.6542 - o5_acc: 0.6038 - o6_acc: 0.5619 - o7_acc: 0.5137 - o8_acc: 0.5324 - val_loss: 6.4951 - val_o1_loss: 0.5779 - val_o2_loss: 0.6433 - val_o3_loss: 0.6829 - val_o4_loss: 0.7692 - val_o5_loss: 0.8680 - val_o6_loss: 0.9704 - val_o7_loss: 1.0385 - val_o8_loss: 0.9449 - val_o1_acc: 0.8010 - val_o2_acc: 0.7740 - val_o3_acc: 0.7570 - val_o4_acc: 0.6690 - val_o5_acc: 0.6480 - val_o6_acc: 0.5920 - val_o7_acc: 0.5370 - val_o8_acc: 0.5330\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.4891 - o1_loss: 0.5261 - o2_loss: 0.6295 - o3_loss: 0.6871 - o4_loss: 0.7700 - o5_loss: 0.8760 - o6_loss: 0.9801 - o7_loss: 1.0605 - o8_loss: 0.9597 - o1_acc: 0.8308 - o2_acc: 0.7610 - o3_acc: 0.7188 - o4_acc: 0.6679 - o5_acc: 0.6256 - o6_acc: 0.5750 - o7_acc: 0.5106 - o8_acc: 0.5371 - val_loss: 12.0825 - val_o1_loss: 0.6226 - val_o2_loss: 0.9200 - val_o3_loss: 1.4153 - val_o4_loss: 1.9105 - val_o5_loss: 2.1333 - val_o6_loss: 1.9660 - val_o7_loss: 1.8669 - val_o8_loss: 1.2479 - val_o1_acc: 0.7610 - val_o2_acc: 0.6050 - val_o3_acc: 0.4370 - val_o4_acc: 0.3440 - val_o5_acc: 0.3540 - val_o6_acc: 0.3290 - val_o7_acc: 0.3280 - val_o8_acc: 0.4930\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.4125 - o1_loss: 0.5017 - o2_loss: 0.6114 - o3_loss: 0.6775 - o4_loss: 0.7667 - o5_loss: 0.8636 - o6_loss: 0.9695 - o7_loss: 1.0647 - o8_loss: 0.9576 - o1_acc: 0.8444 - o2_acc: 0.7702 - o3_acc: 0.7261 - o4_acc: 0.6770 - o5_acc: 0.6350 - o6_acc: 0.5800 - o7_acc: 0.5155 - o8_acc: 0.5416 - val_loss: 6.5210 - val_o1_loss: 0.4925 - val_o2_loss: 0.5761 - val_o3_loss: 0.6691 - val_o4_loss: 0.7682 - val_o5_loss: 0.8524 - val_o6_loss: 0.9346 - val_o7_loss: 1.0613 - val_o8_loss: 1.1668 - val_o1_acc: 0.8370 - val_o2_acc: 0.8070 - val_o3_acc: 0.7350 - val_o4_acc: 0.6620 - val_o5_acc: 0.6360 - val_o6_acc: 0.5970 - val_o7_acc: 0.5280 - val_o8_acc: 0.4270\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.3062 - o1_loss: 0.4693 - o2_loss: 0.5867 - o3_loss: 0.6604 - o4_loss: 0.7539 - o5_loss: 0.8533 - o6_loss: 0.9577 - o7_loss: 1.0501 - o8_loss: 0.9748 - o1_acc: 0.8666 - o2_acc: 0.7857 - o3_acc: 0.7302 - o4_acc: 0.6860 - o5_acc: 0.6393 - o6_acc: 0.5879 - o7_acc: 0.5216 - o8_acc: 0.5286 - val_loss: 6.4504 - val_o1_loss: 0.4701 - val_o2_loss: 0.5642 - val_o3_loss: 0.6454 - val_o4_loss: 0.7256 - val_o5_loss: 0.8601 - val_o6_loss: 1.0282 - val_o7_loss: 1.1485 - val_o8_loss: 1.0083 - val_o1_acc: 0.8680 - val_o2_acc: 0.8140 - val_o3_acc: 0.7650 - val_o4_acc: 0.6890 - val_o5_acc: 0.6430 - val_o6_acc: 0.5450 - val_o7_acc: 0.4780 - val_o8_acc: 0.4990\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 6.2928 - o1_loss: 0.4436 - o2_loss: 0.5726 - o3_loss: 0.6584 - o4_loss: 0.7539 - o5_loss: 0.8504 - o6_loss: 0.9634 - o7_loss: 1.0663 - o8_loss: 0.9842 - o1_acc: 0.8766 - o2_acc: 0.7860 - o3_acc: 0.7380 - o4_acc: 0.6929 - o5_acc: 0.6443 - o6_acc: 0.5909 - o7_acc: 0.5188 - o8_acc: 0.5258 - val_loss: 6.1400 - val_o1_loss: 0.4262 - val_o2_loss: 0.5182 - val_o3_loss: 0.6027 - val_o4_loss: 0.6799 - val_o5_loss: 0.7988 - val_o6_loss: 0.9535 - val_o7_loss: 1.1400 - val_o8_loss: 1.0207 - val_o1_acc: 0.8750 - val_o2_acc: 0.8420 - val_o3_acc: 0.7850 - val_o4_acc: 0.7310 - val_o5_acc: 0.6770 - val_o6_acc: 0.5690 - val_o7_acc: 0.4640 - val_o8_acc: 0.5300\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.9540 - o1_loss: 0.4008 - o2_loss: 0.5319 - o3_loss: 0.6083 - o4_loss: 0.6973 - o5_loss: 0.7967 - o6_loss: 0.9193 - o7_loss: 1.0376 - o8_loss: 0.9621 - o1_acc: 0.8966 - o2_acc: 0.8149 - o3_acc: 0.7629 - o4_acc: 0.7209 - o5_acc: 0.6728 - o6_acc: 0.6080 - o7_acc: 0.5327 - o8_acc: 0.5319 - val_loss: 5.8163 - val_o1_loss: 0.3879 - val_o2_loss: 0.4932 - val_o3_loss: 0.5811 - val_o4_loss: 0.6606 - val_o5_loss: 0.7747 - val_o6_loss: 0.9007 - val_o7_loss: 1.0507 - val_o8_loss: 0.9674 - val_o1_acc: 0.8970 - val_o2_acc: 0.8540 - val_o3_acc: 0.8000 - val_o4_acc: 0.7400 - val_o5_acc: 0.6860 - val_o6_acc: 0.5960 - val_o7_acc: 0.5310 - val_o8_acc: 0.5370\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.7607 - o1_loss: 0.3674 - o2_loss: 0.4982 - o3_loss: 0.5748 - o4_loss: 0.6655 - o5_loss: 0.7647 - o6_loss: 0.8982 - o7_loss: 1.0243 - o8_loss: 0.9676 - o1_acc: 0.9112 - o2_acc: 0.8288 - o3_acc: 0.7781 - o4_acc: 0.7375 - o5_acc: 0.6878 - o6_acc: 0.6174 - o7_acc: 0.5366 - o8_acc: 0.5269 - val_loss: 6.9476 - val_o1_loss: 0.4062 - val_o2_loss: 0.5776 - val_o3_loss: 0.7152 - val_o4_loss: 0.8342 - val_o5_loss: 0.9490 - val_o6_loss: 1.0722 - val_o7_loss: 1.1955 - val_o8_loss: 1.1977 - val_o1_acc: 0.8640 - val_o2_acc: 0.7630 - val_o3_acc: 0.6820 - val_o4_acc: 0.6310 - val_o5_acc: 0.6060 - val_o6_acc: 0.5310 - val_o7_acc: 0.4430 - val_o8_acc: 0.4680\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.6469 - o1_loss: 0.3455 - o2_loss: 0.4821 - o3_loss: 0.5594 - o4_loss: 0.6449 - o5_loss: 0.7484 - o6_loss: 0.8837 - o7_loss: 1.0210 - o8_loss: 0.9619 - o1_acc: 0.9142 - o2_acc: 0.8345 - o3_acc: 0.7845 - o4_acc: 0.7473 - o5_acc: 0.6961 - o6_acc: 0.6192 - o7_acc: 0.5383 - o8_acc: 0.5326 - val_loss: 6.0091 - val_o1_loss: 0.3587 - val_o2_loss: 0.4645 - val_o3_loss: 0.5599 - val_o4_loss: 0.6658 - val_o5_loss: 0.7620 - val_o6_loss: 0.9224 - val_o7_loss: 1.0661 - val_o8_loss: 1.2098 - val_o1_acc: 0.8830 - val_o2_acc: 0.8470 - val_o3_acc: 0.7780 - val_o4_acc: 0.7130 - val_o5_acc: 0.6790 - val_o6_acc: 0.5780 - val_o7_acc: 0.5060 - val_o8_acc: 0.4020\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.4412 - o1_loss: 0.3206 - o2_loss: 0.4544 - o3_loss: 0.5324 - o4_loss: 0.6123 - o5_loss: 0.7149 - o6_loss: 0.8561 - o7_loss: 1.0013 - o8_loss: 0.9491 - o1_acc: 0.9193 - o2_acc: 0.8464 - o3_acc: 0.7936 - o4_acc: 0.7542 - o5_acc: 0.7050 - o6_acc: 0.6325 - o7_acc: 0.5426 - o8_acc: 0.5372 - val_loss: 5.1740 - val_o1_loss: 0.3155 - val_o2_loss: 0.4206 - val_o3_loss: 0.5013 - val_o4_loss: 0.5797 - val_o5_loss: 0.6669 - val_o6_loss: 0.8167 - val_o7_loss: 0.9539 - val_o8_loss: 0.9193 - val_o1_acc: 0.9130 - val_o2_acc: 0.8720 - val_o3_acc: 0.8190 - val_o4_acc: 0.7710 - val_o5_acc: 0.7280 - val_o6_acc: 0.6490 - val_o7_acc: 0.5680 - val_o8_acc: 0.5610\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.4682 - o1_loss: 0.3071 - o2_loss: 0.4436 - o3_loss: 0.5374 - o4_loss: 0.6252 - o5_loss: 0.7310 - o6_loss: 0.8693 - o7_loss: 1.0079 - o8_loss: 0.9467 - o1_acc: 0.9201 - o2_acc: 0.8523 - o3_acc: 0.7950 - o4_acc: 0.7499 - o5_acc: 0.6989 - o6_acc: 0.6311 - o7_acc: 0.5477 - o8_acc: 0.5442 - val_loss: 5.1492 - val_o1_loss: 0.3020 - val_o2_loss: 0.4016 - val_o3_loss: 0.4853 - val_o4_loss: 0.5820 - val_o5_loss: 0.6625 - val_o6_loss: 0.8205 - val_o7_loss: 0.9679 - val_o8_loss: 0.9274 - val_o1_acc: 0.9140 - val_o2_acc: 0.8800 - val_o3_acc: 0.8190 - val_o4_acc: 0.7660 - val_o5_acc: 0.7380 - val_o6_acc: 0.6520 - val_o7_acc: 0.5560 - val_o8_acc: 0.5480\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.3140 - o1_loss: 0.2909 - o2_loss: 0.4248 - o3_loss: 0.5141 - o4_loss: 0.6058 - o5_loss: 0.7001 - o6_loss: 0.8455 - o7_loss: 0.9930 - o8_loss: 0.9399 - o1_acc: 0.9241 - o2_acc: 0.8557 - o3_acc: 0.8035 - o4_acc: 0.7568 - o5_acc: 0.7143 - o6_acc: 0.6440 - o7_acc: 0.5506 - o8_acc: 0.5492 - val_loss: 5.0050 - val_o1_loss: 0.2818 - val_o2_loss: 0.3939 - val_o3_loss: 0.4708 - val_o4_loss: 0.5545 - val_o5_loss: 0.6597 - val_o6_loss: 0.7899 - val_o7_loss: 0.9066 - val_o8_loss: 0.9479 - val_o1_acc: 0.9180 - val_o2_acc: 0.8860 - val_o3_acc: 0.8250 - val_o4_acc: 0.7840 - val_o5_acc: 0.7370 - val_o6_acc: 0.6490 - val_o7_acc: 0.6030 - val_o8_acc: 0.5250\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.9212 - o1_loss: 0.2578 - o2_loss: 0.3813 - o3_loss: 0.4550 - o4_loss: 0.5333 - o5_loss: 0.6415 - o6_loss: 0.7930 - o7_loss: 0.9451 - o8_loss: 0.9141 - o1_acc: 0.9388 - o2_acc: 0.8793 - o3_acc: 0.8314 - o4_acc: 0.7919 - o5_acc: 0.7364 - o6_acc: 0.6599 - o7_acc: 0.5767 - o8_acc: 0.5579 - val_loss: 4.8669 - val_o1_loss: 0.2549 - val_o2_loss: 0.3643 - val_o3_loss: 0.4432 - val_o4_loss: 0.5417 - val_o5_loss: 0.6414 - val_o6_loss: 0.8073 - val_o7_loss: 0.9315 - val_o8_loss: 0.8826 - val_o1_acc: 0.9280 - val_o2_acc: 0.8930 - val_o3_acc: 0.8330 - val_o4_acc: 0.7830 - val_o5_acc: 0.7240 - val_o6_acc: 0.6490 - val_o7_acc: 0.5880 - val_o8_acc: 0.5720\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 5.1250 - o1_loss: 0.2553 - o2_loss: 0.3916 - o3_loss: 0.4771 - o4_loss: 0.5785 - o5_loss: 0.6824 - o6_loss: 0.8302 - o7_loss: 0.9771 - o8_loss: 0.9329 - o1_acc: 0.9337 - o2_acc: 0.8704 - o3_acc: 0.8192 - o4_acc: 0.7689 - o5_acc: 0.7194 - o6_acc: 0.6449 - o7_acc: 0.5658 - o8_acc: 0.5567 - val_loss: 4.7721 - val_o1_loss: 0.2401 - val_o2_loss: 0.3493 - val_o3_loss: 0.4273 - val_o4_loss: 0.5268 - val_o5_loss: 0.6201 - val_o6_loss: 0.7703 - val_o7_loss: 0.8911 - val_o8_loss: 0.9470 - val_o1_acc: 0.9410 - val_o2_acc: 0.8980 - val_o3_acc: 0.8390 - val_o4_acc: 0.7790 - val_o5_acc: 0.7500 - val_o6_acc: 0.6590 - val_o7_acc: 0.6130 - val_o8_acc: 0.5380\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.7934 - o1_loss: 0.2318 - o2_loss: 0.3482 - o3_loss: 0.4255 - o4_loss: 0.5097 - o5_loss: 0.6304 - o6_loss: 0.7890 - o7_loss: 0.9490 - o8_loss: 0.9098 - o1_acc: 0.9439 - o2_acc: 0.8891 - o3_acc: 0.8386 - o4_acc: 0.7956 - o5_acc: 0.7349 - o6_acc: 0.6591 - o7_acc: 0.5709 - o8_acc: 0.5687 - val_loss: 4.8065 - val_o1_loss: 0.2463 - val_o2_loss: 0.3413 - val_o3_loss: 0.4095 - val_o4_loss: 0.5136 - val_o5_loss: 0.6182 - val_o6_loss: 0.7701 - val_o7_loss: 0.9181 - val_o8_loss: 0.9895 - val_o1_acc: 0.9330 - val_o2_acc: 0.8900 - val_o3_acc: 0.8490 - val_o4_acc: 0.7850 - val_o5_acc: 0.7320 - val_o6_acc: 0.6420 - val_o7_acc: 0.5600 - val_o8_acc: 0.5250\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.7110 - o1_loss: 0.2234 - o2_loss: 0.3383 - o3_loss: 0.4082 - o4_loss: 0.5037 - o5_loss: 0.6147 - o6_loss: 0.7797 - o7_loss: 0.9383 - o8_loss: 0.9047 - o1_acc: 0.9459 - o2_acc: 0.8898 - o3_acc: 0.8486 - o4_acc: 0.7976 - o5_acc: 0.7437 - o6_acc: 0.6624 - o7_acc: 0.5728 - o8_acc: 0.5714 - val_loss: 4.7050 - val_o1_loss: 0.2234 - val_o2_loss: 0.3170 - val_o3_loss: 0.3874 - val_o4_loss: 0.4974 - val_o5_loss: 0.6182 - val_o6_loss: 0.7710 - val_o7_loss: 0.8997 - val_o8_loss: 0.9910 - val_o1_acc: 0.9450 - val_o2_acc: 0.9000 - val_o3_acc: 0.8580 - val_o4_acc: 0.8030 - val_o5_acc: 0.7450 - val_o6_acc: 0.6490 - val_o7_acc: 0.5750 - val_o8_acc: 0.4920\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.5946 - o1_loss: 0.2130 - o2_loss: 0.3227 - o3_loss: 0.3927 - o4_loss: 0.4780 - o5_loss: 0.5940 - o6_loss: 0.7618 - o7_loss: 0.9303 - o8_loss: 0.9021 - o1_acc: 0.9487 - o2_acc: 0.8966 - o3_acc: 0.8516 - o4_acc: 0.8097 - o5_acc: 0.7534 - o6_acc: 0.6683 - o7_acc: 0.5742 - o8_acc: 0.5761 - val_loss: 5.0852 - val_o1_loss: 0.2198 - val_o2_loss: 0.3210 - val_o3_loss: 0.3888 - val_o4_loss: 0.4946 - val_o5_loss: 0.6578 - val_o6_loss: 0.8780 - val_o7_loss: 1.1034 - val_o8_loss: 1.0219 - val_o1_acc: 0.9360 - val_o2_acc: 0.8980 - val_o3_acc: 0.8550 - val_o4_acc: 0.8070 - val_o5_acc: 0.7150 - val_o6_acc: 0.6070 - val_o7_acc: 0.4960 - val_o8_acc: 0.4960\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.7940 - o1_loss: 0.2174 - o2_loss: 0.3404 - o3_loss: 0.4284 - o4_loss: 0.5396 - o5_loss: 0.6378 - o6_loss: 0.7859 - o7_loss: 0.9429 - o8_loss: 0.9014 - o1_acc: 0.9435 - o2_acc: 0.8879 - o3_acc: 0.8480 - o4_acc: 0.7987 - o5_acc: 0.7445 - o6_acc: 0.6699 - o7_acc: 0.5810 - o8_acc: 0.5778 - val_loss: 4.4778 - val_o1_loss: 0.1979 - val_o2_loss: 0.3143 - val_o3_loss: 0.3884 - val_o4_loss: 0.4881 - val_o5_loss: 0.6004 - val_o6_loss: 0.7656 - val_o7_loss: 0.8724 - val_o8_loss: 0.8506 - val_o1_acc: 0.9490 - val_o2_acc: 0.9000 - val_o3_acc: 0.8610 - val_o4_acc: 0.7960 - val_o5_acc: 0.7550 - val_o6_acc: 0.6630 - val_o7_acc: 0.6210 - val_o8_acc: 0.5950\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.3342 - o1_loss: 0.1882 - o2_loss: 0.2845 - o3_loss: 0.3482 - o4_loss: 0.4427 - o5_loss: 0.5622 - o6_loss: 0.7260 - o7_loss: 0.8980 - o8_loss: 0.8843 - o1_acc: 0.9578 - o2_acc: 0.9154 - o3_acc: 0.8788 - o4_acc: 0.8260 - o5_acc: 0.7637 - o6_acc: 0.6843 - o7_acc: 0.5855 - o8_acc: 0.5773 - val_loss: 4.2504 - val_o1_loss: 0.2119 - val_o2_loss: 0.2866 - val_o3_loss: 0.3393 - val_o4_loss: 0.4410 - val_o5_loss: 0.5707 - val_o6_loss: 0.7051 - val_o7_loss: 0.8329 - val_o8_loss: 0.8628 - val_o1_acc: 0.9420 - val_o2_acc: 0.9180 - val_o3_acc: 0.8810 - val_o4_acc: 0.8240 - val_o5_acc: 0.7580 - val_o6_acc: 0.6850 - val_o7_acc: 0.6280 - val_o8_acc: 0.5830\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 4.2767 - o1_loss: 0.1840 - o2_loss: 0.2730 - o3_loss: 0.3337 - o4_loss: 0.4291 - o5_loss: 0.5517 - o6_loss: 0.7263 - o7_loss: 0.8922 - o8_loss: 0.8867 - o1_acc: 0.9597 - o2_acc: 0.9192 - o3_acc: 0.8822 - o4_acc: 0.8316 - o5_acc: 0.7658 - o6_acc: 0.6826 - o7_acc: 0.5878 - o8_acc: 0.5809 - val_loss: 4.0911 - val_o1_loss: 0.1782 - val_o2_loss: 0.2623 - val_o3_loss: 0.3270 - val_o4_loss: 0.4318 - val_o5_loss: 0.5572 - val_o6_loss: 0.6922 - val_o7_loss: 0.8087 - val_o8_loss: 0.8337 - val_o1_acc: 0.9510 - val_o2_acc: 0.9280 - val_o3_acc: 0.8930 - val_o4_acc: 0.8350 - val_o5_acc: 0.7540 - val_o6_acc: 0.7020 - val_o7_acc: 0.6520 - val_o8_acc: 0.5940\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 4.3047 - o1_loss: 0.1790 - o2_loss: 0.2700 - o3_loss: 0.3352 - o4_loss: 0.4403 - o5_loss: 0.5682 - o6_loss: 0.7348 - o7_loss: 0.8975 - o8_loss: 0.8798 - o1_acc: 0.9585 - o2_acc: 0.9178 - o3_acc: 0.8816 - o4_acc: 0.8279 - o5_acc: 0.7636 - o6_acc: 0.6788 - o7_acc: 0.5893 - o8_acc: 0.5851 - val_loss: 4.2510 - val_o1_loss: 0.1678 - val_o2_loss: 0.2507 - val_o3_loss: 0.3206 - val_o4_loss: 0.4176 - val_o5_loss: 0.5443 - val_o6_loss: 0.7106 - val_o7_loss: 0.9208 - val_o8_loss: 0.9185 - val_o1_acc: 0.9560 - val_o2_acc: 0.9340 - val_o3_acc: 0.8960 - val_o4_acc: 0.8330 - val_o5_acc: 0.7610 - val_o6_acc: 0.7000 - val_o7_acc: 0.5640 - val_o8_acc: 0.5250\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 4.0873 - o1_loss: 0.1683 - o2_loss: 0.2479 - o3_loss: 0.3004 - o4_loss: 0.3982 - o5_loss: 0.5188 - o6_loss: 0.7005 - o7_loss: 0.8753 - o8_loss: 0.8778 - o1_acc: 0.9610 - o2_acc: 0.9261 - o3_acc: 0.8989 - o4_acc: 0.8409 - o5_acc: 0.7830 - o6_acc: 0.6962 - o7_acc: 0.5953 - o8_acc: 0.5771 - val_loss: 6.1598 - val_o1_loss: 0.2299 - val_o2_loss: 0.4480 - val_o3_loss: 0.8942 - val_o4_loss: 1.1083 - val_o5_loss: 0.8336 - val_o6_loss: 0.8758 - val_o7_loss: 0.8788 - val_o8_loss: 0.8913 - val_o1_acc: 0.9130 - val_o2_acc: 0.7960 - val_o3_acc: 0.6770 - val_o4_acc: 0.6380 - val_o5_acc: 0.6830 - val_o6_acc: 0.6520 - val_o7_acc: 0.6130 - val_o8_acc: 0.5750\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 4.3956 - o1_loss: 0.1871 - o2_loss: 0.2946 - o3_loss: 0.3742 - o4_loss: 0.4839 - o5_loss: 0.5889 - o6_loss: 0.7343 - o7_loss: 0.8762 - o8_loss: 0.8564 - o1_acc: 0.9506 - o2_acc: 0.9114 - o3_acc: 0.8793 - o4_acc: 0.8322 - o5_acc: 0.7725 - o6_acc: 0.6936 - o7_acc: 0.6063 - o8_acc: 0.5965 - val_loss: 4.3453 - val_o1_loss: 0.1564 - val_o2_loss: 0.2385 - val_o3_loss: 0.3030 - val_o4_loss: 0.4101 - val_o5_loss: 0.5488 - val_o6_loss: 0.7469 - val_o7_loss: 0.9983 - val_o8_loss: 0.9432 - val_o1_acc: 0.9590 - val_o2_acc: 0.9310 - val_o3_acc: 0.8970 - val_o4_acc: 0.8400 - val_o5_acc: 0.7680 - val_o6_acc: 0.6650 - val_o7_acc: 0.5230 - val_o8_acc: 0.5240\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 3.8833 - o1_loss: 0.1522 - o2_loss: 0.2262 - o3_loss: 0.2765 - o4_loss: 0.3722 - o5_loss: 0.4895 - o6_loss: 0.6637 - o7_loss: 0.8442 - o8_loss: 0.8587 - o1_acc: 0.9671 - o2_acc: 0.9375 - o3_acc: 0.9103 - o4_acc: 0.8596 - o5_acc: 0.7965 - o6_acc: 0.7099 - o7_acc: 0.6092 - o8_acc: 0.5877 - val_loss: 3.8454 - val_o1_loss: 0.1544 - val_o2_loss: 0.2255 - val_o3_loss: 0.2932 - val_o4_loss: 0.4256 - val_o5_loss: 0.5326 - val_o6_loss: 0.6557 - val_o7_loss: 0.7603 - val_o8_loss: 0.7982 - val_o1_acc: 0.9630 - val_o2_acc: 0.9400 - val_o3_acc: 0.9050 - val_o4_acc: 0.8290 - val_o5_acc: 0.7620 - val_o6_acc: 0.7090 - val_o7_acc: 0.6620 - val_o8_acc: 0.6200\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 20s 2ms/step - loss: 3.8175 - o1_loss: 0.1505 - o2_loss: 0.2172 - o3_loss: 0.2644 - o4_loss: 0.3609 - o5_loss: 0.4780 - o6_loss: 0.6626 - o7_loss: 0.8409 - o8_loss: 0.8430 - o1_acc: 0.9650 - o2_acc: 0.9385 - o3_acc: 0.9173 - o4_acc: 0.8640 - o5_acc: 0.8040 - o6_acc: 0.7090 - o7_acc: 0.6036 - o8_acc: 0.5952 - val_loss: 3.7027 - val_o1_loss: 0.1587 - val_o2_loss: 0.2495 - val_o3_loss: 0.3014 - val_o4_loss: 0.3769 - val_o5_loss: 0.5026 - val_o6_loss: 0.6128 - val_o7_loss: 0.7345 - val_o8_loss: 0.7663 - val_o1_acc: 0.9540 - val_o2_acc: 0.9270 - val_o3_acc: 0.8840 - val_o4_acc: 0.8450 - val_o5_acc: 0.7830 - val_o6_acc: 0.7350 - val_o7_acc: 0.6620 - val_o8_acc: 0.6240\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 3.6993 - o1_loss: 0.1438 - o2_loss: 0.2072 - o3_loss: 0.2524 - o4_loss: 0.3480 - o5_loss: 0.4668 - o6_loss: 0.6387 - o7_loss: 0.8133 - o8_loss: 0.8292 - o1_acc: 0.9677 - o2_acc: 0.9452 - o3_acc: 0.9217 - o4_acc: 0.8701 - o5_acc: 0.8019 - o6_acc: 0.7226 - o7_acc: 0.6209 - o8_acc: 0.5993 - val_loss: 3.4778 - val_o1_loss: 0.1448 - val_o2_loss: 0.2009 - val_o3_loss: 0.2471 - val_o4_loss: 0.3500 - val_o5_loss: 0.4569 - val_o6_loss: 0.5828 - val_o7_loss: 0.7431 - val_o8_loss: 0.7520 - val_o1_acc: 0.9600 - val_o2_acc: 0.9500 - val_o3_acc: 0.9250 - val_o4_acc: 0.8660 - val_o5_acc: 0.8040 - val_o6_acc: 0.7610 - val_o7_acc: 0.6670 - val_o8_acc: 0.6120\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.6087 - o1_loss: 0.1352 - o2_loss: 0.1967 - o3_loss: 0.2376 - o4_loss: 0.3309 - o5_loss: 0.4499 - o6_loss: 0.6262 - o7_loss: 0.8013 - o8_loss: 0.8308 - o1_acc: 0.9719 - o2_acc: 0.9465 - o3_acc: 0.9257 - o4_acc: 0.8779 - o5_acc: 0.8131 - o6_acc: 0.7215 - o7_acc: 0.6241 - o8_acc: 0.5986 - val_loss: 3.4149 - val_o1_loss: 0.1541 - val_o2_loss: 0.1976 - val_o3_loss: 0.2368 - val_o4_loss: 0.3458 - val_o5_loss: 0.4609 - val_o6_loss: 0.5745 - val_o7_loss: 0.6899 - val_o8_loss: 0.7554 - val_o1_acc: 0.9530 - val_o2_acc: 0.9540 - val_o3_acc: 0.9250 - val_o4_acc: 0.8650 - val_o5_acc: 0.8090 - val_o6_acc: 0.7580 - val_o7_acc: 0.6980 - val_o8_acc: 0.6400\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.5157 - o1_loss: 0.1306 - o2_loss: 0.1873 - o3_loss: 0.2292 - o4_loss: 0.3217 - o5_loss: 0.4377 - o6_loss: 0.6134 - o7_loss: 0.7812 - o8_loss: 0.8145 - o1_acc: 0.9715 - o2_acc: 0.9526 - o3_acc: 0.9304 - o4_acc: 0.8799 - o5_acc: 0.8173 - o6_acc: 0.7357 - o7_acc: 0.6341 - o8_acc: 0.6135 - val_loss: 3.2842 - val_o1_loss: 0.1188 - val_o2_loss: 0.1787 - val_o3_loss: 0.2256 - val_o4_loss: 0.3167 - val_o5_loss: 0.4437 - val_o6_loss: 0.5586 - val_o7_loss: 0.7044 - val_o8_loss: 0.7376 - val_o1_acc: 0.9700 - val_o2_acc: 0.9610 - val_o3_acc: 0.9240 - val_o4_acc: 0.8770 - val_o5_acc: 0.8160 - val_o6_acc: 0.7740 - val_o7_acc: 0.6790 - val_o8_acc: 0.6370\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.4336 - o1_loss: 0.1228 - o2_loss: 0.1790 - o3_loss: 0.2195 - o4_loss: 0.3091 - o5_loss: 0.4267 - o6_loss: 0.5980 - o7_loss: 0.7741 - o8_loss: 0.8044 - o1_acc: 0.9734 - o2_acc: 0.9531 - o3_acc: 0.9327 - o4_acc: 0.8879 - o5_acc: 0.8283 - o6_acc: 0.7397 - o7_acc: 0.6405 - o8_acc: 0.6173 - val_loss: 3.8390 - val_o1_loss: 0.1791 - val_o2_loss: 0.1995 - val_o3_loss: 0.2362 - val_o4_loss: 0.3540 - val_o5_loss: 0.4957 - val_o6_loss: 0.6406 - val_o7_loss: 0.8014 - val_o8_loss: 0.9326 - val_o1_acc: 0.9330 - val_o2_acc: 0.9450 - val_o3_acc: 0.9240 - val_o4_acc: 0.8610 - val_o5_acc: 0.7870 - val_o6_acc: 0.7200 - val_o7_acc: 0.6180 - val_o8_acc: 0.5530\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.3614 - o1_loss: 0.1187 - o2_loss: 0.1709 - o3_loss: 0.2118 - o4_loss: 0.3007 - o5_loss: 0.4170 - o6_loss: 0.5844 - o7_loss: 0.7618 - o8_loss: 0.7960 - o1_acc: 0.9747 - o2_acc: 0.9554 - o3_acc: 0.9354 - o4_acc: 0.8912 - o5_acc: 0.8334 - o6_acc: 0.7531 - o7_acc: 0.6442 - o8_acc: 0.6181 - val_loss: 3.5161 - val_o1_loss: 0.1234 - val_o2_loss: 0.1707 - val_o3_loss: 0.2166 - val_o4_loss: 0.3027 - val_o5_loss: 0.4315 - val_o6_loss: 0.5943 - val_o7_loss: 0.8364 - val_o8_loss: 0.8405 - val_o1_acc: 0.9630 - val_o2_acc: 0.9610 - val_o3_acc: 0.9330 - val_o4_acc: 0.8910 - val_o5_acc: 0.8180 - val_o6_acc: 0.7430 - val_o7_acc: 0.5620 - val_o8_acc: 0.5660\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.2654 - o1_loss: 0.1106 - o2_loss: 0.1628 - o3_loss: 0.2030 - o4_loss: 0.2906 - o5_loss: 0.4038 - o6_loss: 0.5748 - o7_loss: 0.7391 - o8_loss: 0.7807 - o1_acc: 0.9761 - o2_acc: 0.9592 - o3_acc: 0.9389 - o4_acc: 0.8960 - o5_acc: 0.8388 - o6_acc: 0.7504 - o7_acc: 0.6477 - o8_acc: 0.6215 - val_loss: 5.6194 - val_o1_loss: 0.1472 - val_o2_loss: 0.2606 - val_o3_loss: 0.3915 - val_o4_loss: 0.6604 - val_o5_loss: 0.8828 - val_o6_loss: 1.1660 - val_o7_loss: 1.1472 - val_o8_loss: 0.9636 - val_o1_acc: 0.9500 - val_o2_acc: 0.9160 - val_o3_acc: 0.8450 - val_o4_acc: 0.7400 - val_o5_acc: 0.6740 - val_o6_acc: 0.6060 - val_o7_acc: 0.5660 - val_o8_acc: 0.5580\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.5551 - o1_loss: 0.1530 - o2_loss: 0.2339 - o3_loss: 0.2779 - o4_loss: 0.3624 - o5_loss: 0.4569 - o6_loss: 0.5906 - o7_loss: 0.7231 - o8_loss: 0.7574 - o1_acc: 0.9609 - o2_acc: 0.9402 - o3_acc: 0.9213 - o4_acc: 0.8838 - o5_acc: 0.8314 - o6_acc: 0.7503 - o7_acc: 0.6731 - o8_acc: 0.6419 - val_loss: 3.0856 - val_o1_loss: 0.1033 - val_o2_loss: 0.1689 - val_o3_loss: 0.2090 - val_o4_loss: 0.2981 - val_o5_loss: 0.4281 - val_o6_loss: 0.5329 - val_o7_loss: 0.6418 - val_o8_loss: 0.7035 - val_o1_acc: 0.9750 - val_o2_acc: 0.9470 - val_o3_acc: 0.9270 - val_o4_acc: 0.8770 - val_o5_acc: 0.8220 - val_o6_acc: 0.7740 - val_o7_acc: 0.7080 - val_o8_acc: 0.6720\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.0605 - o1_loss: 0.0973 - o2_loss: 0.1504 - o3_loss: 0.1839 - o4_loss: 0.2659 - o5_loss: 0.3808 - o6_loss: 0.5354 - o7_loss: 0.7011 - o8_loss: 0.7457 - o1_acc: 0.9802 - o2_acc: 0.9619 - o3_acc: 0.9481 - o4_acc: 0.9091 - o5_acc: 0.8503 - o6_acc: 0.7728 - o7_acc: 0.6818 - o8_acc: 0.6406 - val_loss: 3.0889 - val_o1_loss: 0.1407 - val_o2_loss: 0.1699 - val_o3_loss: 0.1998 - val_o4_loss: 0.3097 - val_o5_loss: 0.4190 - val_o6_loss: 0.5112 - val_o7_loss: 0.6282 - val_o8_loss: 0.7104 - val_o1_acc: 0.9500 - val_o2_acc: 0.9530 - val_o3_acc: 0.9400 - val_o4_acc: 0.8690 - val_o5_acc: 0.8280 - val_o6_acc: 0.7890 - val_o7_acc: 0.7370 - val_o8_acc: 0.6690\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.9921 - o1_loss: 0.0945 - o2_loss: 0.1432 - o3_loss: 0.1776 - o4_loss: 0.2569 - o5_loss: 0.3700 - o6_loss: 0.5271 - o7_loss: 0.6821 - o8_loss: 0.7406 - o1_acc: 0.9806 - o2_acc: 0.9652 - o3_acc: 0.9491 - o4_acc: 0.9127 - o5_acc: 0.8562 - o6_acc: 0.7783 - o7_acc: 0.6893 - o8_acc: 0.6473 - val_loss: 4.6460 - val_o1_loss: 0.1026 - val_o2_loss: 0.1565 - val_o3_loss: 0.2109 - val_o4_loss: 0.3209 - val_o5_loss: 0.4884 - val_o6_loss: 0.7419 - val_o7_loss: 1.1168 - val_o8_loss: 1.5081 - val_o1_acc: 0.9690 - val_o2_acc: 0.9600 - val_o3_acc: 0.9240 - val_o4_acc: 0.8730 - val_o5_acc: 0.7910 - val_o6_acc: 0.6820 - val_o7_acc: 0.5230 - val_o8_acc: 0.4350\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.0842 - o1_loss: 0.0938 - o2_loss: 0.1471 - o3_loss: 0.1905 - o4_loss: 0.2834 - o5_loss: 0.3903 - o6_loss: 0.5423 - o7_loss: 0.6889 - o8_loss: 0.7478 - o1_acc: 0.9799 - o2_acc: 0.9615 - o3_acc: 0.9429 - o4_acc: 0.9035 - o5_acc: 0.8481 - o6_acc: 0.7761 - o7_acc: 0.6837 - o8_acc: 0.6476 - val_loss: 4.1601 - val_o1_loss: 0.1734 - val_o2_loss: 0.3805 - val_o3_loss: 0.4645 - val_o4_loss: 0.4502 - val_o5_loss: 0.6006 - val_o6_loss: 0.6547 - val_o7_loss: 0.6761 - val_o8_loss: 0.7600 - val_o1_acc: 0.9350 - val_o2_acc: 0.8390 - val_o3_acc: 0.8210 - val_o4_acc: 0.8220 - val_o5_acc: 0.7520 - val_o6_acc: 0.7330 - val_o7_acc: 0.7080 - val_o8_acc: 0.6310\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.8779 - o1_loss: 0.0919 - o2_loss: 0.1402 - o3_loss: 0.1714 - o4_loss: 0.2494 - o5_loss: 0.3580 - o6_loss: 0.5082 - o7_loss: 0.6501 - o8_loss: 0.7087 - o1_acc: 0.9791 - o2_acc: 0.9642 - o3_acc: 0.9530 - o4_acc: 0.9171 - o5_acc: 0.8630 - o6_acc: 0.7917 - o7_acc: 0.7013 - o8_acc: 0.6613 - val_loss: 2.9574 - val_o1_loss: 0.0781 - val_o2_loss: 0.1260 - val_o3_loss: 0.1661 - val_o4_loss: 0.2643 - val_o5_loss: 0.3942 - val_o6_loss: 0.5191 - val_o7_loss: 0.6362 - val_o8_loss: 0.7734 - val_o1_acc: 0.9840 - val_o2_acc: 0.9730 - val_o3_acc: 0.9470 - val_o4_acc: 0.8980 - val_o5_acc: 0.8400 - val_o6_acc: 0.7680 - val_o7_acc: 0.7180 - val_o8_acc: 0.6190\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.7525 - o1_loss: 0.0840 - o2_loss: 0.1292 - o3_loss: 0.1560 - o4_loss: 0.2339 - o5_loss: 0.3390 - o6_loss: 0.4885 - o7_loss: 0.6350 - o8_loss: 0.6869 - o1_acc: 0.9829 - o2_acc: 0.9687 - o3_acc: 0.9586 - o4_acc: 0.9245 - o5_acc: 0.8730 - o6_acc: 0.7982 - o7_acc: 0.7025 - o8_acc: 0.6657 - val_loss: 3.2045 - val_o1_loss: 0.0719 - val_o2_loss: 0.1287 - val_o3_loss: 0.1799 - val_o4_loss: 0.2562 - val_o5_loss: 0.3860 - val_o6_loss: 0.5771 - val_o7_loss: 0.8099 - val_o8_loss: 0.7948 - val_o1_acc: 0.9850 - val_o2_acc: 0.9720 - val_o3_acc: 0.9440 - val_o4_acc: 0.9070 - val_o5_acc: 0.8460 - val_o6_acc: 0.7510 - val_o7_acc: 0.5970 - val_o8_acc: 0.5950\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.7335 - o1_loss: 0.0820 - o2_loss: 0.1260 - o3_loss: 0.1520 - o4_loss: 0.2271 - o5_loss: 0.3328 - o6_loss: 0.4778 - o7_loss: 0.6299 - o8_loss: 0.7060 - o1_acc: 0.9826 - o2_acc: 0.9686 - o3_acc: 0.9612 - o4_acc: 0.9293 - o5_acc: 0.8762 - o6_acc: 0.8005 - o7_acc: 0.7072 - o8_acc: 0.6662 - val_loss: 2.6397 - val_o1_loss: 0.0871 - val_o2_loss: 0.1234 - val_o3_loss: 0.1567 - val_o4_loss: 0.2345 - val_o5_loss: 0.3380 - val_o6_loss: 0.4600 - val_o7_loss: 0.5896 - val_o8_loss: 0.6502 - val_o1_acc: 0.9780 - val_o2_acc: 0.9710 - val_o3_acc: 0.9540 - val_o4_acc: 0.9270 - val_o5_acc: 0.8740 - val_o6_acc: 0.8050 - val_o7_acc: 0.7380 - val_o8_acc: 0.6910\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.6612 - o1_loss: 0.0816 - o2_loss: 0.1226 - o3_loss: 0.1480 - o4_loss: 0.2195 - o5_loss: 0.3263 - o6_loss: 0.4680 - o7_loss: 0.6115 - o8_loss: 0.6836 - o1_acc: 0.9827 - o2_acc: 0.9707 - o3_acc: 0.9610 - o4_acc: 0.9310 - o5_acc: 0.8762 - o6_acc: 0.8126 - o7_acc: 0.7164 - o8_acc: 0.6686 - val_loss: 2.5567 - val_o1_loss: 0.0727 - val_o2_loss: 0.1197 - val_o3_loss: 0.1559 - val_o4_loss: 0.2153 - val_o5_loss: 0.3305 - val_o6_loss: 0.4249 - val_o7_loss: 0.5739 - val_o8_loss: 0.6639 - val_o1_acc: 0.9830 - val_o2_acc: 0.9750 - val_o3_acc: 0.9560 - val_o4_acc: 0.9310 - val_o5_acc: 0.8760 - val_o6_acc: 0.8460 - val_o7_acc: 0.7520 - val_o8_acc: 0.6680\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.5523 - o1_loss: 0.0788 - o2_loss: 0.1190 - o3_loss: 0.1412 - o4_loss: 0.2106 - o5_loss: 0.3090 - o6_loss: 0.4457 - o7_loss: 0.5907 - o8_loss: 0.6574 - o1_acc: 0.9838 - o2_acc: 0.9713 - o3_acc: 0.9640 - o4_acc: 0.9365 - o5_acc: 0.8900 - o6_acc: 0.8208 - o7_acc: 0.7305 - o8_acc: 0.6771 - val_loss: 2.5029 - val_o1_loss: 0.0875 - val_o2_loss: 0.1118 - val_o3_loss: 0.1412 - val_o4_loss: 0.2178 - val_o5_loss: 0.3275 - val_o6_loss: 0.4311 - val_o7_loss: 0.5433 - val_o8_loss: 0.6426 - val_o1_acc: 0.9760 - val_o2_acc: 0.9750 - val_o3_acc: 0.9590 - val_o4_acc: 0.9280 - val_o5_acc: 0.8770 - val_o6_acc: 0.8310 - val_o7_acc: 0.7650 - val_o8_acc: 0.6830\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.7626 - o1_loss: 0.0918 - o2_loss: 0.1475 - o3_loss: 0.1861 - o4_loss: 0.2766 - o5_loss: 0.3584 - o6_loss: 0.4685 - o7_loss: 0.5879 - o8_loss: 0.6459 - o1_acc: 0.9752 - o2_acc: 0.9571 - o3_acc: 0.9468 - o4_acc: 0.9126 - o5_acc: 0.8765 - o6_acc: 0.8164 - o7_acc: 0.7355 - o8_acc: 0.6909 - val_loss: 2.5973 - val_o1_loss: 0.0730 - val_o2_loss: 0.1236 - val_o3_loss: 0.1593 - val_o4_loss: 0.2149 - val_o5_loss: 0.3279 - val_o6_loss: 0.4263 - val_o7_loss: 0.5853 - val_o8_loss: 0.6871 - val_o1_acc: 0.9840 - val_o2_acc: 0.9680 - val_o3_acc: 0.9530 - val_o4_acc: 0.9270 - val_o5_acc: 0.8820 - val_o6_acc: 0.8390 - val_o7_acc: 0.7320 - val_o8_acc: 0.6450\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.4091 - o1_loss: 0.0751 - o2_loss: 0.1126 - o3_loss: 0.1302 - o4_loss: 0.1932 - o5_loss: 0.2900 - o6_loss: 0.4159 - o7_loss: 0.5574 - o8_loss: 0.6346 - o1_acc: 0.9832 - o2_acc: 0.9723 - o3_acc: 0.9681 - o4_acc: 0.9443 - o5_acc: 0.8987 - o6_acc: 0.8387 - o7_acc: 0.7463 - o8_acc: 0.6995 - val_loss: 2.6575 - val_o1_loss: 0.0703 - val_o2_loss: 0.1015 - val_o3_loss: 0.1314 - val_o4_loss: 0.1857 - val_o5_loss: 0.3206 - val_o6_loss: 0.4319 - val_o7_loss: 0.5894 - val_o8_loss: 0.8267 - val_o1_acc: 0.9850 - val_o2_acc: 0.9720 - val_o3_acc: 0.9680 - val_o4_acc: 0.9460 - val_o5_acc: 0.8770 - val_o6_acc: 0.8180 - val_o7_acc: 0.7400 - val_o8_acc: 0.5940\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.3803 - o1_loss: 0.0748 - o2_loss: 0.1096 - o3_loss: 0.1258 - o4_loss: 0.1848 - o5_loss: 0.2777 - o6_loss: 0.4036 - o7_loss: 0.5631 - o8_loss: 0.6408 - o1_acc: 0.9829 - o2_acc: 0.9736 - o3_acc: 0.9680 - o4_acc: 0.9469 - o5_acc: 0.9024 - o6_acc: 0.8433 - o7_acc: 0.7434 - o8_acc: 0.6903 - val_loss: 2.8855 - val_o1_loss: 0.0649 - val_o2_loss: 0.1128 - val_o3_loss: 0.1507 - val_o4_loss: 0.2075 - val_o5_loss: 0.3348 - val_o6_loss: 0.4991 - val_o7_loss: 0.7537 - val_o8_loss: 0.7620 - val_o1_acc: 0.9850 - val_o2_acc: 0.9720 - val_o3_acc: 0.9500 - val_o4_acc: 0.9330 - val_o5_acc: 0.8700 - val_o6_acc: 0.7930 - val_o7_acc: 0.6460 - val_o8_acc: 0.6140\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.2827 - o1_loss: 0.0731 - o2_loss: 0.1065 - o3_loss: 0.1209 - o4_loss: 0.1777 - o5_loss: 0.2649 - o6_loss: 0.3807 - o7_loss: 0.5419 - o8_loss: 0.6170 - o1_acc: 0.9840 - o2_acc: 0.9748 - o3_acc: 0.9698 - o4_acc: 0.9490 - o5_acc: 0.9126 - o6_acc: 0.8545 - o7_acc: 0.7581 - o8_acc: 0.7072 - val_loss: 2.1555 - val_o1_loss: 0.0744 - val_o2_loss: 0.1010 - val_o3_loss: 0.1274 - val_o4_loss: 0.1739 - val_o5_loss: 0.2717 - val_o6_loss: 0.3594 - val_o7_loss: 0.4647 - val_o8_loss: 0.5829 - val_o1_acc: 0.9850 - val_o2_acc: 0.9760 - val_o3_acc: 0.9660 - val_o4_acc: 0.9530 - val_o5_acc: 0.9050 - val_o6_acc: 0.8520 - val_o7_acc: 0.8130 - val_o8_acc: 0.7280\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.1755 - o1_loss: 0.0731 - o2_loss: 0.1038 - o3_loss: 0.1148 - o4_loss: 0.1644 - o5_loss: 0.2447 - o6_loss: 0.3612 - o7_loss: 0.5083 - o8_loss: 0.6052 - o1_acc: 0.9833 - o2_acc: 0.9762 - o3_acc: 0.9726 - o4_acc: 0.9570 - o5_acc: 0.9201 - o6_acc: 0.8648 - o7_acc: 0.7764 - o8_acc: 0.7125 - val_loss: 2.2953 - val_o1_loss: 0.0701 - val_o2_loss: 0.0934 - val_o3_loss: 0.1402 - val_o4_loss: 0.2166 - val_o5_loss: 0.3256 - val_o6_loss: 0.3815 - val_o7_loss: 0.4800 - val_o8_loss: 0.5880 - val_o1_acc: 0.9860 - val_o2_acc: 0.9790 - val_o3_acc: 0.9590 - val_o4_acc: 0.9260 - val_o5_acc: 0.8740 - val_o6_acc: 0.8560 - val_o7_acc: 0.8100 - val_o8_acc: 0.7250\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.1174 - o1_loss: 0.0731 - o2_loss: 0.1020 - o3_loss: 0.1146 - o4_loss: 0.1592 - o5_loss: 0.2324 - o6_loss: 0.3432 - o7_loss: 0.4976 - o8_loss: 0.5953 - o1_acc: 0.9822 - o2_acc: 0.9757 - o3_acc: 0.9702 - o4_acc: 0.9576 - o5_acc: 0.9235 - o6_acc: 0.8715 - o7_acc: 0.7734 - o8_acc: 0.7161 - val_loss: 2.0067 - val_o1_loss: 0.0727 - val_o2_loss: 0.0890 - val_o3_loss: 0.1105 - val_o4_loss: 0.1491 - val_o5_loss: 0.2432 - val_o6_loss: 0.3218 - val_o7_loss: 0.4519 - val_o8_loss: 0.5685 - val_o1_acc: 0.9810 - val_o2_acc: 0.9780 - val_o3_acc: 0.9760 - val_o4_acc: 0.9640 - val_o5_acc: 0.9210 - val_o6_acc: 0.8820 - val_o7_acc: 0.8090 - val_o8_acc: 0.7330\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 2.0491 - o1_loss: 0.0701 - o2_loss: 0.0961 - o3_loss: 0.1064 - o4_loss: 0.1477 - o5_loss: 0.2199 - o6_loss: 0.3293 - o7_loss: 0.4851 - o8_loss: 0.5945 - o1_acc: 0.9839 - o2_acc: 0.9780 - o3_acc: 0.9751 - o4_acc: 0.9609 - o5_acc: 0.9281 - o6_acc: 0.8777 - o7_acc: 0.7868 - o8_acc: 0.7186 - val_loss: 1.9711 - val_o1_loss: 0.0559 - val_o2_loss: 0.0845 - val_o3_loss: 0.1049 - val_o4_loss: 0.1418 - val_o5_loss: 0.2258 - val_o6_loss: 0.3201 - val_o7_loss: 0.4551 - val_o8_loss: 0.5830 - val_o1_acc: 0.9890 - val_o2_acc: 0.9800 - val_o3_acc: 0.9780 - val_o4_acc: 0.9720 - val_o5_acc: 0.9260 - val_o6_acc: 0.8700 - val_o7_acc: 0.8010 - val_o8_acc: 0.7070\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.9282 - o1_loss: 0.0691 - o2_loss: 0.0927 - o3_loss: 0.1037 - o4_loss: 0.1414 - o5_loss: 0.2059 - o6_loss: 0.3103 - o7_loss: 0.4539 - o8_loss: 0.5510 - o1_acc: 0.9826 - o2_acc: 0.9787 - o3_acc: 0.9755 - o4_acc: 0.9632 - o5_acc: 0.9360 - o6_acc: 0.8828 - o7_acc: 0.7972 - o8_acc: 0.7329 - val_loss: 1.8913 - val_o1_loss: 0.0552 - val_o2_loss: 0.0836 - val_o3_loss: 0.1021 - val_o4_loss: 0.1344 - val_o5_loss: 0.2263 - val_o6_loss: 0.2987 - val_o7_loss: 0.4112 - val_o8_loss: 0.5797 - val_o1_acc: 0.9880 - val_o2_acc: 0.9800 - val_o3_acc: 0.9760 - val_o4_acc: 0.9660 - val_o5_acc: 0.9260 - val_o6_acc: 0.8720 - val_o7_acc: 0.8220 - val_o8_acc: 0.7320\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.8940 - o1_loss: 0.0661 - o2_loss: 0.0890 - o3_loss: 0.0992 - o4_loss: 0.1365 - o5_loss: 0.1985 - o6_loss: 0.2964 - o7_loss: 0.4499 - o8_loss: 0.5583 - o1_acc: 0.9838 - o2_acc: 0.9803 - o3_acc: 0.9762 - o4_acc: 0.9648 - o5_acc: 0.9367 - o6_acc: 0.8986 - o7_acc: 0.8072 - o8_acc: 0.7420 - val_loss: 1.8045 - val_o1_loss: 0.0520 - val_o2_loss: 0.0760 - val_o3_loss: 0.0949 - val_o4_loss: 0.1243 - val_o5_loss: 0.1956 - val_o6_loss: 0.2769 - val_o7_loss: 0.4145 - val_o8_loss: 0.5703 - val_o1_acc: 0.9900 - val_o2_acc: 0.9820 - val_o3_acc: 0.9830 - val_o4_acc: 0.9700 - val_o5_acc: 0.9410 - val_o6_acc: 0.9020 - val_o7_acc: 0.8190 - val_o8_acc: 0.7150\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.7791 - o1_loss: 0.0621 - o2_loss: 0.0825 - o3_loss: 0.0918 - o4_loss: 0.1259 - o5_loss: 0.1827 - o6_loss: 0.2778 - o7_loss: 0.4273 - o8_loss: 0.5292 - o1_acc: 0.9859 - o2_acc: 0.9826 - o3_acc: 0.9793 - o4_acc: 0.9696 - o5_acc: 0.9436 - o6_acc: 0.9039 - o7_acc: 0.8089 - o8_acc: 0.7496 - val_loss: 1.7548 - val_o1_loss: 0.0833 - val_o2_loss: 0.0811 - val_o3_loss: 0.0923 - val_o4_loss: 0.1213 - val_o5_loss: 0.1997 - val_o6_loss: 0.2631 - val_o7_loss: 0.3808 - val_o8_loss: 0.5331 - val_o1_acc: 0.9750 - val_o2_acc: 0.9830 - val_o3_acc: 0.9820 - val_o4_acc: 0.9690 - val_o5_acc: 0.9390 - val_o6_acc: 0.9000 - val_o7_acc: 0.8480 - val_o8_acc: 0.7400\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 3.1775 - o1_loss: 0.2955 - o2_loss: 0.3262 - o3_loss: 0.3063 - o4_loss: 0.2995 - o5_loss: 0.3387 - o6_loss: 0.4220 - o7_loss: 0.5487 - o8_loss: 0.6405 - o1_acc: 0.9456 - o2_acc: 0.9343 - o3_acc: 0.9395 - o4_acc: 0.9315 - o5_acc: 0.9101 - o6_acc: 0.8598 - o7_acc: 0.7768 - o8_acc: 0.7091 - val_loss: 2.3213 - val_o1_loss: 0.0855 - val_o2_loss: 0.1503 - val_o3_loss: 0.1541 - val_o4_loss: 0.1942 - val_o5_loss: 0.2887 - val_o6_loss: 0.3914 - val_o7_loss: 0.4607 - val_o8_loss: 0.5963 - val_o1_acc: 0.9790 - val_o2_acc: 0.9500 - val_o3_acc: 0.9560 - val_o4_acc: 0.9410 - val_o5_acc: 0.8980 - val_o6_acc: 0.8520 - val_o7_acc: 0.8130 - val_o8_acc: 0.7130\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.7960 - o1_loss: 0.0763 - o2_loss: 0.0998 - o3_loss: 0.1084 - o4_loss: 0.1416 - o5_loss: 0.1958 - o6_loss: 0.2765 - o7_loss: 0.4003 - o8_loss: 0.4973 - o1_acc: 0.9816 - o2_acc: 0.9764 - o3_acc: 0.9732 - o4_acc: 0.9639 - o5_acc: 0.9420 - o6_acc: 0.9077 - o7_acc: 0.8286 - o8_acc: 0.7641 - val_loss: 1.6786 - val_o1_loss: 0.0538 - val_o2_loss: 0.0751 - val_o3_loss: 0.0934 - val_o4_loss: 0.1220 - val_o5_loss: 0.1842 - val_o6_loss: 0.2498 - val_o7_loss: 0.3681 - val_o8_loss: 0.5323 - val_o1_acc: 0.9890 - val_o2_acc: 0.9840 - val_o3_acc: 0.9820 - val_o4_acc: 0.9720 - val_o5_acc: 0.9480 - val_o6_acc: 0.9120 - val_o7_acc: 0.8470 - val_o8_acc: 0.7310\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.6392 - o1_loss: 0.0595 - o2_loss: 0.0778 - o3_loss: 0.0862 - o4_loss: 0.1117 - o5_loss: 0.1616 - o6_loss: 0.2445 - o7_loss: 0.3892 - o8_loss: 0.5087 - o1_acc: 0.9870 - o2_acc: 0.9845 - o3_acc: 0.9811 - o4_acc: 0.9749 - o5_acc: 0.9551 - o6_acc: 0.9190 - o7_acc: 0.8306 - o8_acc: 0.7576 - val_loss: 1.6019 - val_o1_loss: 0.0475 - val_o2_loss: 0.0697 - val_o3_loss: 0.0908 - val_o4_loss: 0.1122 - val_o5_loss: 0.1761 - val_o6_loss: 0.2304 - val_o7_loss: 0.3504 - val_o8_loss: 0.5248 - val_o1_acc: 0.9910 - val_o2_acc: 0.9850 - val_o3_acc: 0.9780 - val_o4_acc: 0.9800 - val_o5_acc: 0.9490 - val_o6_acc: 0.9220 - val_o7_acc: 0.8500 - val_o8_acc: 0.7490\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.5880 - o1_loss: 0.0565 - o2_loss: 0.0740 - o3_loss: 0.0812 - o4_loss: 0.1069 - o5_loss: 0.1563 - o6_loss: 0.2363 - o7_loss: 0.3815 - o8_loss: 0.4952 - o1_acc: 0.9883 - o2_acc: 0.9851 - o3_acc: 0.9826 - o4_acc: 0.9748 - o5_acc: 0.9571 - o6_acc: 0.9212 - o7_acc: 0.8306 - o8_acc: 0.7654 - val_loss: 1.5865 - val_o1_loss: 0.0442 - val_o2_loss: 0.0676 - val_o3_loss: 0.0826 - val_o4_loss: 0.1077 - val_o5_loss: 0.1722 - val_o6_loss: 0.2233 - val_o7_loss: 0.3513 - val_o8_loss: 0.5376 - val_o1_acc: 0.9920 - val_o2_acc: 0.9860 - val_o3_acc: 0.9840 - val_o4_acc: 0.9740 - val_o5_acc: 0.9460 - val_o6_acc: 0.9230 - val_o7_acc: 0.8470 - val_o8_acc: 0.7330\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.4554 - o1_loss: 0.0537 - o2_loss: 0.0691 - o3_loss: 0.0785 - o4_loss: 0.1021 - o5_loss: 0.1456 - o6_loss: 0.2121 - o7_loss: 0.3381 - o8_loss: 0.4561 - o1_acc: 0.9874 - o2_acc: 0.9868 - o3_acc: 0.9837 - o4_acc: 0.9765 - o5_acc: 0.9594 - o6_acc: 0.9316 - o7_acc: 0.8513 - o8_acc: 0.7812 - val_loss: 1.5758 - val_o1_loss: 0.0547 - val_o2_loss: 0.0695 - val_o3_loss: 0.0867 - val_o4_loss: 0.1155 - val_o5_loss: 0.1737 - val_o6_loss: 0.2269 - val_o7_loss: 0.3408 - val_o8_loss: 0.5080 - val_o1_acc: 0.9900 - val_o2_acc: 0.9810 - val_o3_acc: 0.9810 - val_o4_acc: 0.9690 - val_o5_acc: 0.9500 - val_o6_acc: 0.9220 - val_o7_acc: 0.8630 - val_o8_acc: 0.7460\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.5395 - o1_loss: 0.0530 - o2_loss: 0.0682 - o3_loss: 0.0764 - o4_loss: 0.1000 - o5_loss: 0.1439 - o6_loss: 0.2243 - o7_loss: 0.3643 - o8_loss: 0.5094 - o1_acc: 0.9881 - o2_acc: 0.9858 - o3_acc: 0.9832 - o4_acc: 0.9757 - o5_acc: 0.9589 - o6_acc: 0.9268 - o7_acc: 0.8445 - o8_acc: 0.7702 - val_loss: 1.4880 - val_o1_loss: 0.0449 - val_o2_loss: 0.0604 - val_o3_loss: 0.0755 - val_o4_loss: 0.1006 - val_o5_loss: 0.1543 - val_o6_loss: 0.2246 - val_o7_loss: 0.3302 - val_o8_loss: 0.4974 - val_o1_acc: 0.9910 - val_o2_acc: 0.9850 - val_o3_acc: 0.9840 - val_o4_acc: 0.9800 - val_o5_acc: 0.9620 - val_o6_acc: 0.9160 - val_o7_acc: 0.8640 - val_o8_acc: 0.7700\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.4430 - o1_loss: 0.0492 - o2_loss: 0.0638 - o3_loss: 0.0721 - o4_loss: 0.0934 - o5_loss: 0.1341 - o6_loss: 0.2097 - o7_loss: 0.3467 - o8_loss: 0.4740 - o1_acc: 0.9889 - o2_acc: 0.9878 - o3_acc: 0.9849 - o4_acc: 0.9785 - o5_acc: 0.9626 - o6_acc: 0.9304 - o7_acc: 0.8513 - o8_acc: 0.7778 - val_loss: 1.3986 - val_o1_loss: 0.0459 - val_o2_loss: 0.0618 - val_o3_loss: 0.0804 - val_o4_loss: 0.0947 - val_o5_loss: 0.1457 - val_o6_loss: 0.1872 - val_o7_loss: 0.2997 - val_o8_loss: 0.4832 - val_o1_acc: 0.9930 - val_o2_acc: 0.9890 - val_o3_acc: 0.9810 - val_o4_acc: 0.9820 - val_o5_acc: 0.9610 - val_o6_acc: 0.9310 - val_o7_acc: 0.8690 - val_o8_acc: 0.7580\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.3304 - o1_loss: 0.0484 - o2_loss: 0.0610 - o3_loss: 0.0694 - o4_loss: 0.0894 - o5_loss: 0.1254 - o6_loss: 0.1884 - o7_loss: 0.3140 - o8_loss: 0.4343 - o1_acc: 0.9898 - o2_acc: 0.9892 - o3_acc: 0.9865 - o4_acc: 0.9803 - o5_acc: 0.9636 - o6_acc: 0.9383 - o7_acc: 0.8627 - o8_acc: 0.7936 - val_loss: 1.3594 - val_o1_loss: 0.0369 - val_o2_loss: 0.0523 - val_o3_loss: 0.0740 - val_o4_loss: 0.0927 - val_o5_loss: 0.1454 - val_o6_loss: 0.1933 - val_o7_loss: 0.2979 - val_o8_loss: 0.4671 - val_o1_acc: 0.9940 - val_o2_acc: 0.9920 - val_o3_acc: 0.9850 - val_o4_acc: 0.9870 - val_o5_acc: 0.9580 - val_o6_acc: 0.9360 - val_o7_acc: 0.8820 - val_o8_acc: 0.7790\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.4451 - o1_loss: 0.0471 - o2_loss: 0.0605 - o3_loss: 0.0698 - o4_loss: 0.0904 - o5_loss: 0.1269 - o6_loss: 0.2062 - o7_loss: 0.3604 - o8_loss: 0.4838 - o1_acc: 0.9892 - o2_acc: 0.9886 - o3_acc: 0.9850 - o4_acc: 0.9790 - o5_acc: 0.9640 - o6_acc: 0.9339 - o7_acc: 0.8520 - o8_acc: 0.7821 - val_loss: 1.4152 - val_o1_loss: 0.0445 - val_o2_loss: 0.0573 - val_o3_loss: 0.0740 - val_o4_loss: 0.0908 - val_o5_loss: 0.1357 - val_o6_loss: 0.2022 - val_o7_loss: 0.3312 - val_o8_loss: 0.4797 - val_o1_acc: 0.9900 - val_o2_acc: 0.9890 - val_o3_acc: 0.9840 - val_o4_acc: 0.9850 - val_o5_acc: 0.9590 - val_o6_acc: 0.9360 - val_o7_acc: 0.8690 - val_o8_acc: 0.7760\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 1.2735 - o1_loss: 0.0447 - o2_loss: 0.0560 - o3_loss: 0.0666 - o4_loss: 0.0816 - o5_loss: 0.1150 - o6_loss: 0.1780 - o7_loss: 0.3030 - o8_loss: 0.4286 - o1_acc: 0.9898 - o2_acc: 0.9901 - o3_acc: 0.9868 - o4_acc: 0.9806 - o5_acc: 0.9686 - o6_acc: 0.9387 - o7_acc: 0.8698 - o8_acc: 0.7975 - val_loss: 1.2626 - val_o1_loss: 0.0453 - val_o2_loss: 0.0525 - val_o3_loss: 0.0666 - val_o4_loss: 0.0817 - val_o5_loss: 0.1258 - val_o6_loss: 0.1659 - val_o7_loss: 0.2724 - val_o8_loss: 0.4523 - val_o1_acc: 0.9920 - val_o2_acc: 0.9910 - val_o3_acc: 0.9870 - val_o4_acc: 0.9860 - val_o5_acc: 0.9650 - val_o6_acc: 0.9450 - val_o7_acc: 0.8860 - val_o8_acc: 0.7760\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.3575 - o1_loss: 0.0441 - o2_loss: 0.0560 - o3_loss: 0.0648 - o4_loss: 0.0819 - o5_loss: 0.1194 - o6_loss: 0.1919 - o7_loss: 0.3286 - o8_loss: 0.4708 - o1_acc: 0.9900 - o2_acc: 0.9911 - o3_acc: 0.9866 - o4_acc: 0.9814 - o5_acc: 0.9654 - o6_acc: 0.9392 - o7_acc: 0.8660 - o8_acc: 0.7925 - val_loss: 1.4015 - val_o1_loss: 0.0383 - val_o2_loss: 0.0574 - val_o3_loss: 0.0720 - val_o4_loss: 0.0843 - val_o5_loss: 0.1425 - val_o6_loss: 0.1822 - val_o7_loss: 0.3078 - val_o8_loss: 0.5170 - val_o1_acc: 0.9920 - val_o2_acc: 0.9910 - val_o3_acc: 0.9820 - val_o4_acc: 0.9820 - val_o5_acc: 0.9560 - val_o6_acc: 0.9300 - val_o7_acc: 0.8680 - val_o8_acc: 0.7230\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.1604 - o1_loss: 0.0403 - o2_loss: 0.0517 - o3_loss: 0.0611 - o4_loss: 0.0764 - o5_loss: 0.1057 - o6_loss: 0.1592 - o7_loss: 0.2735 - o8_loss: 0.3925 - o1_acc: 0.9908 - o2_acc: 0.9913 - o3_acc: 0.9874 - o4_acc: 0.9830 - o5_acc: 0.9724 - o6_acc: 0.9482 - o7_acc: 0.8830 - o8_acc: 0.8193 - val_loss: 1.3993 - val_o1_loss: 0.0376 - val_o2_loss: 0.0660 - val_o3_loss: 0.0875 - val_o4_loss: 0.1167 - val_o5_loss: 0.1509 - val_o6_loss: 0.1960 - val_o7_loss: 0.2915 - val_o8_loss: 0.4530 - val_o1_acc: 0.9920 - val_o2_acc: 0.9830 - val_o3_acc: 0.9740 - val_o4_acc: 0.9720 - val_o5_acc: 0.9530 - val_o6_acc: 0.9280 - val_o7_acc: 0.8980 - val_o8_acc: 0.7850\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.2453 - o1_loss: 0.0389 - o2_loss: 0.0496 - o3_loss: 0.0583 - o4_loss: 0.0738 - o5_loss: 0.1098 - o6_loss: 0.1714 - o7_loss: 0.3130 - o8_loss: 0.4305 - o1_acc: 0.9911 - o2_acc: 0.9919 - o3_acc: 0.9887 - o4_acc: 0.9827 - o5_acc: 0.9709 - o6_acc: 0.9421 - o7_acc: 0.8680 - o8_acc: 0.8056 - val_loss: 1.2054 - val_o1_loss: 0.0505 - val_o2_loss: 0.0507 - val_o3_loss: 0.0624 - val_o4_loss: 0.0789 - val_o5_loss: 0.1131 - val_o6_loss: 0.1628 - val_o7_loss: 0.2521 - val_o8_loss: 0.4351 - val_o1_acc: 0.9900 - val_o2_acc: 0.9900 - val_o3_acc: 0.9870 - val_o4_acc: 0.9850 - val_o5_acc: 0.9690 - val_o6_acc: 0.9400 - val_o7_acc: 0.9080 - val_o8_acc: 0.8110\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 1.0920 - o1_loss: 0.0400 - o2_loss: 0.0492 - o3_loss: 0.0571 - o4_loss: 0.0707 - o5_loss: 0.0993 - o6_loss: 0.1484 - o7_loss: 0.2581 - o8_loss: 0.3692 - o1_acc: 0.9908 - o2_acc: 0.9919 - o3_acc: 0.9883 - o4_acc: 0.9840 - o5_acc: 0.9728 - o6_acc: 0.9531 - o7_acc: 0.8930 - o8_acc: 0.8357 - val_loss: 1.1948 - val_o1_loss: 0.0625 - val_o2_loss: 0.0570 - val_o3_loss: 0.0582 - val_o4_loss: 0.0754 - val_o5_loss: 0.1163 - val_o6_loss: 0.1623 - val_o7_loss: 0.2529 - val_o8_loss: 0.4102 - val_o1_acc: 0.9830 - val_o2_acc: 0.9840 - val_o3_acc: 0.9890 - val_o4_acc: 0.9850 - val_o5_acc: 0.9630 - val_o6_acc: 0.9440 - val_o7_acc: 0.9110 - val_o8_acc: 0.8120\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.0542 - o1_loss: 0.0363 - o2_loss: 0.0458 - o3_loss: 0.0533 - o4_loss: 0.0681 - o5_loss: 0.0939 - o6_loss: 0.1438 - o7_loss: 0.2524 - o8_loss: 0.3607 - o1_acc: 0.9921 - o2_acc: 0.9929 - o3_acc: 0.9901 - o4_acc: 0.9852 - o5_acc: 0.9747 - o6_acc: 0.9527 - o7_acc: 0.8956 - o8_acc: 0.8399 - val_loss: 1.0679 - val_o1_loss: 0.0395 - val_o2_loss: 0.0449 - val_o3_loss: 0.0562 - val_o4_loss: 0.0644 - val_o5_loss: 0.0988 - val_o6_loss: 0.1338 - val_o7_loss: 0.2293 - val_o8_loss: 0.4009 - val_o1_acc: 0.9940 - val_o2_acc: 0.9910 - val_o3_acc: 0.9880 - val_o4_acc: 0.9870 - val_o5_acc: 0.9700 - val_o6_acc: 0.9570 - val_o7_acc: 0.9090 - val_o8_acc: 0.8060\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.1732 - o1_loss: 0.0387 - o2_loss: 0.0472 - o3_loss: 0.0552 - o4_loss: 0.0683 - o5_loss: 0.1005 - o6_loss: 0.1676 - o7_loss: 0.2979 - o8_loss: 0.3978 - o1_acc: 0.9914 - o2_acc: 0.9923 - o3_acc: 0.9891 - o4_acc: 0.9842 - o5_acc: 0.9710 - o6_acc: 0.9466 - o7_acc: 0.8893 - o8_acc: 0.8327 - val_loss: 1.0388 - val_o1_loss: 0.0418 - val_o2_loss: 0.0456 - val_o3_loss: 0.0563 - val_o4_loss: 0.0740 - val_o5_loss: 0.1056 - val_o6_loss: 0.1284 - val_o7_loss: 0.2215 - val_o8_loss: 0.3656 - val_o1_acc: 0.9930 - val_o2_acc: 0.9910 - val_o3_acc: 0.9890 - val_o4_acc: 0.9860 - val_o5_acc: 0.9700 - val_o6_acc: 0.9650 - val_o7_acc: 0.9290 - val_o8_acc: 0.8370\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.9549 - o1_loss: 0.0346 - o2_loss: 0.0431 - o3_loss: 0.0510 - o4_loss: 0.0630 - o5_loss: 0.0858 - o6_loss: 0.1304 - o7_loss: 0.2265 - o8_loss: 0.3204 - o1_acc: 0.9926 - o2_acc: 0.9925 - o3_acc: 0.9897 - o4_acc: 0.9862 - o5_acc: 0.9785 - o6_acc: 0.9582 - o7_acc: 0.9115 - o8_acc: 0.8673 - val_loss: 1.0845 - val_o1_loss: 0.0407 - val_o2_loss: 0.0454 - val_o3_loss: 0.0521 - val_o4_loss: 0.0757 - val_o5_loss: 0.1013 - val_o6_loss: 0.1524 - val_o7_loss: 0.2517 - val_o8_loss: 0.3652 - val_o1_acc: 0.9930 - val_o2_acc: 0.9880 - val_o3_acc: 0.9920 - val_o4_acc: 0.9820 - val_o5_acc: 0.9710 - val_o6_acc: 0.9540 - val_o7_acc: 0.9160 - val_o8_acc: 0.8560\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.0823 - o1_loss: 0.0371 - o2_loss: 0.0437 - o3_loss: 0.0509 - o4_loss: 0.0626 - o5_loss: 0.0916 - o6_loss: 0.1515 - o7_loss: 0.2739 - o8_loss: 0.3710 - o1_acc: 0.9915 - o2_acc: 0.9926 - o3_acc: 0.9895 - o4_acc: 0.9850 - o5_acc: 0.9742 - o6_acc: 0.9523 - o7_acc: 0.9006 - o8_acc: 0.8535 - val_loss: 0.9455 - val_o1_loss: 0.0437 - val_o2_loss: 0.0429 - val_o3_loss: 0.0528 - val_o4_loss: 0.0676 - val_o5_loss: 0.0972 - val_o6_loss: 0.1224 - val_o7_loss: 0.1931 - val_o8_loss: 0.3259 - val_o1_acc: 0.9940 - val_o2_acc: 0.9920 - val_o3_acc: 0.9900 - val_o4_acc: 0.9870 - val_o5_acc: 0.9730 - val_o6_acc: 0.9650 - val_o7_acc: 0.9420 - val_o8_acc: 0.8580\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8759 - o1_loss: 0.0334 - o2_loss: 0.0412 - o3_loss: 0.0485 - o4_loss: 0.0604 - o5_loss: 0.0813 - o6_loss: 0.1222 - o7_loss: 0.2043 - o8_loss: 0.2846 - o1_acc: 0.9922 - o2_acc: 0.9927 - o3_acc: 0.9897 - o4_acc: 0.9847 - o5_acc: 0.9794 - o6_acc: 0.9610 - o7_acc: 0.9279 - o8_acc: 0.8934 - val_loss: 0.8896 - val_o1_loss: 0.0360 - val_o2_loss: 0.0454 - val_o3_loss: 0.0503 - val_o4_loss: 0.0725 - val_o5_loss: 0.0887 - val_o6_loss: 0.1159 - val_o7_loss: 0.1842 - val_o8_loss: 0.2966 - val_o1_acc: 0.9950 - val_o2_acc: 0.9900 - val_o3_acc: 0.9930 - val_o4_acc: 0.9810 - val_o5_acc: 0.9780 - val_o6_acc: 0.9680 - val_o7_acc: 0.9500 - val_o8_acc: 0.8660\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 2.9850 - o1_loss: 0.3315 - o2_loss: 0.3183 - o3_loss: 0.3201 - o4_loss: 0.3819 - o5_loss: 0.3826 - o6_loss: 0.4033 - o7_loss: 0.4228 - o8_loss: 0.4246 - o1_acc: 0.9394 - o2_acc: 0.9404 - o3_acc: 0.9429 - o4_acc: 0.9322 - o5_acc: 0.9239 - o6_acc: 0.9078 - o7_acc: 0.8754 - o8_acc: 0.8469 - val_loss: 1.2389 - val_o1_loss: 0.0643 - val_o2_loss: 0.0734 - val_o3_loss: 0.0808 - val_o4_loss: 0.0995 - val_o5_loss: 0.1569 - val_o6_loss: 0.1900 - val_o7_loss: 0.2255 - val_o8_loss: 0.3485 - val_o1_acc: 0.9870 - val_o2_acc: 0.9830 - val_o3_acc: 0.9760 - val_o4_acc: 0.9680 - val_o5_acc: 0.9540 - val_o6_acc: 0.9300 - val_o7_acc: 0.9210 - val_o8_acc: 0.8540\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.9454 - o1_loss: 0.0498 - o2_loss: 0.0513 - o3_loss: 0.0586 - o4_loss: 0.0720 - o5_loss: 0.1043 - o6_loss: 0.1442 - o7_loss: 0.2024 - o8_loss: 0.2627 - o1_acc: 0.9874 - o2_acc: 0.9905 - o3_acc: 0.9875 - o4_acc: 0.9822 - o5_acc: 0.9712 - o6_acc: 0.9529 - o7_acc: 0.9357 - o8_acc: 0.9103 - val_loss: 0.9230 - val_o1_loss: 0.0415 - val_o2_loss: 0.0426 - val_o3_loss: 0.0505 - val_o4_loss: 0.0731 - val_o5_loss: 0.0985 - val_o6_loss: 0.1284 - val_o7_loss: 0.1942 - val_o8_loss: 0.2941 - val_o1_acc: 0.9930 - val_o2_acc: 0.9910 - val_o3_acc: 0.9930 - val_o4_acc: 0.9820 - val_o5_acc: 0.9750 - val_o6_acc: 0.9650 - val_o7_acc: 0.9360 - val_o8_acc: 0.8700\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8073 - o1_loss: 0.0361 - o2_loss: 0.0391 - o3_loss: 0.0474 - o4_loss: 0.0582 - o5_loss: 0.0844 - o6_loss: 0.1222 - o7_loss: 0.1853 - o8_loss: 0.2345 - o1_acc: 0.9927 - o2_acc: 0.9943 - o3_acc: 0.9915 - o4_acc: 0.9874 - o5_acc: 0.9790 - o6_acc: 0.9618 - o7_acc: 0.9408 - o8_acc: 0.9197 - val_loss: 1.9077 - val_o1_loss: 0.0449 - val_o2_loss: 0.0398 - val_o3_loss: 0.0465 - val_o4_loss: 0.0636 - val_o5_loss: 0.1257 - val_o6_loss: 0.2215 - val_o7_loss: 0.4758 - val_o8_loss: 0.8900 - val_o1_acc: 0.9920 - val_o2_acc: 0.9940 - val_o3_acc: 0.9920 - val_o4_acc: 0.9860 - val_o5_acc: 0.9620 - val_o6_acc: 0.9310 - val_o7_acc: 0.8150 - val_o8_acc: 0.5950\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8300 - o1_loss: 0.0333 - o2_loss: 0.0377 - o3_loss: 0.0451 - o4_loss: 0.0558 - o5_loss: 0.0818 - o6_loss: 0.1227 - o7_loss: 0.2017 - o8_loss: 0.2519 - o1_acc: 0.9927 - o2_acc: 0.9940 - o3_acc: 0.9913 - o4_acc: 0.9876 - o5_acc: 0.9799 - o6_acc: 0.9621 - o7_acc: 0.9358 - o8_acc: 0.9137 - val_loss: 0.8719 - val_o1_loss: 0.0374 - val_o2_loss: 0.0352 - val_o3_loss: 0.0434 - val_o4_loss: 0.0649 - val_o5_loss: 0.0816 - val_o6_loss: 0.1148 - val_o7_loss: 0.2015 - val_o8_loss: 0.2931 - val_o1_acc: 0.9940 - val_o2_acc: 0.9960 - val_o3_acc: 0.9950 - val_o4_acc: 0.9860 - val_o5_acc: 0.9800 - val_o6_acc: 0.9680 - val_o7_acc: 0.9160 - val_o8_acc: 0.8490\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.7913 - o1_loss: 0.0303 - o2_loss: 0.0349 - o3_loss: 0.0428 - o4_loss: 0.0541 - o5_loss: 0.0751 - o6_loss: 0.1206 - o7_loss: 0.1972 - o8_loss: 0.2363 - o1_acc: 0.9926 - o2_acc: 0.9951 - o3_acc: 0.9916 - o4_acc: 0.9870 - o5_acc: 0.9814 - o6_acc: 0.9635 - o7_acc: 0.9360 - o8_acc: 0.9155 - val_loss: 0.7408 - val_o1_loss: 0.0360 - val_o2_loss: 0.0370 - val_o3_loss: 0.0420 - val_o4_loss: 0.0616 - val_o5_loss: 0.0832 - val_o6_loss: 0.1039 - val_o7_loss: 0.1503 - val_o8_loss: 0.2269 - val_o1_acc: 0.9920 - val_o2_acc: 0.9950 - val_o3_acc: 0.9920 - val_o4_acc: 0.9850 - val_o5_acc: 0.9760 - val_o6_acc: 0.9700 - val_o7_acc: 0.9550 - val_o8_acc: 0.9210\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.6747 - o1_loss: 0.0289 - o2_loss: 0.0349 - o3_loss: 0.0424 - o4_loss: 0.0513 - o5_loss: 0.0745 - o6_loss: 0.1028 - o7_loss: 0.1559 - o8_loss: 0.1840 - o1_acc: 0.9936 - o2_acc: 0.9949 - o3_acc: 0.9914 - o4_acc: 0.9883 - o5_acc: 0.9822 - o6_acc: 0.9698 - o7_acc: 0.9560 - o8_acc: 0.9505 - val_loss: 1.3276 - val_o1_loss: 0.0323 - val_o2_loss: 0.0351 - val_o3_loss: 0.0445 - val_o4_loss: 0.0747 - val_o5_loss: 0.0894 - val_o6_loss: 0.1853 - val_o7_loss: 0.3752 - val_o8_loss: 0.4912 - val_o1_acc: 0.9930 - val_o2_acc: 0.9960 - val_o3_acc: 0.9920 - val_o4_acc: 0.9810 - val_o5_acc: 0.9730 - val_o6_acc: 0.9310 - val_o7_acc: 0.8230 - val_o8_acc: 0.7380\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.7374 - o1_loss: 0.0281 - o2_loss: 0.0340 - o3_loss: 0.0417 - o4_loss: 0.0510 - o5_loss: 0.0765 - o6_loss: 0.1085 - o7_loss: 0.1803 - o8_loss: 0.2174 - o1_acc: 0.9943 - o2_acc: 0.9950 - o3_acc: 0.9907 - o4_acc: 0.9879 - o5_acc: 0.9794 - o6_acc: 0.9678 - o7_acc: 0.9452 - o8_acc: 0.9354 - val_loss: 0.6322 - val_o1_loss: 0.0316 - val_o2_loss: 0.0314 - val_o3_loss: 0.0399 - val_o4_loss: 0.0579 - val_o5_loss: 0.0745 - val_o6_loss: 0.0959 - val_o7_loss: 0.1347 - val_o8_loss: 0.1664 - val_o1_acc: 0.9940 - val_o2_acc: 0.9970 - val_o3_acc: 0.9940 - val_o4_acc: 0.9850 - val_o5_acc: 0.9790 - val_o6_acc: 0.9720 - val_o7_acc: 0.9610 - val_o8_acc: 0.9400\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.6619 - o1_loss: 0.0260 - o2_loss: 0.0318 - o3_loss: 0.0387 - o4_loss: 0.0492 - o5_loss: 0.0711 - o6_loss: 0.1005 - o7_loss: 0.1659 - o8_loss: 0.1786 - o1_acc: 0.9945 - o2_acc: 0.9955 - o3_acc: 0.9927 - o4_acc: 0.9876 - o5_acc: 0.9807 - o6_acc: 0.9697 - o7_acc: 0.9474 - o8_acc: 0.9411 - val_loss: 0.6051 - val_o1_loss: 0.0337 - val_o2_loss: 0.0309 - val_o3_loss: 0.0368 - val_o4_loss: 0.0574 - val_o5_loss: 0.0737 - val_o6_loss: 0.0932 - val_o7_loss: 0.1269 - val_o8_loss: 0.1526 - val_o1_acc: 0.9940 - val_o2_acc: 0.9960 - val_o3_acc: 0.9950 - val_o4_acc: 0.9870 - val_o5_acc: 0.9780 - val_o6_acc: 0.9740 - val_o7_acc: 0.9590 - val_o8_acc: 0.9480\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.6088 - o1_loss: 0.0251 - o2_loss: 0.0306 - o3_loss: 0.0373 - o4_loss: 0.0468 - o5_loss: 0.0682 - o6_loss: 0.0964 - o7_loss: 0.1475 - o8_loss: 0.1570 - o1_acc: 0.9950 - o2_acc: 0.9959 - o3_acc: 0.9927 - o4_acc: 0.9898 - o5_acc: 0.9838 - o6_acc: 0.9719 - o7_acc: 0.9545 - o8_acc: 0.9505 - val_loss: 0.8194 - val_o1_loss: 0.0311 - val_o2_loss: 0.0310 - val_o3_loss: 0.0373 - val_o4_loss: 0.0630 - val_o5_loss: 0.0732 - val_o6_loss: 0.1343 - val_o7_loss: 0.2205 - val_o8_loss: 0.2289 - val_o1_acc: 0.9930 - val_o2_acc: 0.9950 - val_o3_acc: 0.9950 - val_o4_acc: 0.9850 - val_o5_acc: 0.9840 - val_o6_acc: 0.9570 - val_o7_acc: 0.9050 - val_o8_acc: 0.8960\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.5960 - o1_loss: 0.0241 - o2_loss: 0.0301 - o3_loss: 0.0373 - o4_loss: 0.0465 - o5_loss: 0.0682 - o6_loss: 0.0939 - o7_loss: 0.1413 - o8_loss: 0.1546 - o1_acc: 0.9952 - o2_acc: 0.9959 - o3_acc: 0.9920 - o4_acc: 0.9885 - o5_acc: 0.9822 - o6_acc: 0.9728 - o7_acc: 0.9606 - o8_acc: 0.9530 - val_loss: 0.7106 - val_o1_loss: 0.0282 - val_o2_loss: 0.0299 - val_o3_loss: 0.0355 - val_o4_loss: 0.0570 - val_o5_loss: 0.0666 - val_o6_loss: 0.1074 - val_o7_loss: 0.1777 - val_o8_loss: 0.2084 - val_o1_acc: 0.9940 - val_o2_acc: 0.9950 - val_o3_acc: 0.9950 - val_o4_acc: 0.9870 - val_o5_acc: 0.9860 - val_o6_acc: 0.9650 - val_o7_acc: 0.9200 - val_o8_acc: 0.9030\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.5937 - o1_loss: 0.0234 - o2_loss: 0.0297 - o3_loss: 0.0360 - o4_loss: 0.0445 - o5_loss: 0.0649 - o6_loss: 0.0910 - o7_loss: 0.1465 - o8_loss: 0.1578 - o1_acc: 0.9960 - o2_acc: 0.9956 - o3_acc: 0.9924 - o4_acc: 0.9897 - o5_acc: 0.9844 - o6_acc: 0.9721 - o7_acc: 0.9513 - o8_acc: 0.9452 - val_loss: 0.5804 - val_o1_loss: 0.0365 - val_o2_loss: 0.0303 - val_o3_loss: 0.0355 - val_o4_loss: 0.0598 - val_o5_loss: 0.0643 - val_o6_loss: 0.0935 - val_o7_loss: 0.1237 - val_o8_loss: 0.1368 - val_o1_acc: 0.9910 - val_o2_acc: 0.9950 - val_o3_acc: 0.9940 - val_o4_acc: 0.9860 - val_o5_acc: 0.9860 - val_o6_acc: 0.9730 - val_o7_acc: 0.9620 - val_o8_acc: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc9e59e320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.fit(X_train, np.split(Y_train,Y_train.shape[-1],axis=-1),\n",
    "    validation_data=(X_test,np.split(Y_test,Y_test.shape[-1],axis=-1)),\n",
    "    batch_size=128, epochs=100, callbacks=[\n",
    "    keras.callbacks.ReduceLROnPlateau('loss', patience=3, verbose=1)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
