{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as axes3d\n",
    "import keras\n",
    "from sympy import *\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta, phi = symbols('theta, phi', real=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recursive procedure of generating associated legendre polynomials\n",
    "- optimized with dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=4096)\n",
    "def Pmm(m, x):\n",
    "    if m <= 0:\n",
    "        return Number(1)\n",
    "    fact = Number(2*m - 1)\n",
    "    pmm = Number(-1)**m * fact * sqrt(1-x**2) * Pmm(m-1, x)\n",
    "    return pmm.simplify()\n",
    "\n",
    "@functools.lru_cache(maxsize=4096)\n",
    "def Pmmp1(m, x):\n",
    "    pmmp1 = x * (2*m + 1) * Pmm(m, x)\n",
    "    return pmmp1.simplify()\n",
    "\n",
    "@functools.lru_cache(maxsize=4096)\n",
    "def P(l, m, x):\n",
    "    if l == m:\n",
    "        return Pmm(m, x)\n",
    "    if l == m+1:\n",
    "        return Pmmp1(m, x)\n",
    "    pll = ((2*l-1) * x * P(l-1, m, x) - (l+m-1) * P(l-2, m, x)) / (l-m)\n",
    "    return pll.simplify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d real spherical harmonic functions\n",
    "- optimized with dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=4096)\n",
    "def K(l, m):\n",
    "    return sqrt(((2*l+1)/(4*pi))*(factorial(l-m)/factorial(l+m))).simplify()\n",
    "\n",
    "@functools.lru_cache(maxsize=4096)\n",
    "def SH(l, m, theta, phi):\n",
    "    if m > 0:\n",
    "        sh = sqrt(2)*K(l,m)*cos(m*phi)*P(l,m,cos(theta))\n",
    "    elif m < 0:\n",
    "        sh = sqrt(2)*K(l,-m)*sin(-m*phi)*P(l,-m,cos(theta))\n",
    "    else:\n",
    "        sh = K(l,m)*P(l,m,cos(theta))\n",
    "    return sh.simplify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "X_train, X_test = X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a custom keras 3d directional neural layer\n",
    "- it reuse the spherical harmonic generation procedure before\n",
    "- it also demonstrate how to combine sympy and tensorflow together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Directional(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units, channels=4, bands=4, ** kwargs):\n",
    "        self.units = units\n",
    "        self.channels = channels\n",
    "        self.bands = bands\n",
    "        super(Directional, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        input_shape, input_angle_shape = input_shape\n",
    "        if input_angle_shape[-1] != 2:\n",
    "            raise Exception(\"last dimension of the input must be (THETA, PHI)\")\n",
    "        self.coeff = self.add_weight(\n",
    "            shape=(self.units, self.channels, self.bands*self.bands),\n",
    "            initializer='uniform', name='coff')\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units, self.channels),\n",
    "            initializer='zeros', name='bias')\n",
    "        def lambdify_keep_dims(args, func):\n",
    "            if func.is_constant():\n",
    "                return lambda T,P: keras.backend.constant(np.full(T.shape, float(func)))\n",
    "            return lambdify(args, func, modules=['tensorflow','numpy'])\n",
    "        self.__SHs = [\n",
    "            lambdify_keep_dims((theta, phi), SH(l, m, theta, phi).evalf())\n",
    "            for l in range(self.bands)\n",
    "            for m in range(-l, l+1)]\n",
    "        super(Directional, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputs, input_angles = inputs\n",
    "        THETA, PHI = input_angles[:,:,0], input_angles[:,:,1]\n",
    "        logits = keras.backend.sum([\n",
    "            keras.backend.repeat_elements(\n",
    "                keras.backend.expand_dims(\n",
    "                    self.__SHs[i](THETA, PHI), axis=-1), self.channels, axis=-1) * \\\n",
    "            keras.backend.repeat_elements(\n",
    "                keras.backend.expand_dims(\n",
    "                    self.coeff[:,:,i], axis=0), inputs.shape[1], axis=0)\n",
    "            for i in range(0, len(self.__SHs))], axis=0)\n",
    "        logits = keras.backend.reshape(\n",
    "            inputs @ keras.backend.reshape(logits, (-1,self.units*self.channels)),\n",
    "            (-1,self.units,self.channels))\n",
    "        logits += self.bias\n",
    "        activation = keras.backend.sum(keras.backend.tanh(logits), axis=-1)\n",
    "        return activation\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (784, 64, 2)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "directional_1 (Directional)     (None, 64)           3264        reshape_1[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (64, 32, 2)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "directional_2 (Directional)     (None, 32)           1664        directional_1[0][0]              \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (32, 10, 2)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "directional_3 (Directional)     (None, 10)           370         directional_2[0][0]              \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           directional_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,298\n",
      "Trainable params: 5,298\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_input = keras.layers.Input((28,28))\n",
    "X = keras.layers.Reshape((28*28,))(X)\n",
    "X_angle = keras.layers.Lambda(lambda _: keras.backend.constant(\n",
    "    np.random.rand(28*28,64,2)*(np.pi,np.pi*2)))([])\n",
    "X = Directional(64, channels=3, bands=4)([X, X_angle])\n",
    "X_angle = keras.layers.Lambda(lambda _: keras.backend.constant(\n",
    "    np.random.rand(64,32,2)*(np.pi,np.pi*2)))([])\n",
    "X = Directional(32, channels=2, bands=5)([X, X_angle])\n",
    "X_angle = keras.layers.Lambda(lambda _: keras.backend.constant(\n",
    "    np.random.rand(32,10,2)*(np.pi,np.pi*2)))([])\n",
    "X = Directional(10, channels=1, bands=6)([X, X_angle])\n",
    "X = keras.layers.Activation('softmax')(X)\n",
    "M = keras.Model(X_input, X)\n",
    "M.compile('adam', 'sparse_categorical_crossentropy', ['acc'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 1.1885 - acc: 0.8157 - val_loss: 0.9860 - val_acc: 0.9067\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.9766 - acc: 0.9077 - val_loss: 0.9526 - val_acc: 0.9180\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.9463 - acc: 0.9217 - val_loss: 0.9382 - val_acc: 0.9261\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.9298 - acc: 0.9295 - val_loss: 0.9198 - val_acc: 0.9351\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.9181 - acc: 0.9351 - val_loss: 0.9136 - val_acc: 0.9366\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.9117 - acc: 0.9378 - val_loss: 0.9190 - val_acc: 0.9362\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.9052 - acc: 0.9417 - val_loss: 0.9058 - val_acc: 0.9401\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8995 - acc: 0.9446 - val_loss: 0.9010 - val_acc: 0.9439\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8952 - acc: 0.9472 - val_loss: 0.9009 - val_acc: 0.9418\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8917 - acc: 0.9478 - val_loss: 0.9009 - val_acc: 0.9435\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.8874 - acc: 0.9508 - val_loss: 0.9014 - val_acc: 0.9430\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8847 - acc: 0.9514 - val_loss: 0.8955 - val_acc: 0.9466\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.8826 - acc: 0.9526 - val_loss: 0.8964 - val_acc: 0.9451\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.8808 - acc: 0.9527 - val_loss: 0.8948 - val_acc: 0.9479\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.8779 - acc: 0.9549 - val_loss: 0.8941 - val_acc: 0.9471\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8764 - acc: 0.9557 - val_loss: 0.8967 - val_acc: 0.9452\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8748 - acc: 0.9556 - val_loss: 0.8923 - val_acc: 0.9474\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.8728 - acc: 0.9575 - val_loss: 0.8913 - val_acc: 0.9482\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.8735 - acc: 0.9566 - val_loss: 0.8924 - val_acc: 0.9486\n",
      "CPU times: user 5min 56s, sys: 28.9 s, total: 6min 24s\n",
      "Wall time: 5min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a6995e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "M.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
    "    batch_size=128, epochs=50, callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2, verbose=True),\n",
    "        keras.callbacks.EarlyStopping(monitor='loss'),\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
