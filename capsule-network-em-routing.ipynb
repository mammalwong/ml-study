{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_test,Y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train,X_test = X_train/255,X_test/255\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsuleConv2D(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, channels, kernel_size, strides=(1,1),\n",
    "                 em_steps=3, temp_start=1., temp_end=1/3.,\n",
    "                 mat_size=(4,4), coord=False, **kwargs):\n",
    "        self.channels = channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.em_steps = em_steps\n",
    "        self.temp_start = temp_start\n",
    "        self.temp_end = temp_end\n",
    "        self.mat_size = mat_size\n",
    "        self.coord = coord\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.kernel_size[0]*self.kernel_size[1]*input_shape[0][3],\n",
    "                   self.channels, *self.mat_size),\n",
    "            initializer=keras.initializers.TruncatedNormal(\n",
    "                mean=0., stddev=1.), name='kernel')\n",
    "        self.beta_a = self.add_weight(\n",
    "            shape=(self.channels,),\n",
    "            initializer='zeros', name='beta_a')\n",
    "        self.beta_u = self.add_weight(\n",
    "            shape=(self.channels,),\n",
    "            initializer='zeros', name='beta_u')\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_shape = [i_.shape for i_ in inputs]\n",
    "        \n",
    "        poses, activations = inputs\n",
    "        input_channel_size = poses.shape[3]\n",
    "        \n",
    "        if self.coord:\n",
    "            coord_y = np.linspace(-1, 1, num=int(poses.shape[1]))\n",
    "            coord_y = np.repeat(coord_y[:,np.newaxis],int(poses.shape[2]),axis=1)\n",
    "            coord_x = np.linspace(-1, 1, num=int(poses.shape[2]))\n",
    "            coord_x = np.repeat(coord_x[np.newaxis,:],int(poses.shape[1]),axis=0)\n",
    "            coord = np.zeros((1,int(poses.shape[1]),int(poses.shape[2]),\n",
    "                1,int(poses.shape[4]),int(poses.shape[5])))\n",
    "            coord[:,:,:,0,0,-1] = coord_x\n",
    "            coord[:,:,:,0,1,-1] = coord_y\n",
    "            poses = poses + K.constant(coord)\n",
    "        \n",
    "        poses = K.reshape(poses, (\n",
    "            -1,*poses.shape[1:3],poses.shape[3]*self.mat_size[0]*self.mat_size[1]))\n",
    "        def conv_expand(x):\n",
    "            conv_data_size = x.shape[3]\n",
    "            conv_kernel = np.zeros((*self.kernel_size, conv_data_size,\n",
    "                                    self.kernel_size[0]*self.kernel_size[1]))\n",
    "            for i in range(self.kernel_size[0]):\n",
    "                for j in range(self.kernel_size[1]):\n",
    "                    conv_kernel[i,j,:,i*self.kernel_size[0]+j] = 1\n",
    "            x = K.depthwise_conv2d(x, K.constant(conv_kernel),\n",
    "                                       strides=self.strides, padding='same')\n",
    "            x = K.reshape(x, (-1,*x.shape[1:3],conv_data_size,\n",
    "                                     self.kernel_size[0]*self.kernel_size[1]))\n",
    "            x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "            return x\n",
    "        poses = conv_expand(poses)\n",
    "        activations = conv_expand(activations)\n",
    "        \n",
    "        poses = K.reshape(poses, (-1,*poses.shape[1:3],\n",
    "            self.kernel_size[0]*self.kernel_size[1]*input_channel_size,\n",
    "            1,*self.mat_size))\n",
    "        poses = K.tile(poses, (1,1,1,1,self.channels,1,1))\n",
    "        kernel = K.reshape(self.kernel, (1,1,1,*self.kernel.shape))\n",
    "        kernel = K.tile(kernel, K.concatenate([\n",
    "            K.shape(poses)[:3],K.constant(np.ones((4,)),dtype='int32')]))\n",
    "        votes = poses @ kernel\n",
    "        votes = K.reshape(votes, (\n",
    "            -1,*votes.shape[1:5],self.mat_size[0]*self.mat_size[1]))\n",
    "        \n",
    "        activations = K.reshape(activations, (-1,*activations.shape[1:3],\n",
    "            self.kernel_size[0]*self.kernel_size[1]*input_channel_size,1))\n",
    "        r = K.constant(1/self.channels, shape=(1,*votes.shape[1:5]))\n",
    "        r = K.tile(r, K.concatenate([\n",
    "            K.shape(votes)[:1],K.constant(np.ones((4,)),dtype='int32')]))\n",
    "        for t in range(self.em_steps):\n",
    "            inv_temp = self.temp_start*(1-(t/max(1,self.em_steps-1)))\n",
    "            inv_temp = inv_temp + self.temp_end*(t/max(1,self.em_steps-1))\n",
    "            inv_temp = 1/inv_temp\n",
    "            r = r * activations\n",
    "            r_expanded = K.expand_dims(r)\n",
    "            r_sum_i = K.expand_dims(K.sum(r, axis=3))\n",
    "            mu = K.sum(r_expanded*votes,axis=3)/r_sum_i\n",
    "            mu_diff_square = K.square(votes-K.expand_dims(mu,axis=3))\n",
    "            mu_diff_square = mu_diff_square + K.epsilon()\n",
    "            sigma_square = K.sum(r_expanded*mu_diff_square,axis=3)/r_sum_i\n",
    "            sigma = K.sqrt(sigma_square)\n",
    "            cost = K.reshape(self.beta_u,(1,1,1,self.channels,1))\n",
    "            cost = cost + K.log(sigma)\n",
    "            cost = cost * r_sum_i\n",
    "            cost_all_h = K.sum(cost,axis=-1)\n",
    "            # for numerical stability, change cost_all_h to a relative way\n",
    "            cost_all_h_mu = K.mean(cost_all_h,axis=-1,keepdims=True)\n",
    "            cost_all_h_sigma = K.var(cost_all_h,axis=-1,keepdims=True)\n",
    "            cost_all_h_sigma = cost_all_h_sigma + K.epsilon()\n",
    "            cost_all_h = (cost_all_h - cost_all_h_mu)\n",
    "            cost_all_h = cost_all_h / cost_all_h_sigma\n",
    "            a = K.sigmoid(inv_temp*(self.beta_a-cost_all_h))\n",
    "            if t+1 == self.em_steps: continue\n",
    "            # for numerical stability, change p from the paper to log p\n",
    "            log_p = mu_diff_square/K.expand_dims(2*sigma_square,axis=3)\n",
    "            log_p = -K.sum(log_p,axis=-1)\n",
    "            log_p = log_p - K.expand_dims(\n",
    "                K.sum((np.log(2*np.pi)/2)+K.log(sigma),axis=-1),axis=3)\n",
    "            # for numerical stability, compute r from log p instread of p\n",
    "            r = K.expand_dims(K.log(a+K.epsilon()),axis=3) + log_p\n",
    "            r = K.softmax(r,axis=-1)\n",
    "        \n",
    "        a = K.print_tensor(a)\n",
    "        return [K.reshape(mu,(-1,*mu.shape[1:4],*self.mat_size)), a]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0][0],\n",
    "                input_shape[0][1]//self.strides[0],\n",
    "                input_shape[0][2]//self.strides[1],self.channels,*self.mat_size),(\n",
    "                input_shape[1][0],\n",
    "                input_shape[1][1]//self.strides[0],\n",
    "                input_shape[1][2]//self.strides[1],self.channels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spread_loss(y_true, y_pred):\n",
    "    m = K.max(y_true)\n",
    "    y_true = y_true / m\n",
    "    y_true = K.print_tensor(y_true)\n",
    "    y_pred = K.print_tensor(y_pred)\n",
    "    at = K.sum(y_true*y_pred, axis=-1, keepdims=True)\n",
    "    ad = K.square(K.clip(m - (at - y_pred), 0, None))\n",
    "    ad = ad * (1-y_true)\n",
    "    return K.mean(K.sum(ad, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 3)    12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 8)    608         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 64)   12864       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 64)   4160        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16, 16, 4, 4, 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 4)    260         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_1 (CapsuleConv2D [(None, 8, 8, 4, 4,  2312        lambda_1[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_2 (CapsuleConv2D [(None, 4, 4, 4, 4,  2312        capsule_conv2d_1[0][0]           \n",
      "                                                                 capsule_conv2d_1[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_3 (CapsuleConv2D [(None, 2, 2, 8, 4,  4624        capsule_conv2d_2[0][0]           \n",
      "                                                                 capsule_conv2d_2[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_4 (CapsuleConv2D [(None, 1, 1, 10, 4, 11540       capsule_conv2d_3[0][0]           \n",
      "                                                                 capsule_conv2d_3[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           capsule_conv2d_4[0][1]           \n",
      "==================================================================================================\n",
      "Total params: 38,692\n",
      "Trainable params: 38,686\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_input = keras.layers.Input(X_train.shape[1:])\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "X = keras.layers.Conv2D(8, (5,5), strides=(2,2), padding='same',\n",
    "                        activation='relu', kernel_initializer='he_normal')(X)\n",
    "X = keras.layers.Conv2D(64, (5,5), strides=(1,1), padding='same',\n",
    "                        activation='relu', kernel_initializer='he_normal')(X)\n",
    "X_pose = keras.layers.Conv2D(4*4**2, (1,1), padding='same')(X)\n",
    "X_pose = keras.layers.Lambda(\n",
    "    lambda x: K.reshape(x, (-1,*x.shape[1:3],4,4,4)),\n",
    "    output_shape=(int(X_pose.shape[1]),int(X_pose.shape[2]),4,4,4))(X_pose)\n",
    "X = keras.layers.Conv2D(4, (1,1), padding='same', activation='sigmoid')(X)\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2), coord=True)([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(8, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(Y_train.shape[-1], (3,3), strides=(2,2))([X_pose,X])\n",
    "X = keras.layers.Flatten()(X)\n",
    "M = keras.Model(X_input, X)\n",
    "M.compile('nadam', spread_loss)\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 3)    12          input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 8)    608         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 64)   12864       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 64)   4160        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 16, 16, 4, 4, 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 4)    260         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_41 (CapsuleConv2 [(None, 8, 8, 4, 4,  2312        lambda_17[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_42 (CapsuleConv2 [(None, 4, 4, 4, 4,  2312        capsule_conv2d_41[0][0]          \n",
      "                                                                 capsule_conv2d_41[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_43 (CapsuleConv2 [(None, 2, 2, 4, 4,  2312        capsule_conv2d_42[0][0]          \n",
      "                                                                 capsule_conv2d_42[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_44 (CapsuleConv2 [(None, 1, 1, 10, 4, 5780        capsule_conv2d_43[0][0]          \n",
      "                                                                 capsule_conv2d_43[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 10)           0           capsule_conv2d_44[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "softmax_11 (Softmax)            (None, 10)           0           flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 30,620\n",
      "Trainable params: 30,614\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_input = keras.layers.Input(X_train.shape[1:])\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "X = keras.layers.Conv2D(8, (5,5), strides=(2,2), padding='same',\n",
    "                        activation='relu', kernel_initializer='he_normal')(X)\n",
    "X = keras.layers.Conv2D(64, (5,5), strides=(1,1), padding='same',\n",
    "                        activation='relu', kernel_initializer='he_normal')(X)\n",
    "X_pose = keras.layers.Conv2D(4*4**2, (1,1), padding='same')(X)\n",
    "X_pose = keras.layers.Lambda(\n",
    "    lambda x: K.reshape(x, (-1,*x.shape[1:3],4,4,4)),\n",
    "    output_shape=(int(X_pose.shape[1]),int(X_pose.shape[2]),4,4,4))(X_pose)\n",
    "X = keras.layers.Conv2D(4, (1,1), padding='same', activation='sigmoid')(X)\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(Y_train.shape[-1], (3,3), strides=(2,2))([X_pose,X])\n",
    "X = keras.layers.Flatten()(X)\n",
    "X = keras.layers.Softmax()(X)\n",
    "M = keras.Model(X_input, X)\n",
    "M_optimizer = keras.optimizers.SGD(momentum=0.9)\n",
    "M.compile(M_optimizer, 'categorical_crossentropy', ['acc'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1456/50000 [..............................] - ETA: 21:50 - loss: 2.3034 - acc: 0.0975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-423ac58d6403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M.fit(X_train, Y_train, batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 4032/50000 [=>............................] - ETA: 19:44 - loss: 7.3426"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0e95e374f443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 0.9\n",
    "for i in range(10):\n",
    "    M.fit(X_train, Y_train*m, batch_size=16, initial_epoch=i, epochs=i+1)\n",
    "    m = min(m+0.1, 0.9)\n",
    "    test = M.predict(X_test, batch_size=16)\n",
    "    test = np.argmax(test, axis=-1) == np.argmax(Y_test, axis=-1)\n",
    "    test = np.mean(test)\n",
    "    print('val-acc', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EMTest(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, channels, em_steps=3, temp_start=1., temp_end=1/3., **kwargs):\n",
    "        self.channels = channels\n",
    "        self.em_steps = em_steps\n",
    "        self.temp_start = temp_start\n",
    "        self.temp_end = temp_end\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        votes, activations = inputs\n",
    "        \n",
    "        beta_a, beta_u = 0., 0.\n",
    "        \n",
    "        activations = K.expand_dims(activations)\n",
    "        r = K.constant(1/self.channels, shape=(1,*votes.shape[1:5]))\n",
    "        r = K.tile(r, K.concatenate([\n",
    "            K.shape(votes)[:1],K.constant(np.ones((4,)),dtype='int32')]))\n",
    "        for t in range(self.em_steps):\n",
    "            inv_temp = self.temp_start*(1-(t/max(1,self.em_steps-1)))\n",
    "            inv_temp = inv_temp + self.temp_end*(t/max(1,self.em_steps-1))\n",
    "            inv_temp = 1/inv_temp\n",
    "            r = r * activations\n",
    "            r_expanded = K.expand_dims(r)\n",
    "            r_sum_i = K.expand_dims(K.sum(r, axis=3))\n",
    "            mu = K.sum(r_expanded*votes,axis=3)/r_sum_i\n",
    "            mu_diff_square = K.square(votes-K.expand_dims(mu,axis=3))\n",
    "            mu_diff_square = mu_diff_square + K.epsilon()\n",
    "            sigma_square = K.sum(r_expanded*mu_diff_square,axis=3)/r_sum_i\n",
    "            sigma = K.sqrt(sigma_square)\n",
    "            cost = beta_u\n",
    "            cost = cost + K.log(sigma + K.epsilon())\n",
    "            cost = cost * r_sum_i\n",
    "            cost_all_h = K.sum(cost,axis=-1)\n",
    "            # for numerical stability, change cost_all_h to a relative way\n",
    "            cost_all_h_mu = K.mean(cost_all_h,axis=-1,keepdims=True)\n",
    "            cost_all_h_sigma = K.var(cost_all_h,axis=-1,keepdims=True)\n",
    "            cost_all_h_sigma = cost_all_h_sigma + K.epsilon()\n",
    "            cost_all_h = (cost_all_h - cost_all_h_mu)\n",
    "            cost_all_h = cost_all_h / cost_all_h_sigma\n",
    "            a = K.sigmoid(inv_temp*(beta_a-cost_all_h))\n",
    "            if t+1 == self.em_steps:\n",
    "                continue\n",
    "            # for numerical stability, change p from the paper to log p\n",
    "            log_p = mu_diff_square/K.expand_dims(2*sigma_square,axis=3)\n",
    "            log_p = -K.sum(log_p,axis=-1)\n",
    "            log_p = log_p - K.expand_dims(\n",
    "                K.sum((np.log(2*np.pi)/2)+K.log(sigma),axis=-1),axis=3)\n",
    "            # for numerical stability, compute r from log p instread of p\n",
    "            r = K.expand_dims(K.log(a+K.epsilon()),axis=3) + log_p\n",
    "            r = K.softmax(r,axis=-1)\n",
    "        \n",
    "        return [mu, a, r]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0][0],\n",
    "                input_shape[0][1],\n",
    "                input_shape[0][2],self.channels,input_shape[0][-1]),(\n",
    "                input_shape[1][0],\n",
    "                input_shape[1][1],\n",
    "                input_shape[1][2],self.channels),(\n",
    "                input_shape[0][0],\n",
    "                input_shape[0][1],\n",
    "                input_shape[0][2],\n",
    "                input_shape[0][3],self.channels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 1, 1, 64, 2,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 1, 1, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "em_test_9 (EMTest)              [(None, 1, 1, 2, 1), 0           input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_input_votes = keras.layers.Input((1,1,64,2,1))\n",
    "X_input_acti = keras.layers.Input((1,1,64))\n",
    "X = EMTest(2, em_steps=10)([X_input_votes,X_input_acti])\n",
    "M = keras.Model([X_input_votes,X_input_acti],X)\n",
    "M.compile('sgd','mse')\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.random.randn(1,1,1,64,2,1)\n",
    "v[...,:32,0,:] = 1\n",
    "v[...,32:,1,:] = -1\n",
    "a = np.ones((1,1,1,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[ 1.]\n",
      "    [-1.]]]]]\n",
      "[[[[0.5 0.5]]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52886a26d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y,z = M.predict([v,a])\n",
    "print(x)\n",
    "print(y)\n",
    "plt.imshow(z[0,0,0].T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
