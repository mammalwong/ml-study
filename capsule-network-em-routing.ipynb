{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_test,Y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train,X_test = X_train/255,X_test/255\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleConv2D(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, channels, kernel_size, strides=(1,1),\n",
    "                 em_steps=3, mat_size=(4,4), coord=False, **kwargs):\n",
    "        self.channels = channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.em_steps = em_steps\n",
    "        self.mat_size = mat_size\n",
    "        self.coord = coord\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.kernel_size[0]*self.kernel_size[1]*input_shape[0][3],\n",
    "                   self.channels, *self.mat_size),\n",
    "            initializer=keras.initializers.TruncatedNormal(\n",
    "                mean=0., stddev=1.), name='kernel')\n",
    "        self.beta_a = self.add_weight(\n",
    "            shape=(self.channels,),\n",
    "            initializer='glorot_normal', name='beta_a')\n",
    "        self.beta_u = self.add_weight(\n",
    "            shape=(self.channels,),\n",
    "            initializer='glorot_normal', name='beta_u')\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_shape = [i_.shape for i_ in inputs]\n",
    "        \n",
    "        poses, activations = inputs\n",
    "        input_channel_size = poses.shape[3]\n",
    "        \n",
    "        if self.coord:\n",
    "            coord_y = np.linspace(-1, 1, num=int(poses.shape[1]))\n",
    "            coord_y = np.repeat(coord_y[:,np.newaxis],int(poses.shape[2]),axis=1)\n",
    "            coord_x = np.linspace(-1, 1, num=int(poses.shape[2]))\n",
    "            coord_x = np.repeat(coord_x[np.newaxis,:],int(poses.shape[1]),axis=0)\n",
    "            coord = np.zeros((1,int(poses.shape[1]),int(poses.shape[2]),\n",
    "                1,int(poses.shape[4]),int(poses.shape[5])))\n",
    "            coord[:,:,:,0,0,-1] = coord_x\n",
    "            coord[:,:,:,0,1,-1] = coord_y\n",
    "            poses = poses + K.constant(coord)\n",
    "        \n",
    "        poses = K.reshape(poses, (\n",
    "            -1,*poses.shape[1:3],poses.shape[3]*self.mat_size[0]*self.mat_size[1]))\n",
    "        def conv_expand(x):\n",
    "            conv_data_size = x.shape[3]\n",
    "            conv_kernel = np.zeros((*self.kernel_size, conv_data_size,\n",
    "                                    self.kernel_size[0]*self.kernel_size[1]))\n",
    "            for i in range(self.kernel_size[0]):\n",
    "                for j in range(self.kernel_size[1]):\n",
    "                    conv_kernel[i,j,:,i*self.kernel_size[0]+j] = 1\n",
    "            x = K.depthwise_conv2d(x, K.constant(conv_kernel),\n",
    "                                       strides=self.strides, padding='same')\n",
    "            x = K.reshape(x, (-1,*x.shape[1:3],conv_data_size,\n",
    "                                     self.kernel_size[0]*self.kernel_size[1]))\n",
    "            x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "            return x\n",
    "        poses = conv_expand(poses)\n",
    "        activations = conv_expand(activations)\n",
    "        \n",
    "        poses = K.reshape(poses, (-1,*poses.shape[1:3],\n",
    "            self.kernel_size[0]*self.kernel_size[1]*input_channel_size,\n",
    "            1,*self.mat_size))\n",
    "        poses = K.tile(poses, (1,1,1,1,self.channels,1,1))\n",
    "        kernel = K.reshape(self.kernel, (1,1,1,*self.kernel.shape))\n",
    "        kernel = K.tile(kernel, K.concatenate([\n",
    "            K.shape(poses)[:3],K.constant(np.ones((4,)),dtype='int32')]))\n",
    "        votes = kernel @ poses\n",
    "        votes = K.reshape(votes, (\n",
    "            -1,*votes.shape[1:5],self.mat_size[0]*self.mat_size[1]))\n",
    "        \n",
    "        activations = K.reshape(activations, (-1,*activations.shape[1:3],\n",
    "            self.kernel_size[0]*self.kernel_size[1]*input_channel_size,1))\n",
    "        r = K.constant(1/self.channels, shape=(1,*votes.shape[1:5]))\n",
    "        r = K.tile(r, K.concatenate([\n",
    "            K.shape(votes)[:1],K.constant(np.ones((4,)),dtype='int32')]))\n",
    "        for t in range(self.em_steps):\n",
    "            inv_temp = 1+t\n",
    "            r = r * activations\n",
    "            r_expanded = K.expand_dims(r)\n",
    "            r_sum_i = K.expand_dims(K.sum(r, axis=3))\n",
    "            mu = K.sum(r_expanded*votes,axis=3)/r_sum_i\n",
    "            mu_diff_square = K.square(votes-K.expand_dims(mu,axis=3))\n",
    "            sigma_square = K.sum(r_expanded*mu_diff_square,axis=3)/r_sum_i\n",
    "            sigma_square = K.clip(sigma_square, K.epsilon(), None)\n",
    "            sigma = K.sqrt(sigma_square)\n",
    "            cost = K.reshape(self.beta_u,(1,1,1,self.channels,1))\n",
    "            cost = cost + K.log(sigma + K.epsilon())\n",
    "            cost = cost * r_sum_i\n",
    "            cost_all_h = K.sum(cost,axis=-1)\n",
    "            # for numerical stability, change cost_all_h to a relative way\n",
    "            cost_all_h_mu = K.mean(cost_all_h,axis=-1,keepdims=True)\n",
    "            cost_all_h_sigma = K.var(cost_all_h,axis=-1,keepdims=True)\n",
    "            cost_all_h = (cost_all_h - cost_all_h_mu)\n",
    "            cost_all_h = cost_all_h / (cost_all_h_sigma + K.epsilon())\n",
    "            a = K.sigmoid(inv_temp*(self.beta_a-cost_all_h))\n",
    "            if t+1 == self.em_steps:\n",
    "                continue\n",
    "            # for numerical stability, change p from the paper to log p\n",
    "            log_p = mu_diff_square/K.expand_dims(2*sigma_square,axis=3)\n",
    "            log_p = -K.sum(log_p,axis=-1)\n",
    "            log_p = log_p - K.expand_dims(\n",
    "                K.sum((np.log(2*np.pi)/2)+K.log(sigma+K.epsilon()),axis=-1),axis=3)\n",
    "            # for numerical stability, compute r from log p instread of p\n",
    "            r = K.expand_dims(K.log(a+K.epsilon()),axis=3) + log_p\n",
    "            r = K.softmax(r,axis=-1)\n",
    "        \n",
    "        return [K.reshape(mu,(-1,*mu.shape[1:4],*self.mat_size)), a]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0][0],\n",
    "                input_shape[0][1]//self.strides[0],\n",
    "                input_shape[0][2]//self.strides[1],self.channels,*self.mat_size),(\n",
    "                input_shape[1][0],\n",
    "                input_shape[1][1]//self.strides[0],\n",
    "                input_shape[1][2]//self.strides[1],self.channels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spread_loss(y_true, y_pred):\n",
    "    m = K.max(y_true)\n",
    "    y_true = y_true / m\n",
    "    at = K.sum(y_true*y_pred, axis=-1, keepdims=True)\n",
    "    ad = K.square(K.clip(m - (at - y_pred), 0, None))\n",
    "    ad = ad * (1-y_true)\n",
    "    return K.mean(K.sum(ad, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 3)    12          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 8)    608         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   576         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16, 16, 4, 4, 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 4)    36          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_9 (CapsuleConv2D [(None, 8, 8, 4, 4,  2312        lambda_5[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_10 (CapsuleConv2 [(None, 4, 4, 4, 4,  2312        capsule_conv2d_9[0][0]           \n",
      "                                                                 capsule_conv2d_9[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_11 (CapsuleConv2 [(None, 2, 2, 4, 4,  2312        capsule_conv2d_10[0][0]          \n",
      "                                                                 capsule_conv2d_10[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "capsule_conv2d_12 (CapsuleConv2 [(None, 1, 1, 10, 4, 5780        capsule_conv2d_11[0][0]          \n",
      "                                                                 capsule_conv2d_11[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 10)           0           capsule_conv2d_12[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 10)           0           flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,948\n",
      "Trainable params: 13,942\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_input = keras.layers.Input(X_train.shape[1:])\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "X = keras.layers.Conv2D(8, (5,5), strides=(2,2), padding='same',\n",
    "                        activation='relu', kernel_initializer='he_normal')(X)\n",
    "X_pose = keras.layers.Conv2D(4*4**2, (1,1), padding='same')(X)\n",
    "X_pose = keras.layers.Lambda(\n",
    "    lambda x: K.reshape(x, (-1,*x.shape[1:3],4,4,4)),\n",
    "    output_shape=(int(X_pose.shape[1]),int(X_pose.shape[2]),4,4,4))(X_pose)\n",
    "X = keras.layers.Conv2D(4, (1,1), padding='same', activation='sigmoid')(X)\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(4, (3,3), strides=(2,2))([X_pose,X])\n",
    "X_pose,X = CapsuleConv2D(Y_train.shape[-1],\n",
    "                         (3,3), strides=(2,2), coord=True)([X_pose,X])\n",
    "X = keras.layers.Flatten()(X)\n",
    "X = keras.layers.Lambda(lambda x: K.print_tensor(x))(X)\n",
    "M = keras.Model(X_input, X)\n",
    "M.compile('nadam', spread_loss)\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " 6960/50000 [===>..........................] - ETA: 16:23 - loss: 0.5113"
     ]
    }
   ],
   "source": [
    "m = 0.1\n",
    "for i in range(10):\n",
    "    M.fit(X_train, Y_train*m, validation_data=(X_test,Y_test*m),\n",
    "          batch_size=8, initial_epoch=i, epochs=i+1)\n",
    "    m = min(m+0.1, 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
