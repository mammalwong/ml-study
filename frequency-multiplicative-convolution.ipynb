{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train, X_test = X_train/255, X_test/255\n",
    "if len(X_train.shape) != 4:\n",
    "    X_train, X_test = X_train[:,:,:,np.newaxis], X_test[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FrequencyMultiplicative(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters, freq_filters=None, **kwargs):\n",
    "        self.filters = filters\n",
    "        self.freq_filters = freq_filters\n",
    "        super(FrequencyMultiplicative, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self.freq_filters is not None:\n",
    "            self.kernel_freq = self.add_weight(\n",
    "                shape=(1, input_shape[1], input_shape[2],self.freq_filters, input_shape[3]),\n",
    "                initializer='he_uniform', name='kernel_freq')\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(1, self.filters,\n",
    "                   input_shape[3] if self.freq_filters is None else self.freq_filters,\n",
    "                   input_shape[2], input_shape[1]),\n",
    "            initializer='he_uniform', name='kernel')\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.filters,),\n",
    "            initializer='zeros', name='bias')\n",
    "        super(FrequencyMultiplicative, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        if self.freq_filters is not None:\n",
    "            x = K.expand_dims(x, axis=-2)\n",
    "            x = x * self.kernel_freq\n",
    "            x = K.sum(x, axis=-1, keepdims=False)\n",
    "        x = K.permute_dimensions(x, (0,3,1,2))\n",
    "        x = tf.spectral.dct(x, norm='ortho')\n",
    "        x = K.permute_dimensions(x, (0,1,3,2))\n",
    "        x = tf.spectral.dct(x, norm='ortho')\n",
    "        x = K.expand_dims(x, axis=1)\n",
    "        x = x * self.kernel\n",
    "        x = K.sum(x, axis=2, keepdims=False)\n",
    "        x = tf.spectral.idct(x, norm='ortho')\n",
    "        x = K.permute_dimensions(x, (0,1,3,2))\n",
    "        x = tf.spectral.idct(x, norm='ortho')\n",
    "        x = K.permute_dimensions(x, (0,2,3,1))\n",
    "        x = x + self.bias\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (self.filters,)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            **super(FrequencyMultiplicative, self).get_config(),\n",
    "            'filters': self.filters,\n",
    "            'freq_filters': self.freq_filters,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCT(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(DCT, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(DCT, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        x = K.permute_dimensions(x, (0,3,1,2))\n",
    "        x = tf.spectral.dct(x, norm='ortho')\n",
    "        x = K.permute_dimensions(x, (0,1,3,2))\n",
    "        x = tf.spectral.dct(x, norm='ortho')\n",
    "        x = K.permute_dimensions(x, (0,3,2,1))\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionalPooling(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionalPooling, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        data_shape, att_shape = input_shape\n",
    "        if data_shape[-1] != att_shape[-1]:\n",
    "            raise Exception('channel count of data and attention required to be equal')\n",
    "        super(AttentionalPooling, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        data, att = inputs\n",
    "        data = K.reshape(data, (-1,data.shape[1]//2,2,data.shape[2]//2,2,data.shape[3]))\n",
    "        data = K.permute_dimensions(data, (0,1,3,2,4,5))\n",
    "        data = K.reshape(data, (-1,data.shape[1],data.shape[2],4,data.shape[-1]))\n",
    "        att = K.reshape(att, (-1,att.shape[1]//2,2,att.shape[2]//2,2,att.shape[-1]))\n",
    "        att = K.permute_dimensions(att, (0,1,3,2,4,5))\n",
    "        att = K.reshape(att, (-1,att.shape[1],att.shape[2],4,att.shape[-1]))\n",
    "        att = K.softmax(att, axis=-2)\n",
    "        data = data * att\n",
    "        data = K.sum(data, axis=-2, keepdims=False)\n",
    "        return data\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        data_shape, _ = input_shape\n",
    "        return (data_shape[0], data_shape[1]//2, data_shape[2]//2, data_shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dct_2 (DCT)                     (None, 32, 32, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 3)    12          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 3)    12          dct_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_13 (Fr (None, 32, 32, 12)   36876       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_14 (Fr (None, 32, 32, 4)    28676       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 14)   392         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 2)    8           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_19 (Fr (None, 32, 32, 12)   36876       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_20 (Fr (None, 32, 32, 4)    28676       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 14)   392         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 2)    8           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 32)   0           frequency_multiplicative_13[0][0]\n",
      "                                                                 frequency_multiplicative_14[0][0]\n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 32)   0           frequency_multiplicative_19[0][0]\n",
      "                                                                 frequency_multiplicative_20[0][0]\n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 32)   128         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 32)   2432        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 32)   2432        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "attentional_pooling_5 (Attentio (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attentional_pooling_7 (Attentio (None, 16, 16, 32)   0           activation_12[0][0]              \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_15 (Fr (None, 16, 16, 24)   196632      attentional_pooling_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_16 (Fr (None, 16, 16, 8)    40968       attentional_pooling_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 28)   8092        attentional_pooling_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 4)    132         attentional_pooling_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_21 (Fr (None, 16, 16, 24)   196632      attentional_pooling_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_22 (Fr (None, 16, 16, 8)    40968       attentional_pooling_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 28)   8092        attentional_pooling_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 4)    132         attentional_pooling_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 64)   0           frequency_multiplicative_15[0][0]\n",
      "                                                                 frequency_multiplicative_16[0][0]\n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 64)   0           frequency_multiplicative_21[0][0]\n",
      "                                                                 frequency_multiplicative_22[0][0]\n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   51264       attentional_pooling_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 64)   51264       attentional_pooling_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attentional_pooling_6 (Attentio (None, 8, 8, 64)     0           activation_10[0][0]              \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attentional_pooling_8 (Attentio (None, 8, 8, 64)     0           activation_13[0][0]              \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_17 (Fr (None, 8, 8, 24)     98328       attentional_pooling_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_18 (Fr (None, 8, 8, 8)      36872       attentional_pooling_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 28)     16156       attentional_pooling_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 4)      260         attentional_pooling_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_23 (Fr (None, 8, 8, 24)     98328       attentional_pooling_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "frequency_multiplicative_24 (Fr (None, 8, 8, 8)      36872       attentional_pooling_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 28)     16156       attentional_pooling_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 4)      260         attentional_pooling_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 64)     0           frequency_multiplicative_17[0][0]\n",
      "                                                                 frequency_multiplicative_18[0][0]\n",
      "                                                                 conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 8, 8, 64)     0           frequency_multiplicative_23[0][0]\n",
      "                                                                 frequency_multiplicative_24[0][0]\n",
      "                                                                 conv2d_31[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4096)         0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 4096)         0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 8192)         0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          1048704     concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128)          512         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           4128        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32)           128         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32)           0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, array([10], d 330         activation_16[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,089,282\n",
      "Trainable params: 2,088,310\n",
      "Non-trainable params: 972\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = X_input = keras.layers.Input(X_train.shape[1:])\n",
    "X_spatial = X\n",
    "X_freq = DCT()(X)\n",
    "X_inceptions = []\n",
    "for X in [X_spatial, X_freq]:\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X1 = FrequencyMultiplicative(12)(X)\n",
    "    X2 = FrequencyMultiplicative(4, freq_filters=4)(X)\n",
    "    X3 = keras.layers.Conv2D(14, (3,3), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X4 = keras.layers.Conv2D(2, (1,1), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    XA = keras.layers.Conv2D(32, (5,5), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X = keras.layers.Concatenate()([X1,X2,X3,X4])\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = AttentionalPooling()([X,XA])\n",
    "    X1 = FrequencyMultiplicative(24)(X)\n",
    "    X2 = FrequencyMultiplicative(8, freq_filters=4)(X)\n",
    "    X3 = keras.layers.Conv2D(28, (3,3), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X4 = keras.layers.Conv2D(4, (1,1), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    XA = keras.layers.Conv2D(64, (5,5), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X = keras.layers.Concatenate()([X1,X2,X3,X4])\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = AttentionalPooling()([X,XA])\n",
    "    X1 = FrequencyMultiplicative(24)(X)\n",
    "    X2 = FrequencyMultiplicative(8, freq_filters=8)(X)\n",
    "    X3 = keras.layers.Conv2D(28, (3,3), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X4 = keras.layers.Conv2D(4, (1,1), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X = keras.layers.Concatenate()([X1,X2,X3,X4])\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.Flatten()(X)\n",
    "    X_inceptions.append(X)\n",
    "X = keras.layers.Concatenate()(X_inceptions)\n",
    "X = keras.layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "X = keras.layers.Activation('relu')(X)\n",
    "X = keras.layers.Dense(32, kernel_initializer='he_uniform')(X)\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "X = keras.layers.Activation('relu')(X)\n",
    "X = keras.layers.Dense(max(Y_train)+1, activation='softmax')(X)\n",
    "M = keras.Model(X_input, X)\n",
    "M.compile('nadam', 'sparse_categorical_crossentropy', ['acc'])\n",
    "M.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/781 [==============================] - 661s 845ms/step - loss: 0.5353 - acc: 0.8112 - val_loss: 0.7134 - val_acc: 0.7611\n",
      "Epoch 2/30\n",
      "  2/781 [..............................] - ETA: 10:06 - loss: 0.6163 - acc: 0.7656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c51525ee88f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     steps_per_epoch=len(X_train) / 64, epochs=30, callbacks=[\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#keras.callbacks.TensorBoard(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#    log_dir='./models/frequency-multiplicative-convolution/logs/',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M.fit_generator(\n",
    "    datagen.flow(X_train, Y_train, batch_size=64), \n",
    "    validation_data=(X_test, Y_test),\n",
    "    steps_per_epoch=len(X_train) / 64, epochs=30, callbacks=[\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=2, verbose=1),\n",
    "    #keras.callbacks.TensorBoard(\n",
    "    #    log_dir='./models/frequency-multiplicative-convolution/logs/',\n",
    "    #    batch_size=64, histogram_freq=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.models.save_model(M, './models/frequency-multiplicative-convolution/model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = keras.models.load_model('./models/frequency-multiplicative-convolution/model.hdf5', custom_objects={\n",
    "    'FrequencyMultiplicative': FrequencyMultiplicative,\n",
    "    'DCT': DCT,\n",
    "    'AttentionalPooling': AttentionalPooling,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
